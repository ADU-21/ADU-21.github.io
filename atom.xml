<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>杜屹东的博客</title>
  <subtitle>Cloud &amp; DevOps</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.duyidong.com/"/>
  <updated>2017-07-16T11:26:36.000Z</updated>
  <id>https://www.duyidong.com/</id>
  
  <author>
    <name>杜屹东</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>DevOps 从理论到实践</title>
    <link href="https://www.duyidong.com/2017/07/14/what-is-devops/"/>
    <id>https://www.duyidong.com/2017/07/14/what-is-devops/</id>
    <published>2017-07-14T10:35:34.000Z</published>
    <updated>2017-07-16T11:26:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>本周六应邀参加了 <a href="https://www.freecodecamp.org/" target="_blank" rel="external">FreeCodeCamp</a>社区的一次线下活动，主题为《DevOps从理论到实践》，借此机会整理一下近年来看到听到的对于 DevOps 的定义，并产出一些自己的观点。</p>
<h1 id="什么是DevOps"><a href="#什么是DevOps" class="headerlink" title="什么是DevOps"></a>什么是DevOps</h1><h2 id="DevOps-是一个流行词"><a href="#DevOps-是一个流行词" class="headerlink" title="DevOps 是一个流行词"></a>DevOps 是一个流行词</h2><p><img src="/images/devops_word_cloud.png" alt=""></p>
<p>如今 DevOps 已经成为一个流行词，很多公司都在说自己在做 DevOps，但是每个人、每家公司理解的 DevOps 又不尽相同，从 DevOps 诞生的第一天起，如何定义 DevOps 就是一个争论不休的话题。</p>
<p>这里有一篇文章，笔者认为基本诠释了 DevOps 的定义：<a href="https://mp.weixin.qq.com/s?__biz=MzI3OTEzNjI1OQ==&amp;mid=2651492848&amp;idx=1&amp;sn=1a644a2624633489248dda2834dc9572&amp;chksm=f0b2609cc7c5e98a0145eead91b68db41d18dc33bc1be46f08026d1746b1063a6c177b7daf24#rd" target="_blank" rel="external">DevOps 是什么不是什么</a></p>
<p>如果你没有耐心把这篇文章看完，<a href="https://en.wikipedia.org/wiki/DevOps" target="_blank" rel="external">维基百科</a>还给出了一个太长不读版：</p>
<blockquote>
<p> DevOps (a clipped compound of “development” and “operations”) is a software development and delivery process that emphasizes communication and collaboration between product management, software development, and operations professionals.It seeks to automate the process of software integration, testing, deployment, and infrastructure changes by establishing a culture and environment where building, testing, and releasing software can happen rapidly, frequently, and more reliably.</p>
</blockquote>
<p>归纳成三点：</p>
<ul>
<li>DevOps 是一种强调沟通与协作的软件交付过程。它包括产品管理，软件开发及运营等各个方面。</li>
<li>DevOps 自动化软件集成，测试，部署以及基础设施的变更。</li>
<li>它的目标是建立一种文化和环境，使得软件的构建、测试、交付更快，更频繁，更可靠。</li>
</ul>
<p><img src="/images/dev_ops_qa.png" alt=""></p>
<h2 id="DevOps-的由来"><a href="#DevOps-的由来" class="headerlink" title="DevOps 的由来"></a>DevOps 的由来</h2><p>参见 <a href="http://www.jianshu.com/p/f40209023006" target="_blank" rel="external">DevOps编年史</a> 和一个 Youtube 小视频： <a href="https://www.youtube.com/watch?v=o7-IuYS0iSE" target="_blank" rel="external">The (Short) History of DevOps</a> </p>
<p><img src="/images/history_of_devops.png" alt=""></p>
<p>这里我想多提一句的是持续交付和 DevOps 的关系和差别，参照<a href="https://en.wikipedia.org/wiki/Continuous_delivery" target="_blank" rel="external">维基百科</a> 对 DevOps 和持续交付的区别进行解释，DevOps 涵盖的范围比持续交付更宽，它包含了文化，强调团队协作和自动化；而持续交付侧重于频繁、快速     地执行交付流程，两者相辅相成，却又有所区别。</p>
<blockquote>
<p>Continuous delivery and DevOps are similar in their meanings and are often conflated, but they are two different concepts. DevOps has a broader scope, and centers around the cultural change, specifically the collaboration of the various teams involved in software delivery (developers, operations, quality assurance, management, etc.), as well as automating the processes in software delivery.Continuous delivery, on the other hand, is an approach to automate the delivery aspect, and focuses on bringing together different processes and executing them more quickly and more frequently. Thus, DevOps can be a product of continuous delivery, and CD flows directly into DevOps.</p>
</blockquote>
<h2 id="DevOps-理论框架"><a href="#DevOps-理论框架" class="headerlink" title="DevOps 理论框架"></a>DevOps 理论框架</h2><p>因为DevOps源自草根，缺乏自上而下的理论支撑，所以如何定义 DevOps 成了 DevOps 社区里面的一个大难题。一些 DevOps 从业者，纷纷设定自己的 DevOps 框架。其中比较有名的框架有Damon Edwards所定义并被 Jez Humble（持续交付作者之一） 所修订的<a href="https://blog.rackspace.com/quantifying-devops-capability-its-important-to-keep-calms" target="_blank" rel="external">CALMS</a>，和Gene Kim所定义的<a href="https://www.duyidong.com/2017/07/12/the-three-ways-understanding-devops/">The Three Ways</a>。</p>
<h3 id="The-Three-Ways"><a href="#The-Three-Ways" class="headerlink" title="The Three Ways"></a>The Three Ways</h3><ul>
<li><strong>The First Way：</strong> System Thinking （系统思考：强调全局优化，避免局部优化）</li>
<li><strong>The Second Way：</strong> Amplify Feedback Loops （经过放大的反馈回路：创建从开发过程下游至上游的反馈环）</li>
<li><strong>The Third Way：</strong> Culture of Continual Experimentation And Learning（持续做试验和学习的文化：持续做试验，承担风险、从失败中学习；通过反复实践来达到精通）</li>
</ul>
<p><img src="/images/devops_CALMS_model.png" alt=""></p>
<h3 id="CLAMS"><a href="#CLAMS" class="headerlink" title="CLAMS"></a>CLAMS</h3><ul>
<li><strong>Culture – 文化：</strong>公司各个角色一起担当业务变化，实现有效协作和沟通；建立包括运维在内的跨职能协作文化,具有共同目标的一体化团队。这是DevOps运动的根本</li>
<li><strong>Automation – 自动化：</strong>在价值链中尽量除去手工步骤；自动化一切可以自动化的步骤，降低部署和发布的难度</li>
<li><strong>Lean – 精益：</strong>运用精益原则更频繁地交付价值；以精益的方式小步快跑，对过程与技术进行持续改善</li>
<li><strong>Metrics – 度量：</strong>度量并使用数据来优化交付周期；通过建立有效的监控与度量手段来获得反馈,推动产品和团队的持续改进, 支持业务决策</li>
<li><strong>Sharing – 分享：</strong>分享成功和失败的经验来相互学习。</li>
</ul>
<h1 id="为什么要实践-DevOps"><a href="#为什么要实践-DevOps" class="headerlink" title="为什么要实践 DevOps"></a>为什么要实践 DevOps</h1><p>了解了 DevOps 的历史，再来看为什么要实践 DevOps，笔者认为主要有以下三点：</p>
<ul>
<li>更短的交付周期，生产环境部署频率越来越快，简化生产部署流程，且自动化不停机部署</li>
<li>更高的价值，形成特性提出到运营数据、用户反馈验证的实验性交付闭环，基于实际用户反馈调整计划和需求</li>
<li>更好的质量保障，在代码检查，功能和非功能验证，以及部署各方面建立较完善的质量保障体系，尤其是自动化测试集</li>
<li>更高绩效的团队，包含业务，开发测试，和运维职能在内的一体化团队，以产品交付为共同目标紧密协作，共同承担责任</li>
</ul>
<h1 id="DevOps-在技术领域的实践"><a href="#DevOps-在技术领域的实践" class="headerlink" title="DevOps 在技术领域的实践"></a>DevOps 在技术领域的实践</h1><p>DevOps运作包括<strong>文化</strong>（全功能，自运维）和<strong>技术</strong>（自动化，度量反馈）两方面，而技术能力的改进主要关注以下六个领域：</p>
<p><img src="/images/devops_practice.png" alt=""></p>
<h3 id="内建质量体系"><a href="#内建质量体系" class="headerlink" title="内建质量体系"></a>内建质量体系</h3><p>通过持续代码评审，静态分析，自动化测试，自动部署验证等手段构成一套有效的质量保障体系。</p>
<p>主要实践包括：</p>
<ul>
<li>TDD：测试驱动开发的思想，保证代码质量和不偏离业务需求的技术实现</li>
<li>结对编程和代码审查，依靠团队的自治性让团队成员互相监督和审查代码质量</li>
<li>自动化测试，高自动化，且高频率运行的测试，保证测试用例质量的同时保证了交付软件的质量</li>
</ul>
<h3 id="持续部署"><a href="#持续部署" class="headerlink" title="持续部署"></a>持续部署</h3><p>通过自动化的构建，部署过程快速频繁地将软件交付给用户，提高吞吐量；同时保障过程的安全，平滑，可视。</p>
<p>主要实践包括：</p>
<ul>
<li>在已经做到持续集成的情况下，引入持续部署，每次提交均会出发构建并执行部署</li>
<li>蓝绿部署，用于实现零宕机发布新版本</li>
<li>金丝雀发布，用于使应用发布流程具备快速试错的能力</li>
</ul>
<h3 id="持续监控"><a href="#持续监控" class="headerlink" title="持续监控"></a>持续监控</h3><p>持续对运行环境在系统，应用层面进行监控，及时发现风险或问题，保障系统运行的稳定性。</p>
<p>主要实践包括：</p>
<ul>
<li>监控预警，在项目开始初期就引入监控，让整个团队实时能够收到关于产品各个维度数据的反馈</li>
<li>日志聚合，便于错误追踪和展示</li>
<li>分析，利用搜集到的数据实时分析，利用分析结果指导开发进度</li>
</ul>
<h3 id="度量与反馈"><a href="#度量与反馈" class="headerlink" title="度量与反馈"></a>度量与反馈</h3><p>通过对用户行为或业务指标的度量或反馈收集，为产品的决策提供依据。</p>
<p>主要实践包括：</p>
<ul>
<li>持续集成反馈，对代码构建质量，代码质量审查的反馈</li>
<li>测试反馈，对软件质量，功能性的测试，给到业务的反馈</li>
<li>运营数据反馈，新功能上线后对业务影响的反馈，用于指导业务人员提新的需求</li>
</ul>
<h3 id="环境管理"><a href="#环境管理" class="headerlink" title="环境管理"></a>环境管理</h3><p>通过对服务器环境的定义，自动化建立和配置、更新等提高基础设施管理的效率，一致性，并更有效利用资源，可伸缩的架构，保证服务的健壮性。</p>
<p>主要实践包括：</p>
<ul>
<li>弹性架构，保证服务的吞吐量和具备灵活变更的能力</li>
<li>自动化部署脚本，想胶水一样，用于解决一些工程实践不够完善的流程之间的衔接</li>
<li>基础设施即代码，用代码定义基础设施，便于环境管理，追踪变更，以及保证环境一致性</li>
</ul>
<h3 id="松耦合架构"><a href="#松耦合架构" class="headerlink" title="松耦合架构"></a>松耦合架构</h3><p>对传统应用架构进行领域组件化，服务化，提升可测试性和可部署性。</p>
<p>主要实践包括：</p>
<ul>
<li>采用弹性基础设施，比如公有云服务或是 PaaS（Platform as a Service） 平台</li>
<li>构建为服务应用</li>
<li>引入契约测试</li>
</ul>
<p><img src="/images/devops_full_picture.png" alt=""></p>
<center><strong>典型DevOps的持续交付流水线全景图</strong></center>

<p><img src="/images/devops_pipeline.png" alt=""></p>
<center><strong>软件开发全生命周期的持续优化</strong></center>

<h1 id="未来-amp-趋势"><a href="#未来-amp-趋势" class="headerlink" title="未来 &amp; 趋势"></a>未来 &amp; 趋势</h1><ul>
<li><p><strong>DevOps 话语权越来越多被平台厂商掌握</strong></p>
<p>​    在 DevOps 实践的第一阶段，往往会是 Jenkins, Nexus, Ansible, Shell 等一系列工具的拼凑组合，上手难度大，维护成本高，开发体验不好。随着 DevOps 日渐成熟，以 AWS、Pivotal、RedHat 为代表的一些公司分别退出自己的 “DevOps产品”，或是一套完整的工具链，或者直接整合到一个 PaaS 平台，甚至一些产品直接将“敏捷”，“精益”的概念也整合到产品中，直接可以把一家公司的全部业务放到平台上，这和最近大热的“数字化平台战略”也是相吻合的。</p>
<p>​    不管怎样，这些平台厂商一边卖自己的产品一边重新定义着 DevOps，随着平台的完善，DevOps 已经变得越来越不重要，我一直觉得最好的 DevOps  团队应该是“润物细无声”的，就是一个团队不用提 DevOps，整个团队很自然地就能关注到业务价值的交付，且能有序地按照高质量，高效率的要求去做，平台或许能帮助我们做到这一点。</p>
</li>
<li><p><strong>容器化 &amp;  微服务仍然是 DevOps 应用和发展的主要领域</strong></p>
<p>​    容器化、微服务天然适合小而全的功能团队，且一个个自治的服务也很复合 DevOps 端到端交付团队的设计，近年随着容器化技术（Docker）的发展，容器管理（Kubernetes）的日渐成熟（据悉，github 已经将它们的一部分产品环境灰度发布到了 kubernetes 上，京东也将他们的服务百分之六十采用了 kubernetes 管理），DevOps 和微服务成为了相辅相成的两个趋势。</p>
</li>
<li><p><strong>安全成为推动 DevOps 全面发展的重要力量</strong></p>
<p>​    安全是 DevOps 永远绕不开的话题，也往往是新技术在传统行业（例如金融和电信）应用中的最大阻碍。一方面，组织结构的转型迫使企业要打破原先的部门墙，这意味着很多原先的控制流程不再适用。另一方面，由于大量的 DevOps 技术来源于开源社区，缺乏强大技术实力的企业在应用相关技术时不免会有所担忧。</p>
<p>​    DevOps 全局优化的特点与安全社区提出的 “Build Security In”也特别吻合，加之越来越多安全易用的工具涌现，DevOpsSec 会越来越被人们熟知。</p>
</li>
</ul>
<blockquote>
<p>参考资料：</p>
<p><a href="http://insights.thoughtworkers.org/instantiate-the-principles-of-devops/" target="_blank" rel="external">http://insights.thoughtworkers.org/instantiate-the-principles-of-devops/</a></p>
<p><a href="http://www.jianshu.com/p/5781489e8431" target="_blank" rel="external">http://www.jianshu.com/p/5781489e8431</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本周六应邀参加了 &lt;a href=&quot;https://www.freecodecamp.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;FreeCodeCamp&lt;/a&gt;社区的一次线下活动，主题为《DevOps从理论到实践》，借此机会整理一下近年来看到
    
    </summary>
    
      <category term="DevOps" scheme="https://www.duyidong.com/categories/DevOps/"/>
    
    
      <category term="持续交付" scheme="https://www.duyidong.com/tags/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98/"/>
    
      <category term="DevOps" scheme="https://www.duyidong.com/tags/DevOps/"/>
    
      <category term="敏捷" scheme="https://www.duyidong.com/tags/%E6%95%8F%E6%8D%B7/"/>
    
      <category term="DevOps文化" scheme="https://www.duyidong.com/tags/DevOps%E6%96%87%E5%8C%96/"/>
    
      <category term="CALMS" scheme="https://www.duyidong.com/tags/CALMS/"/>
    
  </entry>
  
  <entry>
    <title>DevOps的三种方式</title>
    <link href="https://www.duyidong.com/2017/07/12/the-three-ways-understanding-devops/"/>
    <id>https://www.duyidong.com/2017/07/12/the-three-ways-understanding-devops/</id>
    <published>2017-07-12T14:50:38.000Z</published>
    <updated>2017-07-13T11:43:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文翻译自 <a href="https://itrevolution.com/author/gene-kim/" target="_blank" rel="external">Gene Kim</a> 的博客 <a href="http://itrevolution.com/the-three-ways-principles-underpinning-devops/" target="_blank" rel="external">The Three Ways: The Principles Underpinning DevOps</a></p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这篇博客中提到的“三种方式“源自 <a href="http://www.itrevolution.com/book/the-devops-handbook/" target="_blank" rel="external">《DevOps Handbook》</a> 及《凤凰项目》（<a href="https://itrevolution.com/books/novel/" target="_blank" rel="external">The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win.</a>），这三种方式描述了构成 DevOps 的理论框架、流程、实践及价值观和哲学。</p>
<p>感谢《Lean IT》的作者 Mike Orzen 为此文提供宝贵建议。</p>
<h1 id="三种方式"><a href="#三种方式" class="headerlink" title="三种方式"></a>三种方式</h1><p>下文将介绍三种模式及在该种模式指导下的 DevOps 实践。</p>
<h2 id="第一种方式：-系统思考"><a href="#第一种方式：-系统思考" class="headerlink" title="第一种方式： 系统思考"></a>第一种方式： 系统思考</h2><p><img src="https://itrevolution.com/wp-content/uploads/2012/08/first-way2-400x191.png" alt=""></p>
<p>第一种方式强调<strong>全局优化，而非局部改进</strong>。— 大到部门职能划分（例如研发部和运维部门），小到个人（开发和系统工程师）。</p>
<p>这种方式将关注点放在整个业务价值流上。换句话说，整个团队应该关注在从需求被定义到开发，再到运维这个过程，直到价值被以服务的形式交付给最终用户。</p>
<p>将这种方式带到实践中的产出便是永远不要将已知的缺陷传递到下游工作，永远不要为了局部优化影响了整体价值流交付，总是为了增加价值流动努力，永远追求对架构的深刻理解。</p>
<p>涉及到这种方式的实践有：</p>
<ul>
<li>所有环境和代码使用同一个仓库，将软件包纳入版本管理</li>
<li>团队共同决定发布流程</li>
<li>保持 DEV、TEST、PRODUCTION 环境的一致性</li>
<li>自动化回归测试</li>
<li>小步提交，每日部署；而不是一次部署大量变更</li>
<li>更快、更频繁发布</li>
</ul>
<h2 id="第二种方式：经过放大的反馈回路"><a href="#第二种方式：经过放大的反馈回路" class="headerlink" title="第二种方式：经过放大的反馈回路"></a>第二种方式：经过放大的反馈回路</h2><p><img src="https://itrevolution.com/wp-content/uploads/2012/08/second-way1-400x211.png" alt=""></p>
<p>第二种方式是<strong>创建从开发过程下游至上游的反馈环</strong>。几乎所有的流程改进都是为了从时间上缩短和从覆盖面上放大反馈循环，从而可以不断地进行必要的改正。</p>
<p>第二种方式的产出是关注到价值流中所有涉及到的用户，包括价值流内部和外部的，缩短和放大反馈回路，并且可以随时定位到需要改进的地方。</p>
<p>涉及到这种方式的实践有：</p>
<ul>
<li>代码审查及配置变更检查</li>
<li>有纪律的自动化测试，使许多同时的小型敏捷团队能够有效地工作</li>
<li>尽早设置监控预警</li>
<li>修复 bug 为团队最高优先级</li>
<li>团队成员之间高度互相信任</li>
<li>团队之间保持沟通和良好合作</li>
</ul>
<h2 id="第三种方式：持续做试验和学习的文化"><a href="#第三种方式：持续做试验和学习的文化" class="headerlink" title="第三种方式：持续做试验和学习的文化"></a>第三种方式：持续做试验和学习的文化</h2><p><img src="https://itrevolution.com/wp-content/uploads/2012/08/third-way-400x224.png" alt=""></p>
<p>第三种方式提倡<strong>持续做试验，承担风险、从失败中学习；通过反复实践来达到精通</strong>。</p>
<p>我们需要实验和冒着失败的风险，及时不断地尝试将我们置于一个危险的境地，我们要通过反复试错来掌握使我们远离危险的技能。</p>
<p>第三种方式的输出为为改善日常工作分配时间、奖励团队冒险精神，将错误人工引入系统以提高系统健壮性。</p>
<p>最具有代表性的就是 Netfilx 的 Chaos monkey ，Netflix 在他们的生产环境搭建一个服务用于定时随机关闭服务器，用以模拟服务器正常损坏或服务异常，他们的系统长期在这种环境下运行，“服务器故障”成为系统每日都要面临的问题，因此当服务器真的以外故障时不会对系统整体造成任何的影响。</p>
<h1 id="译者后记"><a href="#译者后记" class="headerlink" title="译者后记"></a>译者后记</h1><p>全局优化、快速反馈、鼓励失败。我们发现其实敏捷、精益、持续交付、DevOps中间有很多相似的东西。</p>
<blockquote>
<p>参考资料: <a href="https://es.slideshare.net/SonatypeCorp/devops-connect-josh-corman-and-gene-kim-discuss-devopssec" target="_blank" rel="external">https://es.slideshare.net/SonatypeCorp/devops-connect-josh-corman-and-gene-kim-discuss-devopssec</a></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文翻译自 &lt;a href=&quot;https://itrevolution.com/author/gene-kim/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Gene Kim&lt;/a&gt; 的博客 &lt;a href=&quot;http://itrevolution.co
    
    </summary>
    
      <category term="DevOps" scheme="https://www.duyidong.com/categories/DevOps/"/>
    
    
      <category term="DevOps" scheme="https://www.duyidong.com/tags/DevOps/"/>
    
      <category term="翻译" scheme="https://www.duyidong.com/tags/%E7%BF%BB%E8%AF%91/"/>
    
      <category term="理论框架" scheme="https://www.duyidong.com/tags/%E7%90%86%E8%AE%BA%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
  <entry>
    <title>如何制作在线幻灯片</title>
    <link href="https://www.duyidong.com/2017/06/20/reveal-js-quick-start/"/>
    <id>https://www.duyidong.com/2017/06/20/reveal-js-quick-start/</id>
    <published>2017-06-20T08:20:33.000Z</published>
    <updated>2017-06-20T09:17:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>都说不会做幻灯片的程序员不是好架构师，工作中有很多场合需要用到幻灯片。最近在准备一个对外分享，内容比较简单，顺手尝试了一下使用 <code>reveal js</code>制作一个在线幻灯片。</p>
<p>效果展示：<a href="https://cdn.rawgit.com/ADU-21/cd-in-cloud-reveal-js/784e1a49/index.html" target="_blank" rel="external">https://cdn.rawgit.com/ADU-21/cd-in-cloud-reveal-js/784e1a49/index.html</a></p>
<p>这个幻灯片中包含文本、图片、视频，下面我会逐一讲解是如何实现的。</p>
<h1 id="价值"><a href="#价值" class="headerlink" title="价值"></a>价值</h1><ul>
<li>解决微软的 PowerPoint 和 Mac keynote 跨平台不兼容问题</li>
<li>传统幻灯片需要拷来拷去，在线幻灯片只需要一个 URL 就可以访问，避免忘带 U 盘的尴尬</li>
<li>在线幻灯片本质上是 html 文件，也可以在无网络环境播放</li>
</ul>
<h1 id="用到的资源"><a href="#用到的资源" class="headerlink" title="用到的资源"></a>用到的资源</h1><ul>
<li><a href="http://lab.hakim.se/reveal-js/#/" target="_blank" rel="external">reveal js</a> ：将幻灯片文本内容渲染为 html</li>
<li><a href="https://github.com/" target="_blank" rel="external">github</a> : 用于存放幻灯片文件</li>
<li><a href="http://rawgit.com/" target="_blank" rel="external">rawgit</a> : 将 GitHub 中的 html 正常加载，并添加 CDN </li>
</ul>
<h1 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h1><h2 id="第一步：-Fork-官方-Repo"><a href="#第一步：-Fork-官方-Repo" class="headerlink" title="第一步： Fork 官方 Repo"></a>第一步： Fork 官方 Repo</h2><p>前往<a href="https://github.com/hakimel/reveal.js" target="_blank" rel="external">https://github.com/hakimel/reveal.js</a> 点击 <code>fork</code>将代码复制到自己账号下。</p>
<pre><code>git clone https://github.com/&lt;you account id&gt;/reveal.js
</code></pre><p>这时你就得到了一个可运行的 reveal js 模板，运行根目录下的 index.html 即可预览。</p>
<p><a href="https://github.com/hakimel/reveal.js/blob/master/README.md" target="_blank" rel="external">README</a> 中提供了很多配置编辑的方式，你要是没耐心看就跟着我继续吧。</p>
<h2 id="第二步：-编辑-index-html"><a href="#第二步：-编辑-index-html" class="headerlink" title="第二步： 编辑 index.html"></a>第二步： 编辑 index.html</h2><p>找到<code>&lt;div class=&quot;slides&quot;&gt;</code> ，这里是幻灯片正文的开始，在这个标签中添加如下代码，开启 <code>markdown</code>编辑模式：</p>
<pre><code>&lt;section data-markdown data-separator=&quot;---&quot; data-separator-vertical=&quot;--&quot;&gt;
    &lt;script type=&quot;text/template&quot;&gt;
    ### 正文在此
    &lt;/script&gt;
&lt;/section&gt;
</code></pre><p>现在你可使用 markdown 语法开始编辑幻灯片内容了。</p>
<h3 id="基本编辑方式"><a href="#基本编辑方式" class="headerlink" title="基本编辑方式"></a>基本编辑方式</h3><p><code>---</code> 表示横向分页。</p>
<p><code>--</code> 表示竖向分页，通常一列可以作为一个章节。</p>
<p><code># 标题</code> <code>- 列表</code></p>
<h3 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h3><p>插入图片有两种方式，基本的插入 markdown 语法就可以支持：</p>
<p><code>![](https://hostname.com/image.png)</code> 外部引用。</p>
<p>考虑到一些时候我们需要在无网络的情况下播放 幻灯片，所以通常还是将图片保存到本地再添加。</p>
<p><code>![](images/image.png)</code> 这种方式需要在根目录下创建一个叫 image 的文件夹，把图片放入其中命名为 imag.png。</p>
<p>如果要对图片又更复杂的支持，比如调整长宽，则需要写 html 代码，如：</p>
<p><code>&lt;img src=&quot;images/image.jpg&quot; alt=&quot;&quot; width=&quot;500px&quot;&gt;</code></p>
<h3 id="插入视频"><a href="#插入视频" class="headerlink" title="插入视频"></a>插入视频</h3><p>以 youtube 视频为例，首先使用 youtube-dl 下载视频：</p>
<pre><code>brew install youtube-dl                     # 安装 youtube-dl
youtube-dl https://www.youtube.com/watch?v=oHg5SJYRHA0
</code></pre><p>下载视频默认格式为 webm 格式，这是一种支持 HTML5 的视频文件格式，可以使用浏览器打开，将视频添加到幻灯片中：</p>
<pre><code>&lt;section data-background-video=&quot;your_video_name.webm&quot;&gt;
</code></pre><p>幻灯片 播放到这一页的时候就会开始自动播放视频。</p>
<h2 id="第三步：-对外访问"><a href="#第三步：-对外访问" class="headerlink" title="第三步： 对外访问"></a>第三步： 对外访问</h2><p>将编辑好后的 reveal js 这个项目提交到 GitHub 上：</p>
<pre><code>git add .
git commit -m &quot;add my slides&quot;
git push origin master
</code></pre><p>从网页访问你的 repo，以示例中的幻灯片为例： <a href="https://github.com/ADU-21/cd-in-cloud-reveal-js/blob/master/index.html" target="_blank" rel="external">https://github.com/ADU-21/cd-in-cloud-reveal-js/blob/master/index.html</a> ，我们发现幻灯片并没有被正常渲染，而是以源代码的方式展示。这个时候就需要用到第三方工具将 github 代码库中的 html 文件按照期望的方式对外暴露使其访问，具体操作：</p>
<ul>
<li>打开 <a href="http://rawgit.com/" target="_blank" rel="external">http://rawgit.com/</a></li>
<li>在中间的输入框输入 <code>https://github.com/&lt;your github id&gt;/cd-in-cloud-reveal-js/blob/master/index.html</code></li>
<li>得到 <code>production url</code> 和 <code>development url</code>两个链接</li>
</ul>
<p>Production url 是带有 CDN 的，和 github 的同步会存在一定的延迟， developement url 的更新会及时一些，不过访问速度相对会没那么快。</p>
<p>现在访问生成的 URL，你的在线幻灯片就已经制作完毕。</p>
<p>以上，不一定是最佳实践，不过经笔者亲测，行之有效。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;都说不会做幻灯片的程序员不是好架构师，工作中有很多场合需要用到幻灯片。最近在准备一个对外分享，内容比较简单，顺手尝试了一下使用 &lt;code&gt;reveal js&lt;/code&gt;制作一个在线幻灯片。&lt;/p&gt;
&lt;p&gt;效果展示：&lt;a href=&quot;https://cdn.rawgit.
    
    </summary>
    
      <category term="工具" scheme="https://www.duyidong.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="https://www.duyidong.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="reveal js" scheme="https://www.duyidong.com/tags/reveal-js/"/>
    
      <category term="在线幻灯片" scheme="https://www.duyidong.com/tags/%E5%9C%A8%E7%BA%BF%E5%B9%BB%E7%81%AF%E7%89%87/"/>
    
  </entry>
  
  <entry>
    <title>PaaS 平台（三）-- Openshift 使用</title>
    <link href="https://www.duyidong.com/2017/06/15/openshift-quick-start/"/>
    <id>https://www.duyidong.com/2017/06/15/openshift-quick-start/</id>
    <published>2017-06-15T10:27:41.000Z</published>
    <updated>2017-07-10T10:38:03.000Z</updated>
    
    <content type="html"><![CDATA[<p>Openshift 是一个基于 Kubernetes 和 Docker 的 PaaS 平台。</p>
<h1 id="Openshift-概念补充"><a href="#Openshift-概念补充" class="headerlink" title="Openshift 概念补充"></a>Openshift 概念补充</h1><p>我们在上文–<a href="https://www.duyidong.com/2017/06/15/kubernetes-infrastructure/">Kubernetes 介绍</a>中已经提到 Kubernetes 引入了一些概念，Openshift 在此基础之上又对这些概念进行了封装。了解 Openshift 除了了解它的架构以外，还要了解他抽象出来的概念。</p>
<ul>
<li><strong>ImageStream:</strong> 对 Docker Image 的抽象，Docker image 只是一个二进制文件实体，而 ImageStream 可以带有状态，可以对外部程序的访问做出相应。</li>
<li><strong>BuildConfig:</strong> 对 Dockerfile 的抽象，上文已经说到 Openshift 中的 Pod 实际上是由多个 Container 构成的，这些 Conatainer 仍然是运行时的 Image，这些 Image 的构建过程就是由 BuildConfig 决定的，不同于 Dockerfile，BuildConfig 可以支持将 gitrepo, Dockerfile, Binary, Image, Input Secrite(Openshift 定义的另一种资源类型，用于存储敏感信息), 二进制软件包，这些资源类型统统打到一个 ImageStream 里面，在“构建”这个动作的上下游还支持事件触发，比如定义“gitrepo的提交会触发一次构建”，以及“在构建完成后执行一次测试”。</li>
<li><strong>DeploymentConfig:</strong> 对 Replication Controller 的封装，定义了应用的运行时架构。</li>
<li><strong>Route:</strong> Kubernetes 定义了 Service 用于实现服务之间的隔离和调用，Openshift 在此之上增加了一层 Route，至此 Service 可以面向内网环境，而由 Route 来真正对外提供服务。</li>
</ul>
<p>将以上流程串起来，在 Openshift 上一个应用的诞生就应该是如下流程：</p>
<p><img src="/images/openshift_deploy_process.png" alt=""></p>
<p>熟悉了 Openshift 的基本概念，下面我们可以动手搭建一个 Openshift Origin 版，并在上面部署一个应用。</p>
<h1 id="Openshift-安装"><a href="#Openshift-安装" class="headerlink" title="Openshift 安装"></a>Openshift 安装</h1><p>这里安装的是 Openshift 社区版，官方也有提供 minishift（需要使用虚拟机）以及 Container 的方式安装，这里使用的方法是用 oc (openshift-cli)，是最简单，也是官方现在推荐的安装方式。<br>安装环境可以选择在 Mac 上或者是云虚拟机（Windows 不确定是否支持），我这里选择的是 AWS EC2，关于其他平台的安装，具体可参照<a href="https://github.com/openshift/origin/blob/master/docs/cluster_up_down.md" target="_blank" rel="external">https://github.com/openshift/origin/blob/master/docs/cluster_up_down.md</a></p>
<h2 id="第一步：在亚马逊上申请一个-Ubuntu-的机器"><a href="#第一步：在亚马逊上申请一个-Ubuntu-的机器" class="headerlink" title="第一步：在亚马逊上申请一个 Ubuntu 的机器"></a>第一步：在亚马逊上申请一个 Ubuntu 的机器</h2><p>有几个要注意的地方：</p>
<ul>
<li>CentOS 的 Dcoker 安装可能会遇到一些问题，是由于 Docker 社区版不支持，详见<a href="https://docs.docker.com/engine/installation/" target="_blank" rel="external">这里</a>。</li>
<li>如果你想实现 hook 功能，即看到代码提交触发 Openshift 内构建的效果，你需要赋予 Instance 一个公网 IP。</li>
<li>安全组开启外部可访问 8443 端口。</li>
</ul>
<h2 id="第二步：安装-Docker"><a href="#第二步：安装-Docker" class="headerlink" title="第二步：安装 Docker"></a>第二步：安装 Docker</h2><p>这里要说明的是现有 Openshift 在 docker 的最高版本下支持有些问题，经测试 1.12.1版本是稳定的。<br>安装脚本：</p>
<pre><code># Install Docker on Xenial 16.04.1 x64
# Ref https://docs.docker.com/engine/installation/linux/ubuntulinux/
# No interactive for now.
export DEBIAN_FRONTEND=noninteractive
# Update your APT package index.
sudo apt-get -y update
# Update package information, ensure that APT works with the https method, and that CA certificates are installed.
sudo apt-get -y install apt-transport-https ca-certificates
# Add the new GPG key.
sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D
# Add docker.list
sudo echo &quot;deb https://apt.dockerproject.org/repo ubuntu-xenial experimental&quot; &gt; /etc/apt/sources.list.d/docker.list
# Update your APT package index.
sudo apt-get -y update
# Purge the old repo if it exists.
sudo apt-get purge lxc-docker
# Verify that APT is pulling from the right repository.
sudo apt-cache policy docker-engine
# Install the recommended package.
sudo apt-get -y install linux-image-extra-$(uname -r)
# Install Docker.
sudo apt-get -y install docker-engine=1.12.1-0~xenial --allow-downgrades
# Start the docker daemon.
sudo service docker start
# Validate docker version
docker -v
</code></pre><p>执行最后一条命令，出现 Dokcer 版本为 1.12.1 表示安装成功。</p>
<h2 id="第三步：配置-Dokcer-registry"><a href="#第三步：配置-Dokcer-registry" class="headerlink" title="第三步：配置 Dokcer registry"></a>第三步：配置 Dokcer registry</h2><p>编辑<code>/etc/systemd/system/multi-user.target.wants/docker.service</code> docker 的 service 文件，将<code>ExecStart=/usr/bin/dockerd -H fd://</code>这一行，替换为 <code>ExecStart=/usr/bin/dockerd --insecure-registry 172.30.0.0/16 -H fd://</code>，然后执行<code>systemctl reload-daemon docker</code>，<code>systemctl restart docker</code></p>
<h2 id="第四步：下载、启动-Openshift"><a href="#第四步：下载、启动-Openshift" class="headerlink" title="第四步：下载、启动 Openshift"></a>第四步：下载、启动 Openshift</h2><p>在服务器上下载<a href="https://github.com/openshift/origin/releases/download/v3.6.0-alpha.2/openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-linux-64bit.tar.gz" target="_blank" rel="external">openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-linux-64bit.tar.gz</a>oc 客户端，解压后把 oc 所在路径加入环境变量，执行：</p>
<pre><code>oc cluster up \
--public-hostname=ec2-13-228-41-255.ap-southeast-1.compute.amazonaws.com \
--routing-suffix=13.228.41.255.xip.io
</code></pre><p>把以上命令中数字替换为你的 Instance 的公网 IP，即可启动一个外部可访问，应用也可以被外部访问的 Openshift 集群。</p>
<p><code>oc login system:admin</code>可以以管理员权限登录<br><code>oc login https://ec2-13-228-41-255.ap-southeast-1.compute.amazonaws.com:8443</code>可以以任意用户名密码登录<br>也可以直接访问 <a href="https://ec2-13-228-41-255.ap-southeast-1.compute.amazonaws.com:8443" target="_blank" rel="external">https://ec2-13-228-41-255.ap-southeast-1.compute.amazonaws.com:8443</a> 进行网页操作。</p>
<p>至此，Openshift 的安装全部完成。</p>
<h1 id="部署一个应用到-Openshift-上"><a href="#部署一个应用到-Openshift-上" class="headerlink" title="部署一个应用到 Openshift 上"></a>部署一个应用到 Openshift 上</h1><p>这一部分内容来自于 workshop，完整版可参照<a href="https://github.com/ADU-21/openshift-workshop" target="_blank" rel="external">https://github.com/ADU-21/openshift-workshop</a></p>
<h2 id="在本地安装-openshift-客户端"><a href="#在本地安装-openshift-客户端" class="headerlink" title="在本地安装 openshift 客户端"></a>在本地安装 openshift 客户端</h2><p>Mac 版：<a href="https://github.com/openshift/origin/releases/download/v3.6.0-alpha.2/openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-mac.zip" target="_blank" rel="external">openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-mac.zip</a><br>Windows 版： <a href="https://github.com/openshift/origin/releases/download/v3.6.0-alpha.2/openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-windows.zip" target="_blank" rel="external">openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-windows.zip</a><br>Linux 版：<a href="https://github.com/openshift/origin/releases/download/v3.6.0-alpha.2/openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-linux-64bit.tar.gz" target="_blank" rel="external">openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-linux-64bit.tar.gz</a></p>
<p>下载到本地之后解压，将一个名为 oc 的可执行文件路径放到 PATH 环境变量里，确保随处可执行。然后执行： <code>oc login https://ec2-13-228-41-255.ap-southeast-1.compute.amazonaws.com:8443</code>，输入任意用户名密码即可登录。</p>
<h2 id="部署一个应用"><a href="#部署一个应用" class="headerlink" title="部署一个应用"></a>部署一个应用</h2><p><strong>1</strong> 创建一个项目</p>
<pre><code>oc new-project [project name]
</code></pre><p>Project 的作用是对 Openshift 的集群中的资源进行隔离。</p>
<p><strong>2</strong> 将一个<a href="https://github.com/openshift/nodejs-ex" target="_blank" rel="external">官方例子</a> fork 到自己的账户下，并克隆到本地：</p>
<pre><code>git clone https://github.com/&lt;your-github-name&gt;/nodejs-ex.git
</code></pre><p>这里包含了项目所需代码，是一个 NodeJS 的应用，稍后我们将把这个应用部署到 Openshift 上。</p>
<p><strong>3</strong> 创建一个应用</p>
<pre><code>oc new-app https://github.com/&lt;your-github-name&gt;/nodejs-ex.git
</code></pre><p>执行这一步命令，Openshift 会自动去查找 repo，根据代码的一些特征（比如<code>package.json</code>）识别这个项目类型，准备响应环境，可以通过<code>watch oc get all</code>的命令看到 openshift 实时创建了哪些资源，按逻辑顺序如下：</p>
<ul>
<li>bc: BuildConfig Openshift - 会先创建一个用于 Build image 的环境，然后创建一个叫做 Build 的对象，这个对象的实体是一个 Pod，在这个 Pod 中完成 Image 的构建</li>
<li>is: ImageStream - 用于管理 Image 的资源对象</li>
<li>bc: DeploymentConfig - 会创建一个 rc (Replication Controller)资源，又 rc 再去创建承载应用的 Pod</li>
<li>svc: Service - Pod 的负载均衡器，与 Kubernetes 中提到的 Service 相同</li>
<li>Pod: 除了提供运行环境的 Pod，这里还有 Build Pod(构建完成之后还会存在，可以用于查看 log)，Deploy Pod(部署完成后会被销毁)</li>
</ul>
<p>经历以上步骤，一个应用就已经在 Openshift 集群中被创建出来了。</p>
<p><strong>4</strong> 创建 route</p>
<pre><code>oc expose svc/nodejs-ex
</code></pre><p>得到执行成功的提示后，执行<code>oc get route</code>，就可以用返回的地址访问你的应用了。<br>这个时候你会看到在<code>oc get all</code>命令中看到有叫做<code>route</code>的资源被创建了。</p>
<p><strong>5</strong> 清理资源</p>
<p>可以看到我们创建的资源都是被打上了 label 的，可以用<code>oc get all --show-labels=true</code>查看，删除资源也可以使用标签<code>oc delete all -l app=nodejs-example</code>，更粗暴的方式是直接删除整个 project，所有资源都会被清理掉：<code>oc delete project &lt;project name&gt;</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Openshift 是一个基于 Kubernetes 和 Docker 的 PaaS 平台。&lt;/p&gt;
&lt;h1 id=&quot;Openshift-概念补充&quot;&gt;&lt;a href=&quot;#Openshift-概念补充&quot; class=&quot;headerlink&quot; title=&quot;Openshift 
    
    </summary>
    
      <category term="Cloud" scheme="https://www.duyidong.com/categories/Cloud/"/>
    
    
      <category term="DevOps" scheme="https://www.duyidong.com/tags/DevOps/"/>
    
      <category term="PaaS" scheme="https://www.duyidong.com/tags/PaaS/"/>
    
      <category term="Openshift" scheme="https://www.duyidong.com/tags/Openshift/"/>
    
      <category term="Kubernetes" scheme="https://www.duyidong.com/tags/Kubernetes/"/>
    
      <category term="平台即服务" scheme="https://www.duyidong.com/tags/%E5%B9%B3%E5%8F%B0%E5%8D%B3%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>PaaS 平台（二） -- Kubernetes 介绍</title>
    <link href="https://www.duyidong.com/2017/06/15/kubernetes-infrastructure/"/>
    <id>https://www.duyidong.com/2017/06/15/kubernetes-infrastructure/</id>
    <published>2017-06-15T01:38:41.000Z</published>
    <updated>2017-06-15T07:10:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes 的很多概念和架构“代表了谷歌过去十余年设计、构建和管理大规模容器集群经验”。</p>
<h1 id="Kubernetes-概念引入"><a href="#Kubernetes-概念引入" class="headerlink" title="Kubernetes 概念引入"></a>Kubernetes 概念引入</h1><p>Kubernetes 基于容器引入了许多重要的概念，了解这些概念有助于认知 Kubernetes 是如何工作的。<br>以下介绍均为 Kubernetes 中被定义的资源，Kubernetes 架构按照 Restful 架构设计，及遵循：</p>
<ul>
<li>网络上的所有事物都被抽象为资源</li>
<li>每个资源对应一个唯一的资源标识符</li>
<li>通过通用的连接器接口对资源进行操作</li>
<li>对资源的各种操作不会改变资源标识符</li>
<li>所有操作都是无状态的</li>
<li>REST是基于HTTP的</li>
</ul>
<p>PS：REST之所以可以提高系统的可伸缩性，就是因为他要求所有的操作都是无状态的。</p>
<h2 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h2><p><img src="/images/kubernetes_pod.png" alt=""></p>
<h3 id="名词释义"><a href="#名词释义" class="headerlink" title="名词释义"></a>名词释义</h3><p>Pod 意为豆荚，内涵多个共享网络和存储的容器，作为被Replication Controller, Label, Service操作的逻辑对象，是Kubernetes里能被创建、调度和管理的最小部署单元。可以想象成一个用于装 Container 的篮子：</p>
<ul>
<li>一个 Pod 里能装多少资源取决于篮子的大小</li>
<li>Label 是贴在篮子上的</li>
<li>IP 分配给篮子而不是容器，篮子里的所有容器共享这个 IP</li>
<li>哪怕只有一个容器，Kubernetes仍然会给它分配一个 Pod，Pod里的Container数量也可以为零</li>
<li>Pod 的运行状态：Pending、Running、Succeeded、Failed</li>
</ul>
<p>Pod中的容器共享了IP及其对应的namespace, Volume；从 Linux 的 namespace 的角度看，Pod 里的容器还共享了 PID, IPC(信号量、消息队列、共享内存)，UTS(主机名与域名) namespace<br>Pod 是为了解决“如何合理使用容器支撑企业级复杂应用”的问题而诞生的，Kubernetes 的设计理念是为了支持绝大多数应用的原生形态，而不是大谈特谈“轻应用”和“十二要素应用”；Pod 对于 Kubernetes 来说最有用的价值就是“原子化调度”，即在为一个 Pod 选择目的宿主机时，Kubernetes 会先考量这个机器是否能放下整个 Pod，而避免出现本应该部署在一起的容器因为资源不足无法满足“超亲密关系”的尴尬。<br>Pod 里面包含一个网络容器先于其他所有容器创建，拥有该 Pod 的 namespace。<br>用户可以使用 <code>rsh</code> 命令登录到一个 Pod 里，原理是在 Pod 里创建了一个 bash Container。</p>
<h3 id="Pod-是如何被定义的"><a href="#Pod-是如何被定义的" class="headerlink" title="Pod 是如何被定义的"></a>Pod 是如何被定义的</h3><p>我们来看 Openshift 的一个 template 是如何描述一个 Pod 对象的：</p>
<pre><code class="yaml"># Kuberntes 是按照 Restful 标准设计，所以你能在每个资源对象中看到 API Version
apiVersion: v1      
# 申明一个 Pod 类型                      
kind: Pod                                 
metadata:
  # 具有严格命名规范的注释，包含版本号，资源url，团队名等
  annotations: { ... }
  # 每个 Pod 需绑定一个或多个 Tag，方便 Replication Controller 和 Service 对 Pod 进行调度和管理
  labels:                                 
    deployment: docker-registry-1
    deploymentconfig: docker-registry
    docker-registry: default
  generateName: docker-registry-1-       
spec:
  # 下面是对 Pod 中 Container 的定义，Containers 为一个列表，可以配置不同类型的多个 Contianer
  containers:
    # Container 中被注入的环境变量                            
  - env:                                 
    - name: OPENSHIFT_CA_DATA
      value: ...
    - name: OPENSHIFT_CERT_DATA
      value: ...
    - name: OPENSHIFT_INSECURE
      value: &quot;false&quot;
    - name: OPENSHIFT_KEY_DATA
      value: ...
    - name: OPENSHIFT_MASTER
      value: https://master.example.com:8443
    # Container 由哪个 image 启动
    image: openshift/origin-docker-registry:v0.6.2 
    imagePullPolicy: IfNotPresent
    name: registry
    ports:
    # 决定了 Pod 暴露出来的端口                              
    - containerPort: 5000
      protocol: TCP
    resources: {}
    securityContext: { ... }      
    # 决定了将被挂载到 Pod 里的外部存储设备挂载到 Container 的哪一个路径      
    volumeMounts:                       
    - mountPath: /registry
      name: registry-storage
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: default-token-br6yz
      readOnly: true
  dnsPolicy: ClusterFirst
  imagePullSecrets:
  - name: default-dockercfg-at06w
  restartPolicy: Always
  serviceAccount: default               
  # 将外部存储设备挂在到 Pod 中，此处为一个临时存储，和一个加密存储
  volumes:                              
  - emptyDir: {}
    name: registry-storage
  - name: default-token-br6yz
    secret:
      secretName: default-token-br6yz
</code></pre>
<h3 id="关于-Volume"><a href="#关于-Volume" class="headerlink" title="关于 Volume"></a>关于 Volume</h3><p>Volume 是 Pod 中能被多个容器访问的共享目录，生命周期和 Pod 相同，如果有数据持久化考虑，如数据库的数据 Volume，通常需要调用云基础设施的持久化存储服务，如 AWS 的 EBS，EFS 等。</p>
<ul>
<li>EmptyDir: 在 Pod 被分配到 Node 时创建，初始内容为空，Pod 被移除时 EmptyDir 中的数据也会永久删除；常用于临时共享目录</li>
<li>hostPath: 在 Pod 上挂载宿主机上的文件或目录；使用时要注意 Pod 会在不同 Node 上漂移的问题，可以用在比如 Redis 集群的数据卷</li>
<li>NFS</li>
<li>EBS 创建一个 EBS Volume，直接挂载到 Pod 里</li>
<li>gitRepo: 挂载一个空目录，并下载一个 git repository</li>
<li>…</li>
</ul>
<h3 id="关于-Label-和-Label-Selector"><a href="#关于-Label-和-Label-Selector" class="headerlink" title="关于 Label 和 Label Selector"></a>关于 Label 和 Label Selector</h3><p><img src="/images/kubernetes_label.png" alt=""></p>
<p><strong>Label：</strong>Replication Controller 和 Service 通过 Label 对 Pod 进行选择和调度，Kubernetes 引入 Label 主要是为了面向用户，包含对象功能性和特征性描述的 Label 比对象名和 UUID 更加用户友好和有意义，而且使用户可以以一种松耦合的方式实现自身组织结构到系统对象之间的映射，无需客户端存储这些映射关系。</p>
<p><strong>Label Selector：</strong>是 Kubernetes 核心的分组机制，用于让客户端识别一组有共同特征或属性的 Kubernetes 对象，这一特性促进了扁平化、多维度的服务组织和部署架构，这对集群管理（譬如配置和部署）和应用的自我检查分析（日志监控预警分析）非常有用。Label Selector 除了严格匹配还支持类似于 SQL WHERE 语句的查询。</p>
<h2 id="Replication-Controller"><a href="#Replication-Controller" class="headerlink" title="Replication Controller"></a>Replication Controller</h2><p><img src="/images/kubernetes_rc.png" alt=""></p>
<h3 id="名词释义-1"><a href="#名词释义-1" class="headerlink" title="名词释义"></a>名词释义</h3><p>Replication Controller 的作用是决定一个Pod在运行时同时有多少个副本，类似于 AWS 的 Auto Scaling Group，方法是在每一个 Pod 外挂了一个控制器进程，与 Pod 相互独立，避免造成性能瓶颈或挂掉影响 Pod。<br>Replication Controller 是 Kubernetes 为了解决“如何构造完全同质的 Pod 副本”的问题而引入的资源对象。其配置文件由三部分组成：一个用于创建 Pod 的 template，一个期望的副本数，和一个用于选择被控制的 Pod 集合的 Label Selector。Replication Controller 会不断地监测控制的 Pod 集合数量并与期望的副本数量进行比较，根据实际情况进行创建和删除 Pod 操作。<br>功能：弹性伸缩，灰度发布（需要两个 Replication Controller ）。</p>
<h3 id="Replication-Controller-是如何被定义的"><a href="#Replication-Controller-是如何被定义的" class="headerlink" title="Replication Controller 是如何被定义的"></a>Replication Controller 是如何被定义的</h3><p>同样我们来看一个 Replication Controller 的配置文件：</p>
<pre><code class="yaml">apiVersion: v1
kind: ReplicationController
metadata:
  name: frontend-1
spec:
  # 描述这个 rc 中期望的同质 Container 的数量
  replicas: 1  
  # Label Selecter 用于匹配期望的 Pod，以及给新创建的 Pod 打上标签
  selector:    
    name: frontend
  # 模板，用于定义 Pod
  template:    
    metadata:
      labels:  
        name: frontend 
    spec:
      containers:
      - image: openshift/hello-openshift
        name: helloworld
        ports:
        - containerPort: 8080
          protocol: TCP
      restartPolicy: Always
</code></pre>
<h2 id="Service"><a href="#Service" class="headerlink" title="Service"></a>Service</h2><p><img src="/images/kubernetes_service.png" alt=""></p>
<h3 id="名词释义-2"><a href="#名词释义-2" class="headerlink" title="名词释义"></a>名词释义</h3><p>由于重新调度等原因，Pod 在 Kubernetes 里的 IP 并不是固定的，因此需要一个代理来确保需要使用 Pod 的应用不需要知道 Pod 的真实 IP 地址，同时 Service 还为多个 Pod 副本提供负载均衡，可以类比 AWS 中的 ELB。<br>Service 由两部分构成，一个与 Service 生命周期相同的 IP 地址，和一个 Label selector；另外还需要配置转发端口 ，Service 对象创建后系统会创建一个同名 Endpoints 对象用于保存匹配 Label selector 后端 Pod 的 IP 地址和端口。<br>Service 可以置空 Label selector 用于代理非 Pod，或得不到 Label 资源的（遗留）系统。方法：通过在 Service 里定义端口转发，再在 Endpoints 中自定义IP和端口。<br>Service 提供外部访问服务有三种形式，利用 Kubernetest 集群 IP 池（由 Administrator 配置）；利用宿主机（Node）的 IP 和端口；利用 LoadBalancer(如 AWS 的 ELB)。<br>另外，Service 是支持黏滞会话的。</p>
<h3 id="Service-是如何被定义的"><a href="#Service-是如何被定义的" class="headerlink" title="Service 是如何被定义的"></a>Service 是如何被定义的</h3><p>来看一个 Service 的配置文件：</p>
<pre><code class="yaml">apiVersion: v1
kind: Service
metadata:
  name: docker-registry      
spec:
  # Label Selector
  selector:                  
    docker-registry: default
  # Endpoint，可以用于代理内部/外部资源（需使用 ”ExternalIPs“）
  portalIP: 172.30.136.123   
  ports:
  - nodePort: 0
    port: 5000               
    protocol: TCP
    targetPort: 5000
</code></pre>
<h3 id="Service-Proxy"><a href="#Service-Proxy" class="headerlink" title="Service Proxy"></a>Service Proxy</h3><p>Service Proxy（Kube-proxy）负责在 Service 建立的时候在宿主机上随机监听端口并建立 Iptable 规则进行转发，同时 Kube-proxy 还会实时监测 Kubernetes 的 Master 节点上的 etcd 中 Service 和 Endpoints 对象的增加和删除信息，从而保证和后端 Pod 的 IP 和端口变化保持一致更新。<br>Service discovering：环境变量（ Pod 创建时被注入所有可用 Service 环境变量形如 XXX_SERVICE_HOST=10.0.0.1）或通过 DNS（skyDNS服务器），调用 Kubernetes 的 WatchAPI, 不间断地监测新 Service 的创建并未每个 Service 新建一个 DNS 记录，在整个集群范围可用，在同 namespace 下的 Service 通过二级域名(Myservice)访问该 Service, 不同 namespace 下则可通过 my service.mynamespace 的方式访问到。DNS 的方式因为存在 TTL 导致服务 DNS 记录更新不及时而存在争议。<br>对于一部分要求外网可访问的 Service，可以通过 createExternalLoadBalancer=true（利用IaaS平台）或者维护一个 PublicIPs 池，利用 Kube-proxy 转发的方式实现。</p>
<h3 id="健康检查"><a href="#健康检查" class="headerlink" title="健康检查"></a>健康检查</h3><p>既然 Service 可以路由，必然也有对 Pod 进行健康检查的功能：</p>
<ul>
<li>进程级别由 Kubelete 通过 Docker daemon 获取所有 Docker 进程的运行状态，如果某容器进程未正常运行则重启。</li>
<li>应用级别由Kubelete在容器内执行活性探针（liveness probe），支持 HTTP get, Container exec, TCP Socket 三种检查方式，默认情况确认失败会删除 Pod, 另外还有一个可选项是 readiness probe，即仅移除 Endpoint，这样保留Pod可以用于错误重现。</li>
</ul>
<h2 id="Pod-RC-Service"><a href="#Pod-RC-Service" class="headerlink" title="Pod + RC + Service"></a>Pod + RC + Service</h2><p>上面提到的 Pod，Replication Controller，Service 三种资源构成了 Kubernetes 集群中最常见的一种应用架构，如下图所示。</p>
<p><img src="/images/pod_rc_service.png" alt=""></p>
<p>这个架构是不是很熟悉？没错，他和 AWS 里 Instance + Autoscaling Group + ELB 的架构是样的，如果你你对 AWS 的服务熟悉的话，可以据此来理解应用在 Kubernetes 里的架构：</p>
<ul>
<li><strong>Pods</strong> - Instances</li>
<li><strong>Replication Controllers</strong> - Auto Scaling</li>
<li><strong>Services</strong> - Elastic Load Balancing</li>
<li>Nodes - Availability Zone</li>
</ul>
<h1 id="Kubernetes-架构"><a href="#Kubernetes-架构" class="headerlink" title="Kubernetes 架构"></a>Kubernetes 架构</h1><p>Kubernetes 的架构如下图所示，对于学习 Openshift 这部分内容仅作兴趣了解即可，PaaS 平台的存在就是为了屏蔽掉这些底层细节。</p>
<p><img src="/images/kubernetes_infrastruacture.png" alt=""></p>
<h2 id="APIServer"><a href="#APIServer" class="headerlink" title="APIServer:"></a>APIServer:</h2><p>运行在 Master 节点，对外作为系统管理指令的统一入口，任何对资源进行的增删改查都要交给 APIServer 处理后才能提交给 etcd。（etcd 是一个键值对数据库，是 APIServer 的唯一持久化节点）</p>
<p>API Server 分为只读端口（Kubernetes-ro service, port:7080）和读写端口(Kubernetes service port:6443)，基于 etcd 实现了一整套 RESTful API 用于操作存储在 etcd 中的 Kubernetes 对象实例，APIServer 借助一个被称为 registry 的实体来完成对etcd的所有操作。</p>
<h2 id="Scheduler"><a href="#Scheduler" class="headerlink" title="Scheduler"></a>Scheduler</h2><p>根据特定的调度算法将 pod 调度到指定的 Node(早期也被叫做minion） 上，也叫绑定。<br>工作节点描述方式：期望状态（由 Json 描述），当前状态，包括：HostIP，Node Phase（Pending, Running, Terminated）, Node Condition(NodeReady)，由 controller manager 下属的 node controller 循环检查 Node 中的 minion 进程获得。</p>
<p>调度算法：Predicates（能不能-端口是否冲突、资源是否够用、Volume 是否有冲突、NodeSelector 是否选中（label selector的一种）、HostName 指定 Node）; Priorities（资源占用比小、Pod数量少、平等对待每个 Node (默认情况不使用)）</p>
<h2 id="Controller-manager"><a href="#Controller-manager" class="headerlink" title="Controller manager"></a>Controller manager</h2><p>运行在 master 上的一个基于 Pod API 的独立服务，重点实现了 service endpoint 的动态更新，管理 kubernetes 集群中的各种控制器（replication controller, node controller,..），用于确保资源保持在预期状态。</p>
<ul>
<li><strong>Replication controller:</strong>每五秒执行一次检查，将返回的健康pod数量和描述文件中定义的数量做个 diff，再根据结果调用 APIServer 执行新建或删除</li>
<li><strong>Service endpoint controller:</strong> 每十秒执行一次检查，遍历集群中所有 namespace 下 service 对象，取到 service 的 label selector 获取 service 对应的后端 Pod 对象列表，将 Pod 和 Service 的详细信息以 Pod 为单位封装成一个个 Endpoint 对象，这就是实际的 Endpoint 对象；用于和 APIService 在 etcd 中检索到的 Endpoint 期望状态进行比较, 在根据 etcd 中的期望调用 APIServer 创建或销毁资源。</li>
<li><strong>Node controller:</strong> 判断是否工作在 IaaS 上，是则直接掉 IaaS API 获取所有可工作节点；定期向 APIServer 注册以此工作节点；每隔五秒 pull 一次 Node 中 kubelet 发送过来的工作节点运行状态，retry 超过30秒无响应设置 node 状态为 Unknow，然后，调用 APIServer 更新 etcd 中的节点信息，如果时间超过 PodTvictionTimeout，则在 etcd 中删除所有 Pod 对象。</li>
<li><strong>Resource quota controller:</strong> 用于追踪集群资源配额的实际使用量，期望值由管理员静态设置。</li>
</ul>
<h2 id="Kubelet"><a href="#Kubelet" class="headerlink" title="Kubelet"></a>Kubelet</h2><p>Kubelet 是运行在 Kubernetes 集群中子节点上的进程，负责管理和维护 Node 上的所有容器。Kubelete 利用 Dokcer cAdvisor 进程用于监控 Node 的状态并将数据汇报给 master。<br>垃圾回收： 容器回收（goroutine 每一分钟调用 Docker 客户端过滤出停止且超过 MinAge 的容器以 Pod 为单位放到 EvictUnit 中，判断宿主机允许回收，则删除）。<br>镜像回收（每五分钟遍历一次，筛选出最长时间没有被使用且大于指定时间的 Image 删除）<br>同步工作节点。</p>
<h2 id="Kube-proxy"><a href="#Kube-proxy" class="headerlink" title="Kube-proxy"></a>Kube-proxy</h2><p>Kube-proxy 既支持 HTTP，也支持 TCP 和 UDP 连接，默认情况下提供 Round Robin 算法将客户端流量复杂均衡到 Service 对应的一组后端 Pod，最重要的是 Kube-proxy 还支持 Session Affinity(Session Sticky，会话黏滞)。而服务发现上，Kube-proxy 使用 etcd 的 Watch 机制，监控集群 Service 和 Endpoint 对象数据的动态变化，并且维护一个从 Service 到 Endpoint 的映射关系，从而保证了后端 Pod 的 IP 变化不会对访问者造成影响。</p>
<h2 id="核心组件协作流程"><a href="#核心组件协作流程" class="headerlink" title="核心组件协作流程"></a>核心组件协作流程</h2><p>费心巴力在网上找了描述准确的图但是他每个对象都少了最后一个字母，更正如下，从左到右：<br>Kubectl        APIServer                 etcd        Scheduler              Kubelet             Docker</p>
<p><img src="/images/kubernetes_create_pod.png" alt=""></p>
<center><strong>创建Pod示意图</strong></center>


<blockquote>
<ul>
<li>参考资料：</li>
<li>《Dokcer 容器与容器云》浙江大学 SEL 实验室著</li>
<li>《Kubernetes权威指南》龚正，吴治辉，王伟 等著</li>
<li><a href="https://www.slideshare.net/imesh/revolutionizing-wso2-paas-with-kubernetes-app-factory" target="_blank" rel="external">https://www.slideshare.net/imesh/revolutionizing-wso2-paas-with-kubernetes-app-factory</a></li>
<li><a href="https://docs.openshift.org/latest/architecture/core_concepts/index.html" target="_blank" rel="external">https://docs.openshift.org/latest/architecture/core_concepts/index.html</a></li>
<li><a href="https://kubernetesbyexample.com/" target="_blank" rel="external">https://kubernetesbyexample.com/</a></li>
<li><a href="https://kubernetes.io/docs/concepts/" target="_blank" rel="external">https://kubernetes.io/docs/concepts/</a></li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes 的很多概念和架构“代表了谷歌过去十余年设计、构建和管理大规模容器集群经验”。&lt;/p&gt;
&lt;h1 id=&quot;Kubernetes-概念引入&quot;&gt;&lt;a href=&quot;#Kubernetes-概念引入&quot; class=&quot;headerlink&quot; title=&quot;Kuber
    
    </summary>
    
      <category term="Cloud" scheme="https://www.duyidong.com/categories/Cloud/"/>
    
    
      <category term="DevOps" scheme="https://www.duyidong.com/tags/DevOps/"/>
    
      <category term="PaaS" scheme="https://www.duyidong.com/tags/PaaS/"/>
    
      <category term="Openshift" scheme="https://www.duyidong.com/tags/Openshift/"/>
    
      <category term="Kubernetes" scheme="https://www.duyidong.com/tags/Kubernetes/"/>
    
      <category term="平台即服务" scheme="https://www.duyidong.com/tags/%E5%B9%B3%E5%8F%B0%E5%8D%B3%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>PaaS 平台（一） -- Openshift 介绍</title>
    <link href="https://www.duyidong.com/2017/06/14/kubernetes-and-openshift/"/>
    <id>https://www.duyidong.com/2017/06/14/kubernetes-and-openshift/</id>
    <published>2017-06-14T13:53:00.000Z</published>
    <updated>2017-07-14T03:37:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>Openshift 是一个基于 Kubernetes 和 Docker 的 PaaS 平台。</p>
<h1 id="历史背景"><a href="#历史背景" class="headerlink" title="历史背景"></a>历史背景</h1><h2 id="容器和容器云的历史"><a href="#容器和容器云的历史" class="headerlink" title="容器和容器云的历史"></a>容器和容器云的历史</h2><p>如下图所示，我整理了一个简单的容器历史年表，蓝色箭头表示容器的发展史，红色箭头表示 Openshift 重大事件。<br>在 2013年以前，容器还是 OpenVZ，LXC 等虚拟化技术的形态，在 2013年3月，Docker 正式发布开源版本，随即在 Github 中代码提交量盛况空前，打响了容器化技术的第一枪。<br>在 Docker 发布之后短短数月的时间，Redhat 就开始了基于 Docker 的 PaaS 平台研发(<a href="https://www.openshift.org/" target="_blank" rel="external">官网</a>标注是在13年6月 Openshift 就已经在基于 Kubernetes 研发)，并在随后发布的 REHL6.5 中集成了对 Docker的支持，标拉开了业界各大厂商竞相支持 Docker 的序幕。次年，云计算三巨头亚马逊、微软、谷歌相继推出了支持 Docker 的云计算品台。<br>2015年7月，谷歌发布了 Kubernetes 的第一个版本，Kubernetes 脱胎于谷歌内部的大规模集群管理工具 Borg，且参与 Kubernetes 项目的早期贡献者正式参与过 Borg 项目的工程师，所以业界基本认同 Kubernetes 的很多概念和架构“代表了谷歌过去十余年设计、构建和管理大规模容器集群经验”的说法。虽然 Kubernest 在容器调度方面表现出众，但他的功能还元不构成一个 PaaS 平台，于是很多厂商开始基于 Kubernetes 开发自己的 PaaS 平台，其中就有目前在国内创业公司被大量使用的 Rancher，值得注意的是 Rancher 是在2016年才开始发布第一个版本，而 Openshift 则早在13年就开始基于 Kubernetes 的开发，但目前看来国内市场对 Ranchard 的接受度是远高于 Openshift 的，就使用体验上看，Rancher 也确实更简单易用。<br>今年（2017年）四月份发生了一件引爆容器社区的事，就是 Docker 开源社区版改名为 Moby，此举为 Docker 公司的商业行为，在此不表态，不赘述。<br>截止到这边文章发出为止，目前 Moby 的最新版本为 17.3.2(Docker 的版本从1.2之后变更了命名方式直接跳到了17)，Kubernetes 为1.7.0(基本与 Docker 更新保持同步) ，Openshift 则为 3.6.0。</p>
<p><img src="/images/container_timeline.png" alt=""></p>
<p>这里要说明一下 Openshift 目前有四个版本，分别为公有云版（类似于AWS）、企业版、企业定制版（保证专属硬件）、社区版本，笔者试用版本为社区版。社区版中有一个分支应用叫 minishift，是一个基于虚拟机的单节点 Openshift 集群，基本和公有云版功能一致，在 16G 的 Mac 上跑起来完全无压力。但还是更推荐直接使用<code>oc cluster up</code>，用容器的方式启动更简单也更轻量，也是目前官方推荐的做法。</p>
<p><img src="/images/openshift_version.png" alt=""></p>
<center><strong>图片来源：</strong><a href="https://docs.openshift.com/" target="_blank" rel="external">https://docs.openshift.com/</a></center>

<h2 id="什么是-PaaS"><a href="#什么是-PaaS" class="headerlink" title="什么是 PaaS"></a>什么是 PaaS</h2><p>PaaS（Platform as a Service，平台即服务）最早是在云计算领域被提出。如下图所示，将企业IT服务分为九层，传统自建数据中心九层设施都需要企业自己维护，成本极高。而云计算架构就相当于吧九层架构中的底层一部分外包给云计算服务提供商，根据外包的层次不同，分为IaaS(Infrastructure as a Service，基础设施即服务)，PaaS，SaaS（Software as a Service）三层。</p>
<ul>
<li>IaaS 层为基础设施运维人员服务、提供计算、存储、网络以及其他硬件资源，云平台使用者可以在上面部署和运行包括操作系统和应用程序在内的任意软件，无需再为基础设施的管理而分心。</li>
<li>PaaS 层为应用开发人员服务，提供支撑应用运行所需的软件运行时环境，相关的工具与服务，如数据库服务、日志服务、监控服务等，让应用开发者可以专注于交付业务价值的代码而无需关心应用所需脚手架。</li>
<li>SaaS 层为一般用户（最终用户）服务，提供了一套完整可用的软件系统，让一般用户无需关心技术细节，只需通过浏览器、应用客户端的方式就能使用部署在云上的应用服务。SaaS 产品比如客户关系管理系统、邮件、虚拟桌面、通信、游戏等。</li>
</ul>
<p><img src="/images/IaaS_PaaS_SaaS.png" alt=""></p>
<center><strong>图片来源：</strong><a href="https://mycloudblog7.wordpress.com/2013/06/19/who-manages-cloud-iaas-paas-and-saas-services/" target="_blank" rel="external">https://mycloudblog7.wordpress.com/2013/06/19/who-manages-cloud-iaas-paas-and-saas-services/</a></center>

<p>这里要更正一个误区，有人可能认为 AWS 是一个 PaaS 服务，那我的项目全部都在 AWS 上，我是不是就已经有了一个 PaaS 平台？<br>答案是否定的。在一些 AWS 的使用场景中，租户往往只是用了它的 IaaS 级服务，比如 EC2 instance，出于也无需要或灵活性的考虑，租户需要自己管理操作系统以上的环境，诸如安装 Tomcat, Apache 等服务，这些工作由一些自动化脚本来完成。除此之外你或许还有一套搭建在 Jenkins 上的持续交付系统，有一个搭建在 Nexus 服务器上的版本管理系统，这些所有目前由你自己管理的组件，才真正构成了一个 PaaS 平台。<br>企业在自己管理 PaaS 平台的时候是会有很多痛点的，比如跨云环境不兼容各云平台厂商的基础设施，比如持续集成服务器不稳定，比如自动化配置脚本难管理。如此种种，给企业数字化平台的管理造成成本，平台成为承载业务的开发的瓶颈，企业产生了选用一套第三方 PaaS 平台的需求，这也是为什么今天我们来讲 Openshift。</p>
<h2 id="Openshift-对比-Cloud-Foundry"><a href="#Openshift-对比-Cloud-Foundry" class="headerlink" title="Openshift 对比 Cloud Foundry"></a>Openshift 对比 Cloud Foundry</h2><p>Cloud Foundry 是一个常被用于和 Openshift 对比的产品，前者由 Pivotal 公司开发(大名鼎鼎的 Springboot，SpringCloud就是他们家的)，后者由 Redhat 开发。很难用一两句话说清两个 PaaS 孰优孰劣，但就我个人的使用体验而言，Cloud Foundry 自动化程度更高一些，而 Openshift 可定制化程度也更高，Openshift 上的应用甚至不需要是一个严格的<a href="https://12factor.net/" target="_blank" rel="external">十二因素应用</a>，这也就意味着可以将任何类型的应用迁移到 Openshift 上。</p>
<h2 id="Openshift-架构概览"><a href="#Openshift-架构概览" class="headerlink" title="Openshift 架构概览"></a>Openshift 架构概览</h2><p>Openshift 实际上由三部分组成，核心部分实现容器的调度是封装的 Kubernetes， 除此之外还有一个内置的镜像仓库（Image Registry），这个仓库是可选的，Openshift 也可以配置使用 Dockerhub 或者企业自己的镜像仓库，最外层部分是一个友好的 Web 界面，用于展示和操作 Openshift 的资源。<br>如下图所示，Openshift 要成为一个完整的数字化平台需要依赖于两个外部系统，一个代码库，一个是持续集成服务，事实上这两个外部服务也是可以跑在 Openshift 里面的。右边的灰色矩形就是 Openshift 的主要架构了，它的上层是一个路由（Router），用于 DNS 解析和转发，确保用户能够调用到 Openshift 集群中的服务。红色的部分是跑在 RHEL 操作系统上的 Kubernetes 集群，侧面是外部存储服务，因为集群里的计算单元是漂浮的，所以通常 Kubernetes 集群只提供计算能力，数据持久外需要依赖外部的比如说 S3，EBS 等云服务商提供的存储服务。最下层同样也是由云服务商提供的基础设施服务。</p>
<p><img src="/images/openshift_infrastracture.png" alt=""></p>
<p>以上为 Openshift 的一个简单的认识，下一部分我会讲解 Kubernetes 引入的一些新概念，这些概念在 Openshift 中也被复用到，理解这些概念有助于理解 Openshift 的架构和流程设计。</p>
<blockquote>
<ul>
<li>参考资料：《Dokcer 容器与容器云》浙江大学 SEL 实验室著</li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Openshift 是一个基于 Kubernetes 和 Docker 的 PaaS 平台。&lt;/p&gt;
&lt;h1 id=&quot;历史背景&quot;&gt;&lt;a href=&quot;#历史背景&quot; class=&quot;headerlink&quot; title=&quot;历史背景&quot;&gt;&lt;/a&gt;历史背景&lt;/h1&gt;&lt;h2 id=&quot;容器和
    
    </summary>
    
      <category term="Cloud" scheme="https://www.duyidong.com/categories/Cloud/"/>
    
    
      <category term="DevOps" scheme="https://www.duyidong.com/tags/DevOps/"/>
    
      <category term="PaaS" scheme="https://www.duyidong.com/tags/PaaS/"/>
    
      <category term="Openshift" scheme="https://www.duyidong.com/tags/Openshift/"/>
    
      <category term="Kubernetes" scheme="https://www.duyidong.com/tags/Kubernetes/"/>
    
      <category term="平台即服务" scheme="https://www.duyidong.com/tags/%E5%B9%B3%E5%8F%B0%E5%8D%B3%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>DevOps 团队交付了什么？</title>
    <link href="https://www.duyidong.com/2017/06/08/work-in-blackops/"/>
    <id>https://www.duyidong.com/2017/06/08/work-in-blackops/</id>
    <published>2017-06-08T08:38:47.000Z</published>
    <updated>2017-06-10T08:46:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>大熊最近在 ThoughtWorks 给大家讲<a href="http://gigix.thoughtworkers.org/2017/4/25/ditigal-platform-strategy-intro/" target="_blank" rel="external">数字平台战略(Digital Platform Strategy)</a>，非常高兴向大家地宣布，我们已经有了战略框架，鼓励项目上的同事多讲讲故事，那我就来讲一个。借此对过去5个月在项目上的磕磕绊绊做个整理。</p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h1><p>客户是一家澳洲大型金融保险企业，在保险领域处于本地绝对领先地位，其IT部门总人数在千人以上，维护应用两百余个。在经历了几年的收购和合并之后，在业务上指定了将收购来的多个品牌进行整合的大方针，于是IT部门也开始面临着系统整合，业务线整合，网站合并的问题，同时客户正在将他们的服务逐渐从自建数据中心向 AWS 公有云服务上迁移。</p>
<h1 id="团队概览"><a href="#团队概览" class="headerlink" title="团队概览"></a>团队概览</h1><p>在数字化转型的漫漫长路中，该企业已经在内部搭建起了一套持续交付系统，以Jenkins为中心，有制品库，依赖管理，代码管理，任务管理系统，敏捷实践成熟。</p>
<p>我所在的团队是在整个组织向 DevOps 转型中的一个比较关键的团队，肩负着 CI/CD 优化、持续交付改进、运维能力输出的重任。类似的团队应该在很多 DevOps 转型的组织里都有，负责维护 CI/CD 基础设施，搭建应用开发脚手架，维护基础设施变更，做各种自动化的工作（姑且就将这类团队称之为 Platform 团队）。比较特殊的是我在的这个团队实行轮岗制，由产品团队的成员（通常是开发）定期轮换到 Platform 团队，带着在产品团队遇到但是没能解决的问题，在这个团队寻求最佳实践和解决方案，一段时间后（通常是三个月），开发从 Platform 团队回到开发团队，同时将 DevOps 技能和最佳实践待到产品开发团队。整个 Platform 团队大小基本维持在3-5人，有一个 IM（Iteration Manager 迭代经理），其余全是 Dev (Developer 开发)。</p>
<h2 id="取得的成就"><a href="#取得的成就" class="headerlink" title="取得的成就"></a>取得的成就</h2><p>回顾过去的五个月，Platform 团队一共经历了10个迭代（每个迭代两个星期），我梳理了一下每个迭代的工作内容，整理出主要成就如下：</p>
<ul>
<li>围绕 CI/CD 做了很多优化，比如简化 Jenkins slave 创建流程，给自动化脚本（基础设施代码）贡献了许多新功能。</li>
<li>新技术试点，比如尝试用将静态文件部署到 AWS S3 中代替 Apache 服务。</li>
<li>为应用设置监控，更新了基础设施脚本用于开启监控，并协助应用团队将配置脚本应用到各个环境。</li>
<li>团队之间的沟通，了解开发团队痛点，帮助开发团队找到能够解决问题的团队（权限，责任划分，知识传递），技能培训等。</li>
<li>响应变化，解决技术难题（虽然我认为更多的还是一个沟通+权限的问题，但是其他所有团队都认为是技术难题那我也就这样认为吧），以及修复一些类似于硬盘空间已满，网络延迟，权限的的问题。</li>
</ul>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>当然在交付价值的同时有很多痛点是非常痛的：</p>
<ul>
<li><strong>权限，</strong>作为一个和各个开发团队沟通的团队，不但没有比开发团队更多的权限，甚至连开发团队的一些权限都没有，比如不能向开发团队的代码库 Push 代码(修改基础设施代码需要这个权限)，比如 Linux 底层问题没法直接修复，因为只有应用级别的权限，再比如 Jenkins 没有服务器权限，出了问题也不能修，因为这些应用是由别的团队专门管理。</li>
<li><strong>沟通，</strong>为了解决一个 bug，有时候要花上两周的时间发邮件，找关键人物，组织会议，跟不同的人解释五遍以上的上下文（技术细节的上下文是很繁琐的），最后解决问题的人还很有可能不是自己团队的（没有权限）。因为大家平时都很忙，而且建卡工作的方式让一部分人对团队请求帮助的问题不是很热心，这种情况在沟通的时候如果表现得情商不够高对方就会要你发邮件给他们团队然后等 IM 建卡，规划到迭代里再说了，我遇到过一次这样的情况，最后还是通过社工手段拿下了这个关键人物，过程不可谓不曲折。</li>
<li><strong>需求，</strong>Platform 团队并不交付业务价值，因此没有 BA(Business analyst 业务分析师，通常扮演梳理需求的角色)，建卡的事基本都由 IM 和 Dev 来做，虽然感觉上是合理的，但实施起来却遇到很多问题，究其根本就是因为对需求的定义和划分不够明确，往往导致最后挪卡的时候大家都说不准这张卡算不算完成了，只能用拍脑袋的方式来决定。</li>
<li><strong>质量，</strong>同上，团队缺少QA(Quality Assurance，质量工程师，测试人员)，Dev 们都是自己做卡自己测，有时候会结对测试，但也会因为对需求理解不充分，或者说拆卡拆得有问题，导致一些卡完成得质量不够，直接影响受依赖的卡。举个例子，部署监控需要自动化脚本的两个模块支持，两个模块被分为两张卡，在做第一张卡的时候遇到了诸多问题，好不容易把代码 Push 到别人的版本库里了，在做第二张卡的时候却发现第一张卡代码里多写了一对引号，导致整个逻辑实现失败，这个时候再回过头来改之前的代码，又要重新解决之前遇到的各种问题（沟通、权限，PS：这个时候做第一张卡的人还下了项目），周期和浪费的工时是可想而知的。</li>
<li><strong>轮岗，</strong>这是 IM 一直很头疼的一件事，Platform 团队大量的时间花在给新来的团队成员输入上下文，同时又有成员离开团队要交接工作，尤其在沟通重要的工作中，成员的离开意味着需要新的人重新和干系人建立联系，再者，一些成员因为项目上的痛点，不是很有心思工作在团队的事务上，而是更关心自己过段时间会被分配到那个团队，如此种种都对团队的价值交付造成了很大的困扰。举一个例子，有一个端到端测试工具一直由 Platform 团队维护，从我加入 Platform 团队开始，这个测试工具就打算新增一个集成远程浏览器引擎的功能，这是一个非常有价值的功能，因为开发团队长期苦于浏览器版本支持过少，端到端测试不稳定；但是在实现过程中一直存在一个网络问题，这张卡先后被关闭，开启，标记完成，又重新开启，经历了大概五六个人的手，困扰我们的网络问题直到 Platform 团队解散，都没能解决。</li>
<li><strong>汇报，</strong>虽说 ThoughtWorks 是扁平化管理，但是面对一个金字塔结构的客户难免也会需要固定有资深的人和客户的高层对接，这种安排是合理且必要的；在交付团队中，开发如果发现资源不足，需要和 TL(Tech Lead 或是 Team Lead，可以理解为项目组长)或者 PM(Production Manager 产品经理)沟通，但是在 Platform 团队，没有合适的汇报对象，一方面在 ThoughtWorks 内部没有工作关系紧密的架构师或者 TL，另一方面客户的汇报线变动频繁，也就是客户的领导也在变，在团队成员缺少资源需要更高管理层的决策支持时沟通难度增加。比如在申请权限时需要客户领导审批，客户的领导却一直在会议中，要么就找不到人（海外项目远程办公，只能通过及时通讯软件呼叫客户），让在团队中别的客户成员帮忙跟进，客户也是无奈地摊摊手，一次又一次在站会中重复着“他很忙，我找不到他”，诸如此类。同样，没有合适的汇报人意味着团队缺少了更高的视角来实时回顾自己做的事情是否是正确的，方向有没有走偏，或者是不是又在造别人造过的轮子。我在团队解散后跟“前” IM 聊天，他还坚持认为我们团队被解散是因为没有一个强有力的领导在背后支持，这也从侧面反映了我们没有找到合适的汇报人，告诉他，我们在做什么，听他说，我们下一步可以做什么。</li>
</ul>
<h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><h2 id="问题背后的原因及可能的改进方案"><a href="#问题背后的原因及可能的改进方案" class="headerlink" title="问题背后的原因及可能的改进方案"></a>问题背后的原因及可能的改进方案</h2><p>团队解散后经过一段时间的沉淀，也和过往的成员逐一了解了他们的想法，总结分析出了以下原因，以及可能的解决方案能使做得更好。</p>
<h3 id="原因1：团队方向不清晰"><a href="#原因1：团队方向不清晰" class="headerlink" title="原因1：团队方向不清晰"></a>原因1：团队方向不清晰</h3><p>不同于交付业务价值的产品团队，Platform 团队不对某一个具体的产品负责，也不直接产出业务价值，所以这个团队应该是属于架构师的一个机动团队，因此客户的架构师的离开，就为 Platform 团队解散埋下了伏笔。（这一点我也是后来才意识到的）<br><strong>可能的改进方案：</strong>在团队利益相关者(Stakeholder)缺失的时候，应立即与我方架构师沟通，在明确团队方向的同时还能发挥 ThoughtWorks 影响力。</p>
<h3 id="原因2：团队角色缺失"><a href="#原因2：团队角色缺失" class="headerlink" title="原因2：团队角色缺失"></a>原因2：团队角色缺失</h3><p>在架构师不能全权参与团队工作的情况下（甚至 Platform 团队还一度没有 IM ），一帮 Dev 就很容易对团队整体整体的感知，每个 Dev 只关心自己手里的工作，迭代开始初期容易考虑不到全局影响不能准确建卡，迭代进行时因为没有合适的汇报人因而跨团队交流困难，迭代结束时没有优质的回顾。<br>在 Micromanagement culture（微观管理文化）中有一个 Alignment(校准)和 Autonomy(自治)两个互斥的指标，我们使用这两个指标作为向量构成四个象限，如下图所示，高校准低自治的团队由领导决定做什么以及怎么做，团队只需要执行，这样会形成“领导说什么就是什么”的局面；而高校准且高自治的团队是由领导指出要解决的问题以及原因，然后由团队成员相互合作共同找到问题的解决方案；低校准低自治的团队则缺乏活力，只能循规蹈矩；而高自治低校准的团队成员可以坐任何他们想做的事情，领导则很无助因为没有人关心真正需要的解决的问题。在敏捷团队中，如果只剩下了 Dev，情形则很有可能变成图中左下象限（也有些许右下）的情况，要想达到右上象限的期望状态，需要提高自治，更多的是校准。<br><strong>可能的改进方案：</strong>在意识到这个问题的时候，团队需要一个关键人物出面充当领导者的角色，扮演这个角色的人必须关注在团队交付价值，目标和方向，并且有强大的沟通能力让团队成目标一致；和利益相关者加强沟通，保证团队方向不会跑偏。<br><img src="/images/spotify.png" alt=""></p>
<center><strong>图片来源：</strong><a href="https://www.youtube.com/watch?v=4GK1NDTWbkY" target="_blank" rel="external">Spotify Engineering Culture</a></center>

<hr>
<h2 id="根本原因"><a href="#根本原因" class="headerlink" title="根本原因"></a>根本原因</h2><p>Platform 团队成立初期被定义为一个立意高远（DevOps 转型）的组织，但是在项目实施过程中变得越来越边缘化，其中有“人”的原因，有组织架构的原因，当然还有一些客观原因。但我突然意识到这背后有一个原因一直被我忽视了，那就是————我们在实践 DevOps 反模式。</p>
<p>国内近年来一直在对 DevOps 如何落地争论不休，DevOps 提倡的是打破开发和运维的部门墙，将开发和运维（的能力）放在一个团队。然而国内大部分项目的现状是，开发不具备运维技能和意识，也不愿意做“背锅侠”（要求开发做运维一定程度上牺牲了开发的利益，比如亚马逊的开发会隔周会被要求24小时 On-call），因此一些公司选择了在项目中先成立一个 “DevOps 团队” 作为过渡，再慢慢将 CI/CD 的理念和技能扩散到其他团队，但是这种方式稍不注意就会变成“换了个名字的 Ops ”，因为工作内容相似，写脚本，做高可用，这些是传统运维也会做的事情，这种形式非常不利于团队思维的转变，“对最终交付物负责”才是 DevOps 的精要，而不是职责划分（只对流程负责）。这样的要求无异是给项目成员增加了工作量和责任，对他们提出了更高的要求。然而很多职员不愿意无回报地多背负一些责任，比如说开发，谁不愿意每天写点代码一提交就早早回家，DevOps 要求他们得看着新功能上线，确保无误之后才能离开；所以 DevOps 的推行在产品团队中是有阻力的，因此，DevOps 应该是场自上而下的运动。</p>
<h1 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h1><blockquote>
<p>做一个项目要有一个项目的收获，不然工作十年你只拥有了十年的工作经历，而不是十年的工作经验。<br>   </p><p style="text-align:right">———— 朱平</p><p></p>
</blockquote>
<ul>
<li><strong>尽早找到关系人，并和他建立联系。</strong><br>  这一点是我觉得最需要反省的，在项目进行到7、8个迭代的时候才意识到要和我方架构师和技术专家建立联系，在此之前走了很多弯路，也错失了很多机会。</li>
<li><strong>让事情发生比如何发生更重要。</strong><br>  应该说在这5个月的工作中，我最喜欢的部分是最后两个迭代我们开始真正搜集来自应用团队的需求，开始在两地组织各个团队的 TL 开会搜集痛点和解决方案。这件事其实我早就意识到会是非常有价值的，但始终没有去做，总是顾虑不知道怎么去开始，去推动，担心自己表述不清，或者不能给 TL 真正解决问题会很不好意思。但是最后这件事终于发生了，才意识到真的是非常有价值，而且早该这么做了。<br>  关于这点在我还在 ThoughtWorks 试用期的时候我的 Buddy(由公司安排负责伴随新员工过度试用期的人) 给了我一个非常好的建议，就是决定要讲一个分享之前先把日程表（邀请邮件）发出来，这种看似是“Deadline driven(截止日期驱动)”的方式，背后暗含了“<strong>这件事情必须发生</strong>”的道理，这和 MVP(Minumum viable product，产品原型) 的原理也是一样的，先上线，再搜集反馈，迭代改进；就算它是一个错误的行为，这也是一次有价值的试错。<br>  类似的事情还有很多，比如敢于和客户沟通，敢于在团队承担很多责任，都可以借鉴。</li>
</ul>
<h2 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a>下一步</h2><p>结合我自身的经历，“DevOps 团队”的实践并不是一个很好地工作体验，应用开发团队自身如果不具备产品思维，要由一个独立的团队去影响它们是很难的，这样的实践下的 DevOps 团队就像是披着 DevOps 外衣的 Ops 团队，不能产生理想的价值。<br>相比之下我更愿意去到一个真正的产品团队做一名开发，交付真正的业务价值。这样不单会让开发更有成就感，而且作为一个有 DevOps 精神的开发，在真正熟悉业务需求之后做出的整体优化，才会更有价值，这种做法也更复合真正的 DevOps 精神。</p>
<h2 id="DevOps-的未来"><a href="#DevOps-的未来" class="headerlink" title="DevOps 的未来"></a>DevOps 的未来</h2><p>自2017年以来，有一个趋势已经越来越明显，那就是 DevOps 已经越来越多的被一些平台厂商（这里的平台指的是应用代码所需的脚手架及基础设施）掌握了话语权，以 AWS 和 Pivotal 为例，这两家公司一家是做公有云，一家做 PaaS(Platform as a Service，平台即服务)，他们一边卖自己的产品，一边卖着咨询，一边运营着自己的社区，四处宣讲最佳实践，在行业内形成一个以生态圈为中心的闭环，不断向外扩张自己的影响力。同时因为自建平台常常是工具的拼凑很难形成一整套好的解决方案，且维护成本也高，越来越多的公司被吸引去尝试使用他们的产品，接受他们的理念。我也相信，这些平台厂商在良好的现金流和足够多的用户支撑下，能够把平台做得越来越好。到那时候，我们不用提及 DevOps，每个项目都是 DevOps 的。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大熊最近在 ThoughtWorks 给大家讲&lt;a href=&quot;http://gigix.thoughtworkers.org/2017/4/25/ditigal-platform-strategy-intro/&quot; target=&quot;_blank&quot; rel=&quot;external
    
    </summary>
    
      <category term="ThoughtWorks" scheme="https://www.duyidong.com/categories/ThoughtWorks/"/>
    
    
      <category term="小结" scheme="https://www.duyidong.com/tags/%E5%B0%8F%E7%BB%93/"/>
    
      <category term="职场" scheme="https://www.duyidong.com/tags/%E8%81%8C%E5%9C%BA/"/>
    
      <category term="DevOps" scheme="https://www.duyidong.com/tags/DevOps/"/>
    
      <category term="Platform" scheme="https://www.duyidong.com/tags/Platform/"/>
    
      <category term="工作" scheme="https://www.duyidong.com/tags/%E5%B7%A5%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>DevOps 技能树</title>
    <link href="https://www.duyidong.com/2017/05/18/DevOps-skill-tree/"/>
    <id>https://www.duyidong.com/2017/05/18/DevOps-skill-tree/</id>
    <published>2017-05-18T08:30:47.000Z</published>
    <updated>2017-05-19T05:17:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>DevOps 是什么，在这些年的争论中似乎总难用一句话概括清楚，但随着技术社区、企业的推动和一些理念越来越多的被人们实践，这个概念已经变得越来越清晰。<br>最近成都 Cloud &amp; DevOps 社区整理了一个 DevOps 技能树，很有意思。对研究 DevOps 而言，提供了一个不错的视角；对 DevOps 领域从业人员而言，可以做个自我定位和学习方向的参考。</p>
<blockquote>
<p>You build it, you run it.</p>
<p style="text-align:right">—— Amazon CTO：Werner Vogels</p>

</blockquote>
<h1 id="社区技能树"><a href="#社区技能树" class="headerlink" title="社区技能树"></a>社区技能树</h1><p><center><strong>成都 Cloud &amp; DevOps Community 能力树</strong></center><br><img src="/images/Chengdu_DevOps_Community_Capability_tree.png" alt=""></p>
<p>这个能力树基本根据大家平时的项目经验构成，大项分为两类，<strong>Best Practices （最佳实践）</strong>基本包含了平时做 session 或者 proposal 需要领悟的一些概念和实践，学习方法主要是翻阅国内外大牛的博客。<strong>Infrastructure &amp; Tools（基础设施和工具）</strong>是概念落地时需要的技术，学习方法主要是多用多练习，以及查阅文档。</p>
<p>对着个基于工作内容构成的偏技术/实践落地的版本，我对照了一下企业招聘的要求，试图梳理出 DevOps 角色画像。</p>
<h1 id="企业如何定义-DevOps-角色能力"><a href="#企业如何定义-DevOps-角色能力" class="headerlink" title="企业如何定义 DevOps 角色能力"></a>企业如何定义 DevOps 角色能力</h1><p>先来看看国内企业对 DevOps 的期望，以下是华为的招聘：</p>
<pre><code>职位：DevOps运维专家

1.计算机相关专业本科毕业，5年以上的工作经验。（大型互联网企业背景优先）；

2.深入理解Linux操作系统、体系结构；

3.优秀的的开发能力，熟悉常用的自动化运维工具；

4.熟悉常用的持续集成工具；

5.熟悉常用的监控工具（例如Nagios、Zabbix等）；

6.熟悉常用数据库（例如MySQL, Oracle、MongoDB, Redis等）；

7.认同并坚持“Automate Everything You Can”的原则，认同DevOps文化，在开
源社群活跃并有积极贡献者优先。
</code></pre><p>关键字：Linux、CI/CD工具、监控、数据库、自动化。<br>对于开发技能只是提了一句优秀的开发技能，但却没对开发技能做要求，可以预见招进去之后应该是不会让你做开发的，这个岗位基本上是一个工作内容包含 Pipeline 搭建的，懂自动化的<strong>运维</strong>角色。————这和我在国内项目的感受是一致的。</p>
<p>再来看几家美国的企业招聘：</p>
<ul>
<li><strong>Ericsson：</strong></li>
</ul>
<pre><code>Title：Solution Architect - Development Operations (DevOps)

Experience with Groovy

Experience with Jenkins and the Jenkins DSL plugin.

Experience with Docker, Kubernetes, Vagrant

Experience with Mesos.

Experience with Plutora.

Experience with OpenShift / appOrbit.

Public cloud experience (such as AWS or Azure).

Experience with Splunk, Sensu or ELK.

Strong Linux system architecture experience (Red Hat/Centos/Debian/Ubuntu)

Excellent analytical and creative problem solving skills.

Independent / go - getter attitude to keep yourself well-versed with new evolving technologies in the DevOps landscape and be able to apply this knowledge to improve the software we are developing now or in future.
</code></pre><p>关键词：CI/CD、容器编排、云、PaaS、日志/监控、方案解决。<br>这个职位更像一个方案解决架构师 + DevOps 的角色，这个招聘传达的需求十分明确，要有架构的知识，持续改进持续交付意识，以及解决问题的能力，而弱化了对传统运维（日志/监控）的技能的要求。</p>
<ul>
<li><strong>ThoughtWorks：</strong></li>
</ul>
<pre><code>Title: Infrastructure Developer (DevOps Champion)

Experience with infrastructure as code / provisioning tools like Chef, Puppet or Ansible

Experience with one or more of the structured major PaaS platforms such as CloudFoundry or OpenShift and understand their benefits and lacks in deploying and end-to-end continuous delivery pipeline

Familiarity with Cloud Native Architecture principles and specific tooling and approaches to support high-availability architectures

Understanding of the pros and cons of the key Continuous Integration tools like Go, TeamCity, Jenkins and Concourse

Knowledge in the administration of application and web servers and servlet containers such as WebSphere, Apache Tomcat, Jetty, Nginx, Mongrel, Passenger, Microsoft ISS, etc.

Extensive experience in scripting languages (golang, Shell, Ruby, Perl, Python, PowerShell, etc) and the SCM Tools like Git(Hub), SVN, Perforce and Mercurial

Linux operating system management, operation and maintenance, and network-related knowledge

Comfort with ambiguity and high level of flexibility

High willingness to travel
</code></pre><p>关键词：基础设施代码、PaaS、Cloud native、CI/CD、Platform、脚本语言（自动化）、Linux、愿意出差。<br>相比于前两个招聘，因为是咨询公司，看得出对技能的广度要求更多，同时技能偏向于基础设施代码编写，流水线搭建，过程优化，而更加弱化了运维（监控/日志都没有出现）。</p>
<p>以上为挑选出来的比较典型的招聘启事，综合来看，对于 DevOps 这个角色达成一致的能力需求，包含了Linux、网络、CI/CD、自动化。除了一致的部分，国内和美国的招聘又有些不同，国内偏向运维，更加强调自动化；美国的企业对 DevOps 更要求架构能力（推测是因为贯彻了基础设施代码的概念），和过程优化的能力；过程优化的主要目的应该就是加速持续交付以支持业务连续性。</p>
<h1 id="综上所述"><a href="#综上所述" class="headerlink" title="综上所述"></a>综上所述</h1><p>DevOps 的目的是消除 Dev 与 Ops 之间的部门墙，从而加速软件迭代的反馈周期，进而实现业务连续性；基于这一目的，诞生了许多最佳实践；配合这些最佳实践，又产生了许多工具用于项目管理，自动化，可视化等等。在云服务蓬勃发展的大背景下，又给 DevOps 赋予了基础设施代码化的使命。随着软件开发流程越来越成熟，迭代周期越来越快，对业务代码以外的东西（可以把它叫做软件开发的脚手架）的稳定性和易用性要求越来越高，所以诞生了一批以 Heroku、Cloud foundry、Openshift 为代表 PaaS 平台，慢慢在将 DevOps 的工作产品化，从而达到“零运维”或者“AI运维”的效果。<br>在漫长的演进史中，DevOps 用灵活的架构和更快的变化帮助企业 IT 响应着市场变化。<br>所以 DevOps 是什么？我认为 DevOps 并不是独自一人改变了软件设计开发流程，DevOps 更像是技术变革史上传统运维消失前的一朵浪花。</p>
<blockquote>
<ul>
<li>招聘材料来源：猎聘，领英</li>
<li>相关链接：<a href="https://www.duyidong.com/2016/11/11/%E4%B8%80%E5%8F%A5%E8%AF%9D%E4%BB%8B%E7%BB%8DDevOps%E6%98%AF%E5%81%9A%E4%BB%80%E4%B9%88%E7%9A%84/">一句话介绍DevOps是做什么的</a></li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;DevOps 是什么，在这些年的争论中似乎总难用一句话概括清楚，但随着技术社区、企业的推动和一些理念越来越多的被人们实践，这个概念已经变得越来越清晰。&lt;br&gt;最近成都 Cloud &amp;amp; DevOps 社区整理了一个 DevOps 技能树，很有意思。对研究 DevOps
    
    </summary>
    
      <category term="DevOps" scheme="https://www.duyidong.com/categories/DevOps/"/>
    
    
      <category term="职场" scheme="https://www.duyidong.com/tags/%E8%81%8C%E5%9C%BA/"/>
    
      <category term="DevOps" scheme="https://www.duyidong.com/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>中文文档写作规范</title>
    <link href="https://www.duyidong.com/2017/05/13/chinese-document-style/"/>
    <id>https://www.duyidong.com/2017/05/13/chinese-document-style/</id>
    <published>2017-05-13T02:16:18.000Z</published>
    <updated>2017-05-13T09:51:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>作为一名程序员，良好的文风和良好的编程习惯同样重要。<br>作为一名中国区开发者，不得不面对国内技术相比英文国家滞后的事实，许多中文文档都翻译自英文。平时参加一些技术类分享的活动时，PPT、文档、README都要用中英文写，常常会很困惑一些格式如何排版比较合理，一些措辞是否适合相应场合，最近读到阮一峰老师的<a href="http://www.ruanyifeng.com/blog/2016/10/document_style_guide.html" target="_blank" rel="external">中文技术文档的写作规范</a>，当即认定是一份答疑解惑的好材料，笔者认为，不止适用于技术文档，博客、胶片，都可参考。<br><a id="more"></a></p>
<h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p>标题分为四级</p>
<pre><code> 一级标题：文章的标题

 二级标题：文章主要部分的大标题

 三级标题：二级标题下面一级的小标题

 四级标题：三级标题下面某一方面的小标题
</code></pre><p>这里主要区分一级标题通常作为文章的标题，而文章大纲类标题宜使用二级标题。<br>另外，尽量避免单个标题的情况，谨慎使用四级标题</p>
<h2 id="文本"><a href="#文本" class="headerlink" title="文本"></a>文本</h2><h3 id="字间距"><a href="#字间距" class="headerlink" title="字间距"></a>字间距</h3><ul>
<li>全角中文字符与半角英文字符之间，应有一个半角空格。</li>
</ul>
<pre><code>示例：本文介绍如何快速启动 Windows 系统。
</code></pre><ul>
<li>全角中文字符与半角阿拉伯数字之间，不需要有半角空格，必须保证风格统一。</li>
</ul>
<pre><code>示例：2011年5月15日，我订购了5台笔记本电脑与10台平板电脑。
</code></pre><ul>
<li>英文单位若不翻译，单位前的阿拉伯数字与单位间不留空格。</li>
</ul>
<pre><code>示例：一部容量为 16GB 的智能手机
</code></pre><ul>
<li>半角英文字符和半角阿拉伯数字，与全角标点符号之间不留空格。</li>
</ul>
<pre><code>示例：他的电脑是 MacBook Air。
</code></pre><p>中英文数字夹杂的情况，原则上应该让字间距显得紧凑，同时英文单词字间距规则优先。这样的排版既不张扬又不局促。</p>
<h3 id="写作风格"><a href="#写作风格" class="headerlink" title="写作风格"></a>写作风格</h3><ul>
<li>尽量不使用被动语态，改为使用主动语态。</li>
</ul>
<pre><code>错误：假如此软件尚未被安装，

正确：假如尚未安装这个软件，
</code></pre><ul>
<li>不使用非正式的语言风格。</li>
<li>用对“的”、“地”、“得”。</li>
<li>使用代词时（比如“其”、“该”、“此”、“这”等词），必须明确指代的内容，保证只有一个含义。</li>
<li>名词前不要使用过多的形容词。</li>
<li>同样一个意思，尽量使用肯定句表达，不使用否定句表达。</li>
</ul>
<pre><code>错误：请确认没有接通装置的电源。

正确：请确认装置的电源已关闭。
</code></pre><ul>
<li>避免使用双重否定句。</li>
</ul>
<pre><code>错误：没有删除权限的用户，不能删除此文件。

正确：用户必须拥有删除权限，才能删除此文件
</code></pre><p>写作风格中除了一些中学老师教过的语法错误不要犯，另外就是注意表达的简洁，准确；少用形容词，避免使用否定句，不用被动语态，都是为了达到逻辑简单，阅读流畅的目的，这一点在音译汉的时候尤其值得注意。</p>
<h3 id="英文处理"><a href="#英文处理" class="headerlink" title="英文处理"></a>英文处理</h3><ul>
<li>第一次出现英文词汇时，在括号中给出中文标注。此后再次出现时，直接使用英文缩写即可。</li>
</ul>
<pre><code>IOC（International Olympic Committee，国际奥林匹克委员会）。这样定义后，便可以直接使用“IOC”了。
</code></pre><ul>
<li>专有名词中每个词第一个字母均应大写，非专有名词则不需要大写</li>
</ul>
<pre><code>“American Association of Physicists in Medicine”（美国医学物理学家协会）是专有名词，需要大写。

“online transaction processing”（在线事务处理）不是专有名词，不应大写。
</code></pre><p>英文处理除了排版问题就是大小写（容易被忽略），另外批注虽然麻烦，但是对初次接触此类技术的人来说是非常有实用价值的。</p>
<h2 id="段落"><a href="#段落" class="headerlink" title="段落"></a>段落</h2><ul>
<li>一个段落只能有一个主题，或一个中心句子。</li>
<li>段落的中心句子放在段首，对全段内容进行概述。后面陈述的句子为核心句服务。</li>
<li>段落的句子语气要使用陈述和肯定语气，避免使用感叹语气。</li>
<li>段落之间使用一个空行隔开。</li>
<li>段落开头不要留出空白字符。</li>
<li>使用外部图片时，必须在图片下方或文末标明来源。</li>
</ul>
<pre><code>示例：本文部分图片来自 Wikipedia
</code></pre><p>图片来源一事，常常被忽略，值得注意。每段文字采用总分结构，是为了便于读者迅速理解作者表达的意思，说话的时候也可以借鉴，对于意图明确的对话场景，先表态，再阐述，会让听的人更容易听懂。</p>
<h2 id="数值"><a href="#数值" class="headerlink" title="数值"></a>数值</h2><h3 id="货币"><a href="#货币" class="headerlink" title="货币"></a>货币</h3><ul>
<li>货币应为阿拉伯数字，并在数字前写出货币符号，或在数字后写出货币中文名称。</li>
</ul>
<pre><code>$1,000
1,000 美元
</code></pre><h3 id="变化程度的表示法"><a href="#变化程度的表示法" class="headerlink" title="变化程度的表示法"></a>变化程度的表示法</h3><p>数字的增加要使用“增加了”、“增加到”。“了”表示增量，“到”表示定量。</p>
<pre><code>增加到过去的两倍
（过去为一，现在为二）

增加了两倍
（过去为一，现在为三）
</code></pre><p>数字的减少要使用“降低了”、“降低到”。“了”表示增量，“到”表示定量。</p>
<pre><code>降低到百分之八十
（定额是一百，现在是八十）

降低了百分之八十
（原来是一百，现在是二十）
</code></pre><p>不能用“降低N倍”或“减少N倍”的表示法，要用“降低百分之几”或“减少百分之几”。因为减少（或降低）一倍表示数值原来为一百，现在等于零。</p>
<h2 id="标点符号"><a href="#标点符号" class="headerlink" title="标点符号"></a>标点符号</h2><ul>
<li>中文语句中的结尾处应该用全角句号（<code>。</code>）。</li>
<li>句子内部的并列词，应该用全角顿号(<code>、</code>) 分隔，而不用逗号。英文句子中，并列词语之间使用半角逗号（<code>,</code>）分隔。</li>
<li>补充说明时，使用<strong>全角</strong>圆括号<code>（）</code>，括号前后不加空格。</li>
<li>省略号<code>……</code>表示语句未完、或者语气的不连续。它占两个汉字空间、包含六个省略点，不要使用<code>。。。</code>或<code>...</code>等非标准形式。省略号不应与“等”这个词一起使用.</li>
<li>数值范围（例如日期、时间或数字）应该使用波浪连接号（<code>～</code>），占一个全角字符的位置。</li>
</ul>
<pre><code>示例：2009年～2011年
</code></pre><p><strong>注意</strong>，波浪连接号前后两个值都应该加上单位。</p>
<h2 id="文档体系结构"><a href="#文档体系结构" class="headerlink" title="文档体系结构"></a>文档体系结构</h2><p>以下内容适用于代码文档。</p>
<h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>软件手册是一部完整的书，建议采用下面的结构。</p>
<ul>
<li><strong>简介</strong>（Introduction）： [必备] [文件] 提供对产品和文档本身的总体的、扼要的说明</li>
<li><strong>快速上手</strong>（Getting Started）：[可选] [文件] 如何最快速地使用产品</li>
<li><strong>入门篇</strong>（Basics）： [必备] [目录] 又称”使用篇“，提供初级的使用教程<ul>
<li><strong>环境准备</strong>（Prerequisite）：[必备] [文件] 软件使用需要满足的前置条件</li>
<li><strong>安装</strong>（Installation）：[可选] [文件] 软件的安装方法</li>
<li><strong>设置</strong>（Configuration）：[必备] [文件] 软件的设置</li>
</ul>
</li>
<li><strong>进阶篇</strong>（Advanced)：[可选] [目录] 又称”开发篇“，提供中高级的开发教程</li>
<li><strong>API</strong>（Reference）：[可选] [目录|文件] 软件 API 的逐一介绍</li>
<li><strong>FAQ</strong>：[可选] [文件] 常见问题解答</li>
<li><strong>附录</strong>（Appendix）：[可选] [目录] 不属于教程本身、但对阅读教程有帮助的内容<ul>
<li><strong>Glossary</strong>：[可选] [文件] 名词解释</li>
<li><strong>Recipes</strong>：[可选] [文件] 最佳实践</li>
<li><strong>Troubleshooting</strong>：[可选] [文件] 故障处理</li>
<li><strong>ChangeLog</strong>：[可选] [文件] 版本说明</li>
<li><strong>Feedback</strong>：[可选] [文件] 反馈方式</li>
</ul>
</li>
</ul>
<h3 id="文件名"><a href="#文件名" class="headerlink" title="文件名"></a>文件名</h3><p>文件名必须使用半角字符，不得使用全角字符。这也意味着，中文不能用于文件名。</p>
<pre><code>错误： 名词解释.md

正确： glossary.md
</code></pre><p>文件名建议只使用小写字母，不使用大写字母。</p>
<pre><code>错误：TroubleShooting.md

正确：troubleshooting.md
</code></pre><p>为了醒目，某些说明文件的文件名，可以使用大写字母，比如<code>README</code>、<code>LICENSE</code>。</p>
<p>文件名包含多个单词时，单词之间建议使用半角的连词线（<code>-</code>）分隔。</p>
<pre><code>不佳：advanced_usage.md

正确：advanced-usage.md
</code></pre><blockquote>
<ul>
<li>参考资料：<a href="https://github.com/ruanyf/document-style-guide" target="_blank" rel="external">https://github.com/ruanyf/document-style-guide</a></li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作为一名程序员，良好的文风和良好的编程习惯同样重要。&lt;br&gt;作为一名中国区开发者，不得不面对国内技术相比英文国家滞后的事实，许多中文文档都翻译自英文。平时参加一些技术类分享的活动时，PPT、文档、README都要用中英文写，常常会很困惑一些格式如何排版比较合理，一些措辞是否适合相应场合，最近读到阮一峰老师的&lt;a href=&quot;http://www.ruanyifeng.com/blog/2016/10/document_style_guide.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;中文技术文档的写作规范&lt;/a&gt;，当即认定是一份答疑解惑的好材料，笔者认为，不止适用于技术文档，博客、胶片，都可参考。&lt;br&gt;
    
    </summary>
    
      <category term="我的博客" scheme="https://www.duyidong.com/categories/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="文档规范" scheme="https://www.duyidong.com/tags/%E6%96%87%E6%A1%A3%E8%A7%84%E8%8C%83/"/>
    
  </entry>
  
  <entry>
    <title>云原生应用 (Cloud Native Application)</title>
    <link href="https://www.duyidong.com/2017/05/03/Cloud-Native/"/>
    <id>https://www.duyidong.com/2017/05/03/Cloud-Native/</id>
    <published>2017-05-03T03:04:03.000Z</published>
    <updated>2017-05-18T14:58:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文翻译自Pivotal的<a href="https://pivotal.io/cloud-native" target="_blank" rel="external">Cloud Native</a>。</p>
<h2 id="更快部署，更低风险，和业务一同扩展"><a href="#更快部署，更低风险，和业务一同扩展" class="headerlink" title="更快部署，更低风险，和业务一同扩展"></a>更快部署，更低风险，和业务一同扩展</h2><p>云原生应用程序是专为云上的应用而设计的。这些应用程序通过小型专用功能团队实现快速构建和频繁部署，提供了轻松扩展和硬件解耦的平台，让组织更敏捷，更具有可扩展性和云端可移植性。</p>
<h2 id="什么是云原生应用？"><a href="#什么是云原生应用？" class="headerlink" title="什么是云原生应用？"></a>什么是云原生应用？</h2><p><strong>云原生是一种充分利用云计算优势，用于构建和部署应用的方式。</strong>在过去的十几年，云已经重新定义了几乎所有行业的竞争格局，消除了企业对IT基础设施资本投入的关注，企业也不用增加雇员去维护一个自建的数据中心。取而代之的是无限的计算、存储能力，并按时按需付费。降低IT支出的同时也降低了行业壁垒，使得初创公司可以很快地实践自己的想法并应用到市场。这正是为什么软件正在吞噬世界，而创业公司正在使用云原生的方式颠覆传统行业。</p>
<p>现在的组织需要一个集成了DevOps，持续交付，微服务和容器化得平台用于构建和运维云原生应用和服务。</p>
<p><img src="/images/Cloud_Native_With_four.png" alt=""></p>
<ul>
<li><strong>DevOps</strong> 是开发和运维的合作，目标是自动化软件交付和基础设施更改过程。它创造了一个文化和环境，让构建，测试和发布软件可以快速，频繁，更可靠地发生。</li>
</ul>
<p><img src="https://d1fto35gcfffzn.cloudfront.net/images/topics/cloudnative/infographic-devops.png" alt=""></p>
<ul>
<li><strong>持续交付</strong>让单个应用随时处于可发布状态，而不用等待与其他变更绑定到一次发布中。持续交付使得发布变成一个频繁且平常的过程，因此组织可以以更低的风险经常交付，并从最终用户获得更快的反馈，直到部署成为业务流程和企业竞争力的重要组成部分。</li>
</ul>
<p><img src="https://d1fto35gcfffzn.cloudfront.net/images/topics/cloudnative/infographic-cd.png" alt=""></p>
<ul>
<li><strong>微服务</strong>是将大型应用程序转变为小型服务的集合的架构方法；每个服务实现单独的业务功能，运行在自己独立的进程中并通过HTTP API进行通信。每个微服务器都可以独立于应用程序中的其他服务进行部署，升级，扩展和重新启动，通常作为自动化系统的一部分，可以在不影响终端客户使用的情况下频繁独立更新。</li>
</ul>
<p><img src="https://d1fto35gcfffzn.cloudfront.net/images/topics/cloudnative/infographic-microservices.png" alt=""></p>
<ul>
<li><strong>容器</strong>比虚拟机（VM）提供了更高的效率和更快的速度。使用操作系统（OS）级别的虚拟化，单个操作系统实例被动态划分为多个相互独立的容器，每个容器具有唯一可写的文件系统和资源配额。创建和销毁容器的低开销，以及单个instance可高密度运行多个容器的特性使得容器成为部署微服务各个模块的完美工具。</li>
</ul>
<p><img src="https://d1fto35gcfffzn.cloudfront.net/images/topics/cloudnative/infographic-containers.png" alt=""></p>
<blockquote>
<p>我们所学到的一件事是，如果你不能更快地把你的想法推向市场，市场必然会发生变化。到这个时候，不论你如何优化，如何管理训练你的员工，都不会有很好的成效，因为已经晚了。</p>
<p style="text-align:right">– James McGlenon（美国利宝相互保险集团 执行副总裁兼首席信息官）</p>

</blockquote>
<h2 id="为什么云原生应用很重要"><a href="#为什么云原生应用很重要" class="headerlink" title="为什么云原生应用很重要"></a>为什么云原生应用很重要</h2><ul>
<li><p><strong>云是具有竞争力的优势</strong><br>  云原生意味着基础设施的目标将由节约成本变为驱动业务发展，在软件生命周期中，快速构建业务和快速交付以响应客户需求将会让企业具有主宰市场的优势。产品一旦上线就不会停止运行，且可以动态伸缩扩容。</p>
</li>
<li><p><strong>灵活性</strong><br>  企业一旦构建了应用就可以在任何云上运行而不需要修改。团队可以随时将应用在不同的公有云供应商的平台和私有云平台之间迁移或分发，以此来满足业务需求和节约开销。</p>
</li>
<li><p><strong>让开发人员做他们擅长的</strong><br>  团队拥抱云原生应用可以屏蔽不同云基础设施的差异，让开发者只用关心代码，集中精力关注在交付的业务价值。由heroku提出的<a href="https://12factor.net/zh_cn/" target="_blank" rel="external">12因素应用</a>为开发人员定义了一套云上应用的开发标准，形同一份与开发人员签订的“合同”，用于确保自己的应用程序充分利用底层的云平台的优势。</p>
</li>
<li><p><strong>运维与业务对齐</strong><br>  基于自动化的IT运维，企业可以转变为一个精益团队，将团队的关注点与推动业务发展对齐。它可以避免人工失误操作带来的风险，以流程改进代替原本的日常运维工作。通过实施在各个层面的自动补丁和自动升级，消除了宕机时间，也消除了需要“运维专家”手动修复才能解决问题的痛点。</p>
<p>  <center><strong>云原生架构：</strong>如何达到云原生</center><br>  <img src="https://d1fto35gcfffzn.cloudfront.net/images/topics/cloudnative/diagram-cloud-native-arch-01.svg" alt=""></p>
</li>
</ul>
<hr>
<h2 id="云原生与传统企业应用对比"><a href="#云原生与传统企业应用对比" class="headerlink" title="云原生与传统企业应用对比"></a><center><strong>云原生与传统企业应用对比</strong></center></h2><table>
<thead>
<tr>
<th><center>云原生应用</center></th>
<th><center>传统企业应用</center></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>可预测：</strong>云原生应用符合一个通过可预测行为来最大限度发挥弹性优势的“合同”。高自动化，容器驱动的架构使用云平台驱动改变了软件交付形式。这种“合同”的一个很好的例子就是heroku的<a href="https://12factor.net/zh_cn/" target="_blank" rel="external">十二因素应用</a>。</td>
<td><strong>不确定性：</strong>传统应用在开发方式和架构上往往不能真正发挥云服务的优势。这样的应用通常需要很长的时间来构建，一次发布很多内容，只能逐步伸缩，并常伴有许多单点故障。</td>
</tr>
<tr>
<td><strong>操作系统抽象：</strong>云原生应用要求开发者使用一个平台作为基础设施，意味着应用的基础设施是经过抽象的，更易于迁移和伸缩。构建抽象平台的方法可以自己搭建也可以购买第三方服务，比如Openshift，Cloud foundry。</td>
<td><strong>操作系统依赖：</strong>传统的应用程序架构使得开发人员习惯于在应用程序和底层操作系统，硬件，存储和后台服务之间建立紧密的依赖关系。相比于云原生应用，这种依赖会让应用的迁移和伸缩变得异常复杂和充满风险。</td>
</tr>
<tr>
<td><strong>大小适合的容量：</strong>云本地应用平台可自动进行基础设施配置，并根据应用的需求在部署时重新动态分配资源。管理好一个云原生应用运行时的全生命周期，可以做到按需伸缩，提高资源利用率，编排计算资源，以及最短宕机时间的故障恢复。</td>
<td><strong>过大容量：</strong>传统的IT设施为应用设计了专属的技术设施架构，为一个应用准备充足的基础设施资源，从而延迟应用的部署。这种设计方案通常会按照最坏情况下估算容量，解决方案的规模往往大大超过实际需要的规模。</td>
</tr>
<tr>
<td><strong>共同协作：</strong>云原生促进DevOps，人员，流程和工具的组合，从而在开发和运营之间进行密切协作，以加速和平滑将完成的应用程序代码发布到生产环境中。</td>
<td><strong>部门孤立：</strong>传统IT在开发和运维之间有高高的部门墙，开发要跨过一堵墙来向运维交付软件，组织事务优先于客户价值，导致内部冲突，妥协和缓慢的交付让员工士气低落。</td>
</tr>
<tr>
<td><strong>持续交付：</strong>IT团队的产品永远处于可发布状态。发布软件的周期保证了更短的反馈周期，并能更有效地响应客户需求。持续交付最好和其他一些实践一起使用，例如测试驱动开发和持续集成。</td>
<td><strong>瀑布模式：</strong>IT团队定期发布，通常周期为数周至数月，尽管代码已经完成构建，甚至于其他部件并无依赖，仍然不能发布。客户期望的功能总是被搁浅、延期，企业从而丧失了竞争优势、客户、和机会。</td>
</tr>
<tr>
<td><strong>独立：</strong>微服务架构将一个复杂的应用解耦为一个个小而独立的模块，这些小的服务由一个个小型团队开发和运维，确保各自独立、频繁的更新，伸缩和故障切换/重新启动，而不影响其他服务。</td>
<td><strong>依赖：</strong>单体架构将原本不需要绑定的模块绑定在一个软件包中发布，导致开发和部署过程中的敏捷性丧失。</td>
</tr>
<tr>
<td><strong>自动扩容：</strong>基础设施自动扩容可以消除宕机时间和避免人为操作失误。计算机自动化不会遇到任何类似的挑战，在任何规模的部署中都使用同一套部署脚本。云原生也超越了基于传统的面向虚拟化的业务流程的自动化实践。一个完全的云原生架构包括适用于团队的自动化和业务流程，而不是要求他们习惯于写自动化脚本。换句话说，团队的目标是使得构建和启动应用变得易于管理，而自动化只是其中的一个手段。</td>
<td><strong>手动扩容：</strong>人工基础设施包含了人工运维和人工管理的服务器，网络，以及存储配置。扩容工作因为其复杂性，运营人员很难在扩容过程中诊断问题，而且实施过程中很容易出现错误，手工编写的配置文件有可能将人为错误的硬编码到基础设施中，成为一个很难发现且长期存在的隐患。</td>
</tr>
<tr>
<td><strong>快速恢复：</strong>容器化运行时提供了一个虚拟机之上的动态，高密度的虚拟层，是理想的微服务托管方式。动态管理容器在宿主机上的编排，方便及时回滚，扩容，和重现错误。</td>
<td><strong>缓慢恢复：</strong>基于虚拟机的基础架构对于基于微服务的应用程序来说是一个缓慢而低效的基础设施，因为单个虚拟机启动/关闭的速度很慢，甚至在部署应用程序代码之前也就带来很大的开销。</td>
</tr>
</tbody>
</table>
<blockquote>
<ul>
<li>参考资料:</li>
<li><a href="https://pivotal.io/cloud-native" target="_blank" rel="external">https://pivotal.io/cloud-native</a></li>
<li><a href="https://12factor.net/" target="_blank" rel="external">https://12factor.net/</a></li>
<li><a href="https://www.duyidong.com/pdf/beyond-the-12-factor-app.pdf">https://www.duyidong.com/pdf/beyond-the-12-factor-app.pdf</a></li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文翻译自Pivotal的&lt;a href=&quot;https://pivotal.io/cloud-native&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Cloud Native&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;更快部署，更低风险，和业务一同扩展&quot;&gt;&lt;a
    
    </summary>
    
      <category term="Cloud" scheme="https://www.duyidong.com/categories/Cloud/"/>
    
    
      <category term="Cloud" scheme="https://www.duyidong.com/tags/Cloud/"/>
    
      <category term="Cloud Native" scheme="https://www.duyidong.com/tags/Cloud-Native/"/>
    
      <category term="翻译" scheme="https://www.duyidong.com/tags/%E7%BF%BB%E8%AF%91/"/>
    
  </entry>
  
  <entry>
    <title>基础设施代码测试</title>
    <link href="https://www.duyidong.com/2017/04/13/Infrastructure-as-Code-Testing/"/>
    <id>https://www.duyidong.com/2017/04/13/Infrastructure-as-Code-Testing/</id>
    <published>2017-04-13T05:41:29.000Z</published>
    <updated>2017-05-05T07:23:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>在DevOps的文化中有一个已经被广泛认可的概念叫做<a href="https://martinfowler.com/bliki/InfrastructureAsCode.html" target="_blank" rel="external">基础设施及代码</a>，意在将基础设施以配置文件的方式纳入版本管理以达到更灵活且便于管理的目的，从而更加适应基础设施频繁变更需求。</p>
<p>虽说此举俨然已将<a href="https://www.duyidong.com/2016/05/19/CI-CD/">CI/CD</a>（持续集成和持续交付）概念应用在了基础设施代码上，然而在应用产品的<a href="https://www.duyidong.com/tags/%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%8F%91%E5%B8%83/">持续部署与发布</a>实施过程中，基础设施变更仍然是一件令人<em>胆战心惊</em>的事，原因很简单——没有<strong>反馈及时</strong>且<strong>覆盖充分</strong>的测试。</p>
<p>随着基础设施即代码的不断推广，这一痛点变得越来越明显，最近一期<a href="https://assets.thoughtworks.com/assets/technology-radar-vol-16-cn.pdf" target="_blank" rel="external">ThoughtWorks技术雷达</a>中列出了两个工具<strong>Molecule</strong>和<strong>Testinfra</strong>一个是用于测试Ansible Role(如果还不知道Ansible是什么请移步我的另一篇博客：<a href="https://www.duyidong.com/2016/06/15/Ansible%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0/">Ansible学习小计</a>)，一个用于测试基础设施，下面我就来试用一下这两个工具。</p>
<h2 id="Testinfra介绍"><a href="#Testinfra介绍" class="headerlink" title="Testinfra介绍"></a>Testinfra介绍</h2><p><a href="https://github.com/philpep/testinfra" target="_blank" rel="external">Testinfra</a>是由Python社区贡献的基础设施实际状态自动化测试工具，其目标是成为<a href="http://serverspec.org/" target="_blank" rel="external">Serverspec</a>在Python中的等价物，并且作为<strong>Pytest</strong>测试引擎的插件来使用。</p>
<p>官方文档：<a href="http://testinfra.readthedocs.io/en/latest/index.html" target="_blank" rel="external">http://testinfra.readthedocs.io/en/latest/index.html</a></p>
<h3 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h3><p>环境准备：</p>
<pre><code>$ pip install testinfra      # 安装Testinfra
$ pip install paramiko       # Python的SSH支持以执行远程测试
$ pip install pytest-xdist   # 添加多线程支持
</code></pre><p>来感受下Testinfra的写法:</p>
<pre><code class="python">def test_passwd_file(File):         # 定义文件检查
    passwd = File(&quot;/etc/passwd&quot;)    # 定义文件
    assert passwd.contains(&quot;root&quot;)  # 文件是否包含关键字”root“
    assert passwd.user == &quot;root&quot;    # 文件owner是否为root
    assert passwd.group == &quot;root&quot;   # 文件所属组是否为root
    assert passwd.mode == 0644      # 检查文件权限


def test_nginx_is_installed(Package):
    nginx = Package(&quot;nginx&quot;)
    assert nginx.is_installed       # nginx是否安装
    assert nginx.version.startswith(&quot;1.10&quot;) # 检查nginx版本


def test_nginx_running_and_enabled(Service):
    nginx = Service(&quot;nginx&quot;)
    assert nginx.is_running         # 检查nginx是否已启动
    assert nginx.is_enabled         # nginx是否配置开机自启
</code></pre>
<p>基本和Python的单元测试一模一样，下面来看运行结果：</p>
<pre><code>$ testinfra -v test_myinfra.py
</code></pre><p><img src="/images/Testinfra_local_success.png" alt=""></p>
<p>报错也是PyTest的尿性：</p>
<p><img src="/images/Testinfra_local_fail.png" alt=""></p>
<h3 id="远程测试虚拟机"><a href="#远程测试虚拟机" class="headerlink" title="远程测试虚拟机"></a>远程测试虚拟机</h3><p>通过配置ssh并在启动时加入如下参数：</p>
<pre><code># -n 为指定并发数 --connection为指定链接方式
$ testinfra -n 1 -v --host=&quot;hostname&quot; --connection=ssh test_myinfra.py
</code></pre><p>感觉执行方式和Ansible有些相似，以下为执行结果：</p>
<p><img src="/images/Testinfra_remote_success.png" alt=""></p>
<p>耗时6s，中规中矩吧。</p>
<h3 id="其他功能"><a href="#其他功能" class="headerlink" title="其他功能"></a>其他功能</h3><p>除了SSH协议链接Testinfra还支持paramiko，docker，salt，kubectl等连接方式，对于Docker的测试，无外乎也是在起起来的容器上使用<code>docker exec</code>的方法对基础设施即环境配置进行验证。</p>
<p>另外Testinfra支持自定义module的形式保证测试方法的灵活性，同时Testinfra可以再PyTest之外用于调用SSH连接从而进行测试，形如：</p>
<pre><code>&gt;&gt;&gt; import testinfra
&gt;&gt;&gt; conn = testinfra.get_backend(&quot;paramiko://root@server:2222&quot;, sudo=True)
&gt;&gt;&gt; conn.File(&quot;/etc/shadow&quot;).mode == 0640
True
</code></pre><h3 id="Testinfra评价"><a href="#Testinfra评价" class="headerlink" title="Testinfra评价"></a>Testinfra评价</h3><p>在基础设施代码的测试金字塔中，Testinfra提供了以单台服务器为单位的基础设施测试，从而确保了代码有一个正确的运行环境；然而这种层面的测试即使不使用测试工具也很容易进行，与云环境紧密相关的基础设施对测试的需求应该是对架构的整体描述而不是局限于一个计算单元，这一点上，Testinfra还没有显现出它对测试金字塔高层级测试的功力。</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>基本涵盖了应用所需环境测试的内容，且可灵活扩展。</li>
<li>可读性好，学习成本低.</li>
<li>环境依赖简单，能够与项目完美结合。</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>测试未能覆盖到IaaS层的测试，仅能够在操作系统之上进行测试。对于云环境的基础设施还包括网络，负载均衡，数据库等等资源，这些都不能照顾到。</li>
<li>测试覆盖率虽然有所提升，但反馈不够及时。在开发和Debug过程中最痛苦的应该是每次使用新代码创建基础设施都要等很久才能得到反馈，这个问题并没有得到解决。</li>
<li>报错信息不够友好，个人认为基础设施的测试应该不能等同于代码层面的测试，所以PyTest的报错方式并不能让用户一眼就看到是哪方面出了错误；往远了说，要根据这个报错信息Trigger一个行为也很难做到。</li>
</ul>
<h2 id="Molecule介绍"><a href="#Molecule介绍" class="headerlink" title="Molecule介绍"></a>Molecule介绍</h2><p><a href="https://github.com/metacloud/molecule" target="_blank" rel="external">MOLECULE</a>旨在帮助开发和测试Ansible的Role。通过在虚拟机或容器上为正在运行的Ansible Role的测试构<br>建脚手架，我们无需再手工创建这些测试环境。Molecule利用Vagrant，Docker和OpenStack来管理虚拟机或容器，并支持Serverspec、Testinfra或Goss来运行测试。在sequence facility model中的默认步骤包括：虚拟机管理，Ansible语法静态检查，幂等性测试和收敛性测试。</p>
<p>话不多说，我们来看看这个工具究竟能解决什么样的问题吧。</p>
<h3 id="版本支持"><a href="#版本支持" class="headerlink" title="版本支持"></a>版本支持</h3><p>目前Molecule支持的Ansible版本为<code>2.1.4.0</code>和<code>2.2.1.0</code>，好吧，这一点，虽然项目上还在用<code>1.7.2</code>（一直担心<em>Breake change</em>所以没有升上去），但我觉得大部分公司应该使用的是<code>2.2</code>以上的版本，这一点我没有异议。</p>
<h3 id="Quick-Start-1"><a href="#Quick-Start-1" class="headerlink" title="Quick Start"></a>Quick Start</h3><p>环境准备</p>
<pre><code>$ yum install ansible -y      # 为了避免踩坑不使用pip的ansible
$ pip install docker          # 安装python的docker支持
$ pip install molecule        # 主角登场
</code></pre><p>运行</p>
<pre><code>$ molecule init --role foo --driver docker
$ cd foo
$ molecule test
</code></pre><p>运行结果：</p>
<p><img src="/images/Molecule_Test_Success.png" alt=""></p>
<p>第一次运行速度比较慢，因为运行Ansible需要到Docker镜像仓库拉取一个Ubuntu的镜像，可以从Log里看出，整个测试过程包含如下步骤：</p>
<ul>
<li>从基础镜像（Ubuntu）创建一个测试需要的镜像（docker image）</li>
<li>从镜像启动一个测试运行需要的容器（docker container）</li>
<li>开始测试，运行playbook</li>
<li>使用Testinfra判断准备环境是否正确</li>
<li>测试完毕，停止并删除容器</li>
</ul>
<p>整个过程容器的创建和销毁并没有占用很多时间，和跑一个Ansible时间相差不多。</p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>Molecule的配置文件采用的yml，可以在项目下也可以放到<code>~/.config/molecule/config.yml</code>作为默认配置，示例如下：</p>
<pre><code>---
dependency:
  name: galaxy         # Molecule使用Ansible Galaxy拉取Role
driver:
  name: docker         # 使用Docker引擎跑测试
docker:
  containers:          # 容器配置
    - name: foo
      image: ubuntu
      image_version: latest
      ansible_groups:  # 目标机器组
        - group1
verifier:
  name: testinfra      # 验证最终执行结果
</code></pre><p>其中Driver除了Docker还支持OpenStack及Vagrant，Verifier除了Testinfra还可选Serverspec及Goss。</p>
<h3 id="测试方法"><a href="#测试方法" class="headerlink" title="测试方法"></a>测试方法</h3><p>关于测试内容的定义，看一下<code>test/test_default.py</code>文件：</p>
<pre><code>import testinfra.utils.ansible_runner

testinfra_hosts = testinfra.utils.ansible_runner.AnsibleRunner(
    &#39;.molecule/ansible_inventory&#39;).get_hosts(&#39;all&#39;)


def test_hosts_file(File):
    f = File(&#39;/etc/hosts&#39;)

    assert f.exists
    assert f.user == &#39;root&#39;
    assert f.group == &#39;root&#39;
</code></pre><p>简单看来就是利用Testinfra看了下/etc/hosts是否存在，所属用户和所属组是否为root</p>
<h3 id="Molecule评价"><a href="#Molecule评价" class="headerlink" title="Molecule评价"></a>Molecule评价</h3><p>与其说Molecule是一个新的Ansible测试工具不如说是一种组合docker，Testinfra和Ansible的测试方法，换总说法它并不是一个集成在Ansible之中的更细粒度的测试方法，而是高于Ansible的更适合于放在Pipeline中作为测试Ansible运行最终结果的一个工具集，其效果大致和运行<code>docker run XXX ansible</code>之后再运行<code>Testinfra -v</code>两行shell命令是一样的</p>
<h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><ul>
<li>开始关注自动化配置脚本的测试，不失为一种尝试</li>
<li>使用Docker作为引擎，速度还可以</li>
<li>能够提升更改Ansible脚本后的构建信心</li>
</ul>
<h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>仍然要运行完Playbook才能看到结果，并没有解决<strong>反馈不及时</strong>的痛点</li>
<li>不支持细粒度的测试，且对一个playbook使用不同参数构建不同环境的应用场景也没有很好的支持</li>
<li>不管是使用Docker还是Vagrant，都增加了<em>空间</em>的消耗，且增加了<em>知识成本</em></li>
</ul>
<h2 id="综上所述"><a href="#综上所述" class="headerlink" title="综上所述"></a>综上所述</h2><p>随着DevOps的普及，已经有人开始关注基础设施代码测试这一块的工作，但这些测试工具还在初级阶段，反馈不能及时，增加覆盖面的成本也还较高，且不能很好地与云环境结合。<br>由于在软件开发中基础设施对业务价值的贡献并不明显，提升Ops技能与其说能过帮助公司挣钱不如说是帮公司省钱；而且在大部分项目中基础设施变更并没有那么频繁，紧急的问题通常还是由Ops（或者是被称为DevOps的一个角色）手动来解决，这种现象在国内公司尤其明显。大家对DevOps的认识还没有达到不一致，DevOps中的测试也还没有被定义清楚，基础设施代码的测试，还有很长的路要走。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在DevOps的文化中有一个已经被广泛认可的概念叫做&lt;a href=&quot;https://martinfowler.com/bliki/InfrastructureAsCode.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;基础设施及代码&lt;/a&gt;，意
    
    </summary>
    
      <category term="DevOps" scheme="https://www.duyidong.com/categories/DevOps/"/>
    
    
      <category term="Infrastructure as Code" scheme="https://www.duyidong.com/tags/Infrastructure-as-Code/"/>
    
      <category term="ThoughtWorks技术雷达" scheme="https://www.duyidong.com/tags/ThoughtWorks%E6%8A%80%E6%9C%AF%E9%9B%B7%E8%BE%BE/"/>
    
      <category term="基础设施即代码" scheme="https://www.duyidong.com/tags/%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD%E5%8D%B3%E4%BB%A3%E7%A0%81/"/>
    
      <category term="持续交付" scheme="https://www.duyidong.com/tags/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98/"/>
    
      <category term="Cloud" scheme="https://www.duyidong.com/tags/Cloud/"/>
    
  </entry>
  
  <entry>
    <title>离骚</title>
    <link href="https://www.duyidong.com/2017/04/12/leave-TW/"/>
    <id>https://www.duyidong.com/2017/04/12/leave-TW/</id>
    <published>2017-04-11T16:01:40.000Z</published>
    <updated>2017-05-04T12:19:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近在公司的离职群里出现了一个调查问卷，我觉得很有意思，引发了我对ThoughtWorks的一些思考，顺手贴在这里。</p>
<p>另，骚窝为ThoughtWorks音译，所以从骚窝离职的人被称为离骚。</p>
<pre><code>【骚人一】在骚窝4年多，2015年4月离开


离开骚窝后，有什么让你兴奋？

至少在一开始，创业让我兴奋；做一个自己的产品让我兴奋；

现在的工作和生活方式，与在骚窝最大的不同是什么？

用自己喜欢的技术让我兴奋。

你认为骚窝对你最大的改变是什么？

认识了一大帮牛人，体验到最好的开发方式，开拓了视野。

你最怀念骚窝哪一点儿？

骚！引领技术风骚！

你想对骚窝或者骚窝的某个人说几句话吗？

好多熟人都走了，现在回公司，有点陌生了。所以不知道说啥。
</code></pre><pre><code>【骚人二】在骚窝3年多，2009年底离开


离开骚窝后，有什么让你兴奋？

孩子的成长。

现在的工作和生活方式，与在骚窝最大的不同是什么？

出差。

你认为骚窝对你最大的改变是什么？

敏捷方法及时间管理观念（time box，迭代等）

你最怀念骚窝哪一点儿？

温馨的工作分氛围

你想对骚窝或者骚窝的某个人说几句话吗？

所有在TW一起工作过的同事：谢谢你们，依然怀念和你们在一起的时光。
</code></pre><pre><code>【骚人三】在骚窝3个月，2015年底离开


离开骚窝后，有什么让你兴奋？

重新聚焦自身优势

现在的工作和生活方式，与在骚窝最大的不同是什么？

没那么活跃了，也规律了

你认为骚窝对你最大的改变是什么？

不大。

你最怀念骚窝哪一点儿？

骨子里的自由和文艺。
</code></pre><pre><code>【骚人四】在骚窝5年，2016年7月离开


离开骚窝后，有什么让你兴奋？

全心做自己公司的产品，而不是作为vendor。

现在的工作和生活方式，与在骚窝最大的不同是什么？

公司几乎不用微信群沟通（工作上的和工作外的）。

你认为骚窝对你最大的改变是什么？

不断提升自己，接受反馈，提供反馈。

你最怀念骚窝哪一点儿？

一帮人在想办法提升工作效率。

你想对骚窝或者骚窝的某个人说几句话吗？

ThoughtWorks 一直是高标准。怀恋这个程序员的天堂。
</code></pre><pre><code>【骚人五】在骚窝1年，2016年10月离开


离开骚窝后，有什么让你兴奋？

待遇更高了，可以去产品公司了。

现在的工作和生活方式，与在骚窝最大的不同是什么？

在腾讯天天出差。

你认为骚窝对你最大的改变是什么？

对敏捷了解更深，更敢说，企业文化无比认同。

你最怀念骚窝哪一点儿？

扁平化，没心机，简单，单纯，企业文化。
</code></pre><pre><code>【骚人七】在骚窝5年，2013年离开


离开骚窝后，有什么让你兴奋？

有自己的团队了。

现在的工作和生活方式，与在骚窝最大的不同是什么？

执行多了，讨论少了。

你认为骚窝对你最大的改变是什么？

批判性思维，闭环的方法论。

你最怀念骚窝哪一点儿？

人聪明，沟通不费劲。

你想对骚窝或者骚窝的某个人说几句话吗？

一时竟然想不起该说啥...
</code></pre><pre><code>【骚人八】在骚窝4年，2014年离开


离开骚窝后，有什么让你兴奋？

移民了。

现在的工作和生活方式，与在骚窝最大的不同是什么？

毕竟是还了个国家，生活方式截然不同。

你认为骚窝对你最大的改变是什么？

ThoughtWorks给我了太多人生的第一次。

第一次做开源项目，第一次做公开演讲，第一次做售前，第一次做咨询，第一次被人骂代码写得差，第一次把项目做失败……如果没有ThoughtWorks这个平台，可能我依然在过着庸庸碌碌的日子，抱怨现实的压力但又不去设计自己的未来。

这里很累、辛苦、费脑子，在ThoughtWorks注定了要迎接一个又一个挑战，而且很多都是突如其来的。比如在你开会的时候销售总监把你拉出来说过几天有个项目要上，你去一下。

这里有很多很优秀的人，而且更重要的是，他们完全不吝啬将自己的经验、经历、思考问题的过程拿出来跟人分享。当看到他们的邮件他们的博客，我就有种感觉，这些人的存在完全就是为了在你前行的路上亮起一盏灯光，甚至供你仰望的。但这种感觉很好。当你困惑的时候有人诉说，当你懈怠的时候知道其他人都在干什么。

在出差的过程中你会跟同事们结下深厚的友谊，一起准备session，总结回顾，规划项目前景，解决疑难……一切的一切，在过往的工作经历中都是体会不到的。

有一天我选择了走自己的路，但是我前些日子面试的时候，面试官是ThoughtWorks墨尔本办公室之前的Mobile Tech Lead，我问他跟我结对编程过后的感受，他说，“感觉很舒服，很自在，就像回到了ThoughtWorks一样”。那一刻我深刻的感觉到了四年间ThoughtWorks在我身上留下的烙印。

你最怀念骚窝哪一点儿？

人。
</code></pre><pre><code>【骚人九】在骚窝4年,2016年离开


离开骚窝后，有什么让你兴奋？

投入到建设国家健康医疗大数据平台的试点工程中

你现在的工作和生活方式，与在骚窝最大的不同是什么?

周围可用的人才太少，或者可塑之才太少

你认为骚窝对你最大的改变是什么？

开放的理念，社会公正的实践，当然也有自己技术上的提高

你最怀念骚窝哪一点儿？

随便抓个人都能打硬仗

你想对骚窝或者骚窝的某个人说几句话吗?

加油
</code></pre><pre><code>【骚人十】在骚窝3年,3年前离开

离开骚窝后，有什么让你兴奋？

干事终有有头有尾了。

你现在的工作和生活方式，与在骚窝最大的不同是什么?

专注，可以专注于一个产品，围着这个产品方方面面都做。

全功能，技术不再是唯一的关注点，市场，运营，业务，营收，广告，管理团队，修网络，搭VPN，交办公室租金，给新来的小朋友买电脑，和打扫卫生的阿姨唠嗑......

你认为骚窝对你最大的改变是什么？

开阔了视野，给了一种可能

你最怀念骚窝哪一点儿？

人，还是那帮人，虽然大部分都离职了

你想对骚窝或者骚窝的某个人说几句话吗?

喵同学，你还在等什么
</code></pre><pre><code>【骚人十一】在骚窝两年半,一零年一月离开


离开骚窝后，有什么让你兴奋？

拿到了全额奖学金去美国读书了。当学生的感觉和在骚窝差不多，一样兴奋😊 毕业后去了谷歌

你现在的工作和生活方式，与在骚窝最大的不同是什么?

我现在在谷歌总部的搜索架构组，需要是做大规模的并发系统的开发和优化。这里软件过程比较少。需求都是自己提的。少了些思想的碰撞。当然赚的多了些😄

你认为骚窝对你最大的改变是什么？

接触到不同的客户锻炼到自己的同理心了。了解到了每个人看问题的不同角度。当然明白了软件开发的流程。现在我还在用这些方式来组织我带领的技术小组的开发工作。

你最怀念骚窝哪一点儿？

结对编程😄很喜欢和不同的人工作。学到很多知识、结识了很对朋友

你想对骚窝或者骚窝的某个人说几句话吗?

当时走得很匆忙，没能和大家打好招呼。后来的这些年很想念大家。希望有机会能再见。
</code></pre><pre><code>【骚人十四】在骚窝4年半,2013.05离开

离开骚窝后，有什么让你兴奋？

业余生活丰富起来，聚会多起来。好奇怪，很多人说国外好寂寞。

你现在的工作和生活方式，与在骚窝最大的不同是什么?

工作：各种不靠谱程序员，各种号称扁平是管理的老板。

生活变化不大。

你认为骚窝对你最大的改变是什么？

在职场人和人可以这样高效自组织协作。

你最怀念骚窝哪一点儿？

feedback，开放式协作

你想对骚窝或者骚窝的某个人说几句话吗?

你仍然是我爱的最深的那家前公司。你最初的梦想是很多人至今的梦想，在我们心里你永远祝福你不忘初心。
</code></pre><pre><code>【骚人十五】在骚窝一年半,2016年离开

是否得到了当初离开时想要追求的东西？

是

离开骚窝后，有什么让你兴奋？

周围同事平均水平更高了，不用和客户撕扯了，可以专心做东西

你现在的工作和生活方式，与在骚窝最大的不同是什么?

不用每天各种会和敏捷形式化了

你认为骚窝对你最大的改变是什么？

敏捷开发更适合交付项目

你最怀念骚窝哪一点儿？

压力小，交付项目做完就不用操心维护和业务了，不用oncall

你想对骚窝或者骚窝的某个人说几句话吗?

谢谢大家的帮忙^_^美帝血汗工厂的微服务做的一点也不好^_^
</code></pre><pre><code>【骚人十六】在骚窝俩年多,2013年底离开

是否得到了当初离开时想要追求的东西？

离开时没有什么新的追求

离开骚窝后，有什么让你兴奋？

做不同的事情，尝试不同的岗位

你现在的工作和生活方式，与在骚窝最大的不同是什么?

自由

你认为骚窝对你最大的改变是什么？

觉得牛人还是很多的，上学的时候觉得牛人太少

你最怀念骚窝哪一点儿？

年轻的朋友们
</code></pre><pre><code>【骚人十七】在骚窝1.3,2015离开

是否得到了当初离开时想要追求的东西？

差不多

离开骚窝后，有什么让你兴奋？

能将自己所学的项目管理方法，学以致用，以证明自己哪些是用的，哪些是错的。

你现在的工作和生活方式，与在骚窝最大的不同是什么?

生活方式没有变，工作变了，要学会适应非全功能团队的协作方式（可以是中国传统的协作方式）

你认为骚窝对你最大的改变是什么？

思维方式变了。也变得更包容了。眼界变得开拓了。

你最怀念骚窝哪一点儿？

在TW待过两个团队，和他们一起工作时的氛围。也就是和他们一起工作太开心了。

你想对骚窝或者骚窝的某个人说几句话吗?

胡凯，感谢你抽时间回复我邮件，帮助我成长。还有，你是对的，我真的又离职了，产品终归是别人的，我没有能“做自己的产品”。

我知道了，除非自己做老板，不可能完全做自己的产品。
</code></pre><pre><code>【骚人十八】在骚窝1年,2016-10离开

是否得到了当初离开时想要追求的东西？

追求的东西一直都在变化，随着年龄的增长追求的内容也不同，离开以后发现了更多需要自己去熟悉的内容，不仅仅局限在dev范围内部。有得也有失。

离开骚窝后，有什么让你兴奋？

可以全身心的工作到自己的产品中，在离骚每个项目做完以后，就会有另一个项目等着你，之前做过的项目到底是否成功，用户量有多大，并没有多少反馈。项目的结束给我带来的成就感远远小于自己做一个产品上线以后，看到不断有用户注册时的激动。

你现在的工作和生活方式，与在骚窝最大的不同是什么?

不用天天在客户现场应对各种问题和challenge.

你认为骚窝对你最大的改变是什么？

对技术栈的重新定义，对客户的认识以及业务知识

你最怀念骚窝哪一点儿？

自由的工作方式，自己想做点什么事情没有任何阻拦。

你想对骚窝或者骚窝的某个人说几句话吗?

对Dev说，技术不是最终的追求，这个世界是业务起主导作用的世界，没有业务驱动技术很难有实施性的发挥。当技术和业务发生冲突的时候，临时的避让或者妥协是很好的解决方案。没有清晰的对错分界线，也没有技术水平高低的判断条件。当产品满足业务需求，当客户欣然接受，这就是最好的交付结果。远比用各种fashion的技术栈来得实在。

对业务说，业务是主导一切的根源，发现业务和挖掘业务也许是未来发展的新标向。在骚窝做业务的同学们应当发挥比dev更重要的作用，你们是技术实现的基石，也是客户的向导。

对UX说，你们的水平可以说是目前竞争对手中做得最好的团队，一个产品的设计在默写程度上可以左右项目的认可度，提高产品的Level。当客户第一眼看到产品的时候，他们看的不是你用了reactjs还是vuejs，也不是业务需求是否满足。而是产品的外观是否吸引用户。提高设计能力和水平是骚窝继续往下发展的重要法宝。

对PM说，在如此竞争激烈的市场下，每个团队都可以快速开发MVP并投入市场。敏锐的发现市场需求和控制项目进度是制胜的法宝，让客户把他们的成败压在咱们的交付产品或咨询上是把拉近客户的必要手段，我们不一定一直处在乙方的位置，真要是到了一定程度，说不定谁是乙方谁是甲方。提高我们在客户面前的话语权，深度挖掘积累某个行业、领域的知识是我们项目往下走的方向。
</code></pre><pre><code>【骚人十九】在骚窝6年多,2013离开

是否得到了当初离开时想要追求的东西？

还行

离开骚窝后，有什么让你兴奋？

踏踏实实做产品

你现在的工作和生活方式，与在骚窝最大的不同是什么?

工作上更注重流程了，也更注重每个决策的长期影响

生活上没有国内那么丰富，但得到了环境上的回报

你认为骚窝对你最大的改变是什么？

锻炼了思维方式，从其他角度看软件开发

你最怀念骚窝哪一点儿？

丰富的思维碰撞

你想对骚窝或者骚窝的某个人说几句话吗?

希望每个骚窝人不忘初心，成为思想工作者，通过软件成为更好的自己
</code></pre><p>从以上调查中可以大致可以分析得出以下信息：</p>
<ul>
<li>前TWer们大部分是比较认可TW的企业文化的，认为这里有一帮聪明且主动性强的同事，以及宽松自由的工作环境，想做就做的干劲，同时也有会议太多，沟通花费过高等弊病</li>
<li>离职后的人一部分人创业，一部分人移民，一部分在国内大公司发展</li>
<li>在TW时往往只能受雇于人做一些产品开发，这常常成为TWer离职的原因——没有自己的产品</li>
</ul>
<p>在以上发言中，七号，十一号，十八号，给我的印象最为深刻。<br>曾经有人告诉我：入职第一天就为离职做好准备的员工是好员工。因为这样的员工往往会保持高度的警惕且持续学习，随时辞职随时都能找到更好待遇的工作的目标，保证了员工提供给公司是高于自己待遇的价值。<br>所以企业最看重的，是价值；职场上最重要的，应该是人。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在公司的离职群里出现了一个调查问卷，我觉得很有意思，引发了我对ThoughtWorks的一些思考，顺手贴在这里。&lt;/p&gt;
&lt;p&gt;另，骚窝为ThoughtWorks音译，所以从骚窝离职的人被称为离骚。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;【骚人一】在骚窝4年多，2015年4月离
    
    </summary>
    
      <category term="ThoughtWorks" scheme="https://www.duyidong.com/categories/ThoughtWorks/"/>
    
    
      <category term="ThoughtWorks" scheme="https://www.duyidong.com/tags/ThoughtWorks/"/>
    
      <category term="职场" scheme="https://www.duyidong.com/tags/%E8%81%8C%E5%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>AWS助理架构师认证考经</title>
    <link href="https://www.duyidong.com/2017/04/05/How-to-pass-the-aws-certification/"/>
    <id>https://www.duyidong.com/2017/04/05/How-to-pass-the-aws-certification/</id>
    <published>2017-04-05T06:48:45.000Z</published>
    <updated>2017-05-04T12:25:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>上周去参加了AWS助理级架构师的考试并顺利通过，是2017年的第一个小目标也是对云服务知识的一个检验，在此分享一下考试的经过和经验。</p>
<h1 id="什么是AWS认证"><a href="#什么是AWS认证" class="headerlink" title="什么是AWS认证"></a>什么是AWS认证</h1><p>亚马逊作为云计算领域的领头羊，在云计算领域已经有了十多年的积累，亚马逊的云计算不论是从服务还是性能在全球都是首屈一指的。近年来国内有很多创业公司依托于阿里云，微软云，Ucloud等IaaS, PaaS服务构建了许多SaaS服务，其中不乏客如云之类的成功案例，许多大型企业也将自己的基础设施往云上迁移。近两个月腾讯云和中国电信两次以0.01元中标政府云服务项目更是起到了推波助澜的作用。如此种种，可见云服务在IT届的地位已经越来越高，对于从业者的云计算知识要求也必然会越来越高。那么考取云服务界领头羊亚马逊的认证也会变得越来越有价值。<br>AWS目前仅有助理级和专家级两个级别，2017年还会加入大数据，安全，网络三个认证。<br>就目前有的认证而言，开发者(Developer)认证应该是最好考的，助理方案解决架构师(Solutions Architect)次之，助理级最难的是运维（SysOps）。要取得专家级认证必须先取得助理级认证，关系如图：</p>
<p><img src="/images/AWS_Certification_Level.png" alt=""></p>
<p>关于八个认证的难以程度即考取顺序建议如下：</p>
<p><img src="/images/AWS_Certification_Easy_to_Hard.png" alt=""></p>
<p>笔者选择先考助理架构师，意在先建立一个比较全面和高视角的认识，再考Developer和Sysops也会比较容易。<br>AWS认证是检测自己云计算领域知识最好的方式，同时也是增加求职筹码的一个不错的选择。</p>
<h1 id="我的考试经历"><a href="#我的考试经历" class="headerlink" title="我的考试经历"></a>我的考试经历</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>笔者在准备考试前有一些AWS的使用经历，大部分在项目中使用，但服务涉及很窄，基本只限于创建instance，明白不同Subnet意味着不同网段。<br>为公司项目做过AWS的虚拟机方案预算，基本知道Instance Type以及Cost有关的一些东西。<br>从开始准备到正式考试大概两个月，每天投入3-4小时，主要花费在阅读文档和动手练习，另外还买了<a href="https://acloud.guru" target="_blank" rel="external">acloud.guru</a>上的一个课程，价格29美刀，没有购买AWS的练习题。</p>
<h2 id="考前准备"><a href="#考前准备" class="headerlink" title="考前准备"></a>考前准备</h2><ul>
<li>参考AWS官方<a href="https://aws.amazon.com/certification/certification-prep/" target="_blank" rel="external">考试介绍</a>定位考试的大致方向</li>
<li>仔细阅读<a href="https://awstrainingandcertification.s3.amazonaws.com/production/AWS_certified_solutions_architect_associate_blueprint.pdf" target="_blank" rel="external">考试大纲</a>，了解考试设计到的知识点和大纲</li>
<li>根据AWS的<a href="http://aws.amazon.com/cn/documentation/" target="_blank" rel="external">官方文档</a>梳理了<a href="https://www.duyidong.com/2017/02/28/AWS-Services-Overview/">AWS现有的重要服务</a></li>
<li>认真过了一遍关于<a href="https://www.duyidong.com/2017/03/15/AWS-EC2/">EC2</a>，<a href="https://www.duyidong.com/2017/03/06/%E6%B5%85%E8%B0%88AWS-IAM/">IAM</a>，<a href="https://www.duyidong.com/2017/03/13/AWS-S3/">S3</a>有关的文档，这几个服务加上VPC和RDS为考察的重点，同时也是AWS的核心服务</li>
<li>在AWS上做了一些操作练习，主要包括：<ul>
<li>在AWS上搭建了public &amp; private subnet的<a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenario2.html" target="_blank" rel="external">典型网络结构</a></li>
<li>在AWS上搭建了一个ELB+Autoscaling的高可用的网站</li>
<li><a href="https://www.duyidong.com/2017/03/07/Deploy-Hexo-to-S3/">将自己的博客迁移到AWS上</a>，并<a href="https://www.duyidong.com/2017/03/20/Enable-HTTPS-and-CDN-with-Cloudfront/">使用Cloudfront做CDN和Route53做DNS解析</a></li>
</ul>
</li>
<li>仔细大量地阅读了<a href="https://aws.amazon.com/faqs/" target="_blank" rel="external">FAQ</a></li>
<li>看了一下AWS的几个<a href="https://aws.amazon.com/whitepapers/" target="_blank" rel="external">白皮书</a>，包括<a href="https://d0.awsstatic.com/whitepapers/aws-overview.pdf" target="_blank" rel="external">AWS服务概览</a>，<a href="https://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf" target="_blank" rel="external">关于架构</a>，<a href="https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf" target="_blank" rel="external">安全最佳实践</a>，<a href="https://d0.awsstatic.com/whitepapers/AWS_Cloud_Best_Practices.pdf" target="_blank" rel="external">AWS最佳实践</a>，主要认真理解了<a href="https://www.duyidong.com/2017/03/23/AWS-well-architected-framework/">什么样的架构是一个良好的架构</a></li>
<li>做了大约两百道练习题，事实在上考试的时候有百分之二十的都是在见过的原题。</li>
</ul>
<h2 id="考试"><a href="#考试" class="headerlink" title="考试"></a>考试</h2><p>考试首先要在网上注册预约：<a href="https://www.webassessor.com" target="_blank" rel="external">https://www.webassessor.com</a>，需要visa卡支付，并提供公司名称，地址等信息。<br>考试地点在<a href="https://www.google.com/maps/place/Shangpu+Fortune+Center+Plaza/@30.6525977,104.0673653,17z/data=!3m1!4b1!4m5!3m4!1s0x36efc53df2a6a879:0x5c54ecee2ff20a3c!8m2!3d30.6525977!4d104.069554" target="_blank" rel="external">成都上普财富中心2514鸿景国际教育</a>，锦江宾馆地铁站出站走几步就是，是一家代理考试点，每次同时只有一个人考试，在一个独立的房间，有一位监考员，负责帮你准备考试的环境。考试原则上不允许带手机，使用考点的笔记本电脑，并且是远程连接到美国，所以网络会比较卡顿，经常做题做着做着就白屏了，需要刷新才能继续，有些考验心理素质。<br>考试是80分钟60道题，据说判断是否过关是根据一段时间考试的人的成绩取排名靠前的百分之六十的人作为比较，达到这个标准就算过关，考试完后立马知道分数。根据以往的经验，一般分数在65分以上可以过关。考试分单选和多选，多选题会有提示有几个选项，每道题可以标记“Mark this item for later review”，系统会在答题完成后给出所有待检查的题号以重新作答，还是比较方便的。<br>根据考试经验，得分往往会低于做的时候的感觉期望，由于考试时间并不紧张（笔者在完成答题后还剩半个小时交卷），一定要认真检查，最好知道每个题要考察你什么知识，很多题都是有坑的，如果你能把考察点说出来，这道题多半是没有问题的。<br>考试完后随即你就会在邮箱里收到一封这样的证书：</p>
<p><img src="/images/AWS_Certification_SAA.jpeg" alt=""></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>AWS方案解决架构师助理级的考试总的来说难度不大，主要考察的就是在何种需求场景下应该选择AWS的何种服务，考试分为设计一个符合<a href="https://www.duyidong.com/2017/03/23/AWS-well-architected-framework/">最好架构</a>设计原则的系统；工具和开发；安全；以及解决问题四个部分，<strong>设计一个良好的架构</strong>是最重要的也是最能体现云服务意义的，需要好好准备。<strong>工具和开发</strong>考察的是动手操作的能力，一般做够几个实验都没什么问题。<strong>安全</strong>方方面面都有涉及，考察的比较细致，主要是针对不同场景需要使用权限管理，网络管理，服务策略管理等不同方式，配合AWS的<a href="https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf" target="_blank" rel="external">安全最佳实践白皮书</a>问题不大。最后一个<strong>解决问题</strong>在AWS文档中很多部分都是Troubleshooting，比如<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html" target="_blank" rel="external">Troubleshooting Connecting to Your Instance</a>，<a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot.html" target="_blank" rel="external">Troubleshooting IAM</a>，<a href="https://aws.amazon.com/premiumsupport/knowledge-center/elb-connectivity-troubleshooting/" target="_blank" rel="external">Elastic Load Balancing Connectivity Troubleshooting</a>都是可能被考察的内容，需要阅读文档的时候足够仔细。<br>另外，给出一些考试资料供参考：</p>
<blockquote>
<ul>
<li>AWS测试题：<ul>
<li><a href="https://quizlet.com/152377618/aws-certified-solutions-architect-associate-practice-questions-flash-cards/" target="_blank" rel="external">https://quizlet.com/152377618/aws-certified-solutions-architect-associate-practice-questions-flash-cards/</a></li>
<li><a href="http://www.aiotestking.com/amazon/category/exam-aws-saa-aws-certified-solutions-architect-associate/" target="_blank" rel="external">http://www.aiotestking.com/amazon/category/exam-aws-saa-aws-certified-solutions-architect-associate/</a></li>
</ul>
</li>
<li>一个关于考试的feedback: <a href="https://acloud.guru/forums/aws-certified-solutions-architect-associate/discussion/-KSDNs4nfg5ikp6yBN9l/exam_feedback_-_20_specific_po" target="_blank" rel="external">https://acloud.guru/forums/aws-certified-solutions-architect-associate/discussion/-KSDNs4nfg5ikp6yBN9l/exam<em>feedback</em>-_20_specific_po</a></li>
<li>AWS博客：<a href="https://aws.amazon.com/blogs/aws/" target="_blank" rel="external">https://aws.amazon.com/blogs/aws/</a></li>
<li>两篇同事的博客：<ul>
<li><a href="http://www.huangbowen.net/blog/2014/10/27/how-to-pass-the-aws-certification/" target="_blank" rel="external">http://www.huangbowen.net/blog/2014/10/27/how-to-pass-the-aws-certification/</a></li>
<li><a href="http://www.jianshu.com/p/02233ae66b80" target="_blank" rel="external">http://www.jianshu.com/p/02233ae66b80</a></li>
</ul>
</li>
<li>Jayendra的博客：<a href="http://jayendrapatil.com/" target="_blank" rel="external">http://jayendrapatil.com/</a></li>
<li>Youtube上deep dive的视频：<a href="https://www.youtube.com/results?search_query=aws+deep+dive" target="_blank" rel="external">https://www.youtube.com/results?search_query=aws+deep+dive</a></li>
<li>AWS官方教学小视频： <a href="https://aws.amazon.com/training/intro_series/" target="_blank" rel="external">https://aws.amazon.com/training/intro_series/</a></li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上周去参加了AWS助理级架构师的考试并顺利通过，是2017年的第一个小目标也是对云服务知识的一个检验，在此分享一下考试的经过和经验。&lt;/p&gt;
&lt;h1 id=&quot;什么是AWS认证&quot;&gt;&lt;a href=&quot;#什么是AWS认证&quot; class=&quot;headerlink&quot; title=&quot;什么
    
    </summary>
    
      <category term="Amazon Web Services" scheme="https://www.duyidong.com/categories/Amazon-Web-Services/"/>
    
    
      <category term="学习" scheme="https://www.duyidong.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AWS" scheme="https://www.duyidong.com/tags/AWS/"/>
    
      <category term="云计算认证" scheme="https://www.duyidong.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97%E8%AE%A4%E8%AF%81/"/>
    
      <category term="Certification" scheme="https://www.duyidong.com/tags/Certification/"/>
    
      <category term="AWS认证考试" scheme="https://www.duyidong.com/tags/AWS%E8%AE%A4%E8%AF%81%E8%80%83%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>AWS认为，什么样的架构是一个良好的架构</title>
    <link href="https://www.duyidong.com/2017/03/23/AWS-well-architected-framework/"/>
    <id>https://www.duyidong.com/2017/03/23/AWS-well-architected-framework/</id>
    <published>2017-03-23T14:01:23.000Z</published>
    <updated>2017-05-05T07:23:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>AWS Well Architected framework，其实是亚马逊的一封<a href="https://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf" target="_blank" rel="external">白皮书</a>，围绕云架构设计的安全性，可靠性，负载，花销，运维（2016年11月加入）五个支柱阐述了一个良好的架构应该遵循什么样的原则，以及一些最佳实践。</p>
<p>亚马逊在云服务届处于世界领先水平，且在十多年的云架构实践中已经积累了相当的经验，该白皮书是对这些经验的一个总结和提炼。不管是对于考试，对于成为一个云架构师，还是对于单纯的学习和了解云服务，都是一份不可多得的好材料。<br>下面附上资源地址：<a href="https://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf" target="_blank" rel="external">https://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf</a></p>
<h2 id="啰嗦几句"><a href="#啰嗦几句" class="headerlink" title="啰嗦几句"></a>啰嗦几句</h2><p>自从互联网诞生以来，各互联网公司通过将自己服务器的端口暴露在公共网络的方式提供服务，普通用户通过供应商接入公共网络，与公司服务器建立连接进行数据传输，从而实现“上网”的功能。对普通用户而言，终端以外的世界都是黑盒，而对于提供服务的互联网公司而言，则要运维大量的服务器，交换机等设备，为了保证服务的可靠性，容灾能力，为了开发，测试，常常需要维护超过实际提供服务的服务器数量很多倍的基础设施。又例如，在淘宝双十一期间可能由于用户访问量基层淘宝需要临时增加一倍的服务器数量来保证服务的正常运行，而在活动结束后，又需要恢复正常的服务器数量，那么这多出来的一倍服务器难免就会造成资源浪费。而且在很多时候，传统运维的背景下，申请一台服务器时间很长，手续繁琐，为了方便，研发部门通常会申请超出所需的基础设施资源，“以备不时之需”，这样的情况也会给企业造成大量的浪费。云服务，就是为了解决这种种问题而诞生的。</p>
<p><img src="/images/Cloud_better.png" alt=""></p>
<p>最简单的云服务模型，就是在云服务厂商集中托管了一个超级大型的服务器群，云服务厂商通过对外租赁服务器的形式代替了互联网厂商自己维护服务器的方式。这样做的好处在于一是避免了闲置基础设施资源的浪费，二是随着云服务的不断普及，以及Agile，DevOps运动的兴起，人们对IT设施的灵活度要求越来越高，这两年Infrastructure as Code（基础设施即代码）的理念已经被越来越多的厂商应用到生产实践中去，基础设施及代码的理念，和云服务是一脉相承的，租户可以更快地申请到设备，可以更灵活的对自己的设备定制化，规定大小，容量，甚至预配置一些环境，和自己的服务紧耦合，使公司的生产活动可以跟多的关注在业务上，而不用去操心服务器的性能，预估自己能承受的访问量，从而给业务发展带来更大的发展空间。这一点表现在今年AWS大力在推行的的Serverless架构上。<br>在笔者看来，云服务并不是一个技术上的创新，而更像是一种商业模式，为了让企业更灵活的适应瞬息万变的市场和用户需求，为了使社会资源更加合理化配置，同时，云服务也是信息全球化的重要一环，为人工智能，大数据奠定了基础。</p>
<h1 id="如何定义一个良好的架构"><a href="#如何定义一个良好的架构" class="headerlink" title="如何定义一个良好的架构"></a>如何定义一个良好的架构</h1><p>AWS从五大支柱来判定一个架构设计得是否优秀：</p>
<ul>
<li><strong>Security</strong>安全：保护信息，系统安全，在风险可控的前提下对外提供服务，以及迁移的策略</li>
<li><strong>Reliability</strong>可靠：系统的容错能力和自我修复能力，系统在负载增加时动态获取计算资源以满足业务需求，以及在系统模块发生故障时自动替换掉故障模块</li>
<li><strong>Performance Efficiency</strong>负载能力：根据系统需要，伸缩负载的能力</li>
<li><strong>Cost Optimization</strong>资费优化：在满足需求的情况下花尽可能少的钱</li>
<li><strong>Operational Excellence</strong>运维出色：业务连续性，系统状况监控预警能力</li>
</ul>
<h3 id="一般设计原则（General-Design-Principles）"><a href="#一般设计原则（General-Design-Principles）" class="headerlink" title="一般设计原则（General Design Principles）"></a>一般设计原则（General Design Principles）</h3><ul>
<li>停止估算需要多少基础设施，架构可以根据业务情况灵活伸缩</li>
<li>构建一个和生产环境完全一致的测试环境，你可以在测试环境完全模拟生产环境的情形，并在完成测试之后清理掉所有资源</li>
<li>自动化使架构变更的风险更低，基础设施及代码的好处，让架构可复制，架构变更变得可追踪，且减少了很多情况认为操作带来的风险</li>
<li>允许架构更灵活地变更，一是风险更低，因为变更可追溯，二是架构可以被及时回滚，三是彻底的变更成本很小</li>
<li>数据驱动型架构，灵活的架构方式允许你使用面向数居的架构方式</li>
<li>通过“game day”来提升架构，由于架构可以被轻易的复制且用户只需要按使用付费，租户可以在任意时候测试自己的架构是否存在安全漏洞，是否存在可以被改进的地方</li>
</ul>
<p>下面白皮书围绕以上提到的几大优秀架构的设计支柱，提出了一系列设计原则，最佳实践以及实践这些最佳实践可以用到的服务：</p>
<h2 id="安全（Security-Pillar）"><a href="#安全（Security-Pillar）" class="headerlink" title="安全（Security Pillar）"></a>安全（Security Pillar）</h2><h3 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h3><ul>
<li>在每一个层面引入安全：除了应用安全还应该在网络，负载均衡器，防火墙，操作系统关注安全</li>
<li>可追溯：保证系统的每一次操作/更改都被记录日志，并对日志进行审查</li>
<li>确保“最小权限原则”：确保每一个资源都被赋予了恰好需要的最小权限，实时审查这些权限，及时清理掉没用的权限</li>
<li>关注在你的系统安全：根据AWS的责任划分模型，关注在用户应该负责的系统安全和数据安全层面<br><img src="https://d0.awsstatic.com/security-center/NewSharedResponsibilityModel.png" alt=""></li>
<li>自动化安全最佳实践：使用基于应用层的策略保证安全问题能够被快速修复，例如，创建打好补丁的镜像，然后让所有之后创建的instance使用这个镜像；再例如，对常见安全问题自动响应和自动修复故障</li>
</ul>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>AWS将最佳实践划分为五个范畴：</p>
<ul>
<li>数据保护</li>
<li>认证和权限管理</li>
<li>架构保护</li>
<li>追踪控制</li>
<li>事件响应</li>
</ul>
<p>在设计你的架构之前，你需要知道谁可以对你的系统做什么，此外，你还希望确定判断每个发生在系统的事件是否安全，保护你的操作系统和服务，你需要维护和保密你的数据，你还需要做到系统对安全事件能够自动响应。</p>
<h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><h4 id="数据保护"><a href="#数据保护" class="headerlink" title="数据保护"></a>数据保护</h4><p>确认只有必要的用户有访问部分数据的权限，确保数据在存储时被加密，传输过程中被加密，使用IAM，以下实践可以保证你的数据安全：</p>
<ul>
<li>AWS的用户享有对所有数据完全的控制权</li>
<li>AWS确保用户可以轻松对自己的数据进行加密，并提供方法管理加密所使用的key，并可以通过AWS或者用户自己定义的方式自动定期更换key（Key Management Service）</li>
<li>AWS允许开启详细的日志信息，包括文件的权限变更（CloudTrail）</li>
<li>AWS提供极高的可用性保证你的数据不会丢失（S3）</li>
<li>开启版本管理，可以作为数据生命周期的一部分，可以保护对数据的误操作</li>
<li>AWS默认不会对数据做跨Region的转移或备份，即数据不会离开它所在Region的“国家/城市”</li>
</ul>
<p>另外两个重要的问题：</p>
<ul>
<li>如何保证数据存储时加密？</li>
<li>如何确保数据传输过程的加密？（SSL）</li>
</ul>
<h4 id="认证和权限管理"><a href="#认证和权限管理" class="headerlink" title="认证和权限管理"></a>认证和权限管理</h4><p>通过亚马逊的AMI，租户可以完全控制根账户下每个用户，以及应用对所有资源的访问权限，确保每个User和Role只拥有必须的权限是必要的，同时确保每个资源只在被授权的情况下才能够被访问和使用。常见的权限管理包含以下内容：</p>
<ul>
<li>ACL（用于管理用户对于S3中存放对象的操作访问权限）</li>
<li>基于Role的权限控制</li>
<li>密码管理（定期更换密码）</li>
</ul>
<p>同样，几个问题：</p>
<ul>
<li>如何保证根账户的安全？（是否开启了第三方验证，是否删掉了Access Key）</li>
<li>如何保证User和Role的权限是安全的？（是否使用Group管理用户）</li>
<li>如何限制应用程序，脚本，或第三方工具对AWS资源的控制访问权限？</li>
<li>如何管理Key和证书？</li>
</ul>
<h4 id="架构保护"><a href="#架构保护" class="headerlink" title="架构保护"></a>架构保护</h4><p>通常来说架构保护指的是对本地数据中心的保护，在AWS的白皮书中主要提到的是对于VPC的保护，主要包括VPC中的Security Group，Network Control list，路由策略</p>
<p>几个问题：</p>
<ul>
<li>如何管理你的网络策略，和设备安全？（是否有内外网划分，在外网的Instance的登录验证是怎样的，有没有开启多重验证）</li>
<li>服务层面的安全管理？（多少用户有对你资源的访问权限，是否有对这些用户进行分组管理，是否对这些用户的验证进行了强行的限制，如强密码和定期更换密码，等等）</li>
<li>如何保证你的系统安全，如何运维监控你的服务？</li>
</ul>
<h4 id="追踪控制"><a href="#追踪控制" class="headerlink" title="追踪控制"></a>追踪控制</h4><p>以下服务可以用于设施变更的追溯及审查：</p>
<ul>
<li>CloudTrail，用于记录AWS API的每一次操作，并生成日志保存在S3中</li>
<li>Amazon CloudWatch，用于实时监控和预警</li>
<li>AWS Config</li>
<li>Amazon S3</li>
<li>Amazon Glacier</li>
</ul>
<p>常见问题：</p>
<ul>
<li>如何获取和分析你的日志？</li>
</ul>
<h3 id="涉及到的服务（Key-AWS-Services）"><a href="#涉及到的服务（Key-AWS-Services）" class="headerlink" title="涉及到的服务（Key AWS Services）"></a>涉及到的服务（Key AWS Services）</h3><ul>
<li>数据保护：加密数据存储和传输：ELB, S3 &amp; RDS</li>
<li>权限管理：IAM, MFA</li>
<li>架构保护：VPC, NCL, SG</li>
<li>追踪控制：CloudTrail, Config, CloudWatch</li>
</ul>
<h2 id="可靠性（Reliability-Pillar）"><a href="#可靠性（Reliability-Pillar）" class="headerlink" title="可靠性（Reliability Pillar）"></a>可靠性（Reliability Pillar）</h2><h3 id="设计原则-1"><a href="#设计原则-1" class="headerlink" title="设计原则"></a>设计原则</h3><ul>
<li>测试覆盖率</li>
<li>自动修复错误</li>
<li>水平扩展</li>
<li>停止猜测生产力</li>
<li>自动追踪架构变更</li>
</ul>
<h3 id="最佳实践-1"><a href="#最佳实践-1" class="headerlink" title="最佳实践"></a>最佳实践</h3><h4 id="建立基础"><a href="#建立基础" class="headerlink" title="建立基础"></a>建立基础</h4><p>在开始架构设计之前，选择Region，确立方案。</p>
<ul>
<li>如何管理AWS对服务数量的限制</li>
<li>如何设计网络拓扑</li>
<li>是否有预留空间用于处理技术难题</li>
</ul>
<h4 id="变更管理"><a href="#变更管理" class="headerlink" title="变更管理"></a>变更管理</h4><p>这里说的变更主要指的是架构的水平扩展</p>
<ul>
<li>如何根据业务需求进行系统变更</li>
<li>如何监控变更</li>
<li>如何执行变更（自动化）</li>
</ul>
<h4 id="容错管理"><a href="#容错管理" class="headerlink" title="容错管理"></a>容错管理</h4><ul>
<li>数据备份</li>
<li>灾难恢复</li>
<li>如何应对应用组件失效</li>
<li>如何对系统弹性进行测试</li>
</ul>
<h3 id="涉及到的服务"><a href="#涉及到的服务" class="headerlink" title="涉及到的服务"></a>涉及到的服务</h3><ul>
<li>建立基础：IAM, VPC</li>
<li>变更管理：CloudTrail</li>
<li>容错管理：CloudFormation</li>
</ul>
<h2 id="性能负载（Performance-Efficiency-Pillar）"><a href="#性能负载（Performance-Efficiency-Pillar）" class="headerlink" title="性能负载（Performance Efficiency Pillar）"></a>性能负载（Performance Efficiency Pillar）</h2><p>这一个支柱的核心思想是如何使用变更的计算资源来满足日益变化的业务需求</p>
<h3 id="设计原则-2"><a href="#设计原则-2" class="headerlink" title="设计原则"></a>设计原则</h3><ul>
<li>为用户隐藏更多的细节让用户可以轻松调度资源，更关注在产品的业务价值</li>
<li>数分钟内让服务发布到全球</li>
<li>使用无服务（Serverless）架构</li>
<li>更容易实验</li>
<li>使用最符合用户想要实现的技术方法。例如，在选择数据库或存储方法时考虑数据访问模式。</li>
</ul>
<h3 id="最佳实践-2"><a href="#最佳实践-2" class="headerlink" title="最佳实践"></a>最佳实践</h3><h4 id="选择"><a href="#选择" class="headerlink" title="选择"></a>选择</h4><ul>
<li>架构：数据驱动/事件驱动/ETL(数据仓储)/Pipeline，架构的选择决定了以下几种资源的选择</li>
<li>计算：Instance（type, monitor, quantity ）/Container/Function，同时要考虑到水平扩展能力</li>
<li>存储：涉及到存储服务选择（S3/S3 IA/S3 RRS/Glacier），存储介质选择（SSD/HDD）<ul>
<li>存储方式：块存储、文件存储、对象存储</li>
<li>访问方式：随机还是连续</li>
<li>吞吐量要求</li>
<li>访问频率：在线、离线、存档</li>
<li>更新频率：缓慢变更、动态实时更新</li>
<li>可用性限制</li>
<li>数据耐久度限制</li>
</ul>
</li>
<li>数据库：RDS/DynamoDB/Redshift</li>
<li>网络：考虑地址，网络延迟（是否需要PlacementGroup），在各服务组合方式中寻找合适的配置Cloudfront, VPC, DirectConnect, Route53</li>
</ul>
<h4 id="回顾审视"><a href="#回顾审视" class="headerlink" title="回顾审视"></a>回顾审视</h4><p>设计好一个架构，应该再次审视你的架构是如何配合业务需求的，以及随着业务的改变，当引入新的资源类型和功能时，如何确保继续拥有最合适的资源配置？</p>
<h4 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h4><p>如何监控服务器负载和性能</p>
<h4 id="时间空间的平衡"><a href="#时间空间的平衡" class="headerlink" title="时间空间的平衡"></a>时间空间的平衡</h4><p>如何用增加空间，冗余备份的方式提高系统响应速度，增加性能负载。最明显的例子就是利用Cloudfront将静态文件缓存到各个节点从而增加各个地区的访问速度</p>
<h3 id="涉及到的服务-1"><a href="#涉及到的服务-1" class="headerlink" title="涉及到的服务"></a>涉及到的服务</h3><ul>
<li>选择<ul>
<li>计算：Auto Scaling是关键，确保你拥有合适数量的Instance来满足业务需求</li>
<li>存储：EBS提供灵活多样的存储介质及参数，比如SSD, PIOPS，S3提供了静态文件交付方式，Amazon S3 Transfer Acceleration使用户可以远距离，快速，方便，安全的传输大文件</li>
<li>数据库： RDS（IOPS，Read Replicas）DynamoDB可以灵活扩展且提供毫秒级延迟的服务</li>
<li>网络：Route53可以提供根据地区延迟分发的路由策略，VPC endpoint(NAT, VPN, Direct Connect)开启灵活的网络互连</li>
</ul>
</li>
<li>回顾审视：<a href="https://aws.amazon.com/blogs/aws/" target="_blank" rel="external">AWS Blog</a>和<a href="https://aws.amazon.com/new/" target="_blank" rel="external">AWS What’s New section</a>可以看到AWS又推出了何种新服务</li>
<li>监控：AWS CloudWatch提供了不同维度(Metrics)的监控，触发事件(alarms)，以及提示(Notifications)，可以配合Lambda对监控事件作出反应</li>
<li>空间换时间：AWS ElastiCache，Cloudfront，Snowball，以及RDS的Read Replicas都是为了空间换时间的典型</li>
</ul>
<h2 id="费用优化（Cost-Optimization-Pillar）"><a href="#费用优化（Cost-Optimization-Pillar）" class="headerlink" title="费用优化（Cost Optimization Pillar）"></a>费用优化（Cost Optimization Pillar）</h2><h3 id="设计原则-3"><a href="#设计原则-3" class="headerlink" title="设计原则"></a>设计原则</h3><ul>
<li>采用消费模式：根据使用情况实时变更资源配置，而不是精确估计资源使用情况</li>
<li>收益与经济规模：因为AWS拥有比单个企业大得多的经济规模，可以在各个企业的需求之间平衡资源需求，所以价格将会更加便宜</li>
<li>停止在自建数据中心中的投入</li>
<li>分析支出：云使得资源利用率和成本更加透明，有助于企业主衡量投资回报率，并为用户提供优化资源降低成本的机会</li>
<li>托管服务降低成本</li>
</ul>
<h3 id="最佳实践-3"><a href="#最佳实践-3" class="headerlink" title="最佳实践"></a>最佳实践</h3><ul>
<li>更佳有效地利用资源</li>
<li>更贴近业务需求</li>
<li>支出意识：<ul>
<li>清楚地认识到哪些服务是会被收费的，收费方式怎样，哪些服务是免费的</li>
<li>监控支出</li>
<li>及时关闭不被使用的资源</li>
<li>给资源配置权限管理以控制花费</li>
</ul>
</li>
<li>随时优化</li>
</ul>
<h3 id="涉及到的服务-2"><a href="#涉及到的服务-2" class="headerlink" title="涉及到的服务"></a>涉及到的服务</h3><ul>
<li>有效利用资源：对于EC2，申请预留实例以减少开销，使用 AWS Trusted Advisor 找到可以减少花费的方式</li>
<li>贴近业务需求：Auto Scaling</li>
<li>支出意识：CloudWatch用于监控花费情况，SNS用于提示超出预算的花费</li>
<li>随时优化：<a href="https://aws.amazon.com/blogs/aws/" target="_blank" rel="external">AWS Blog</a>和<a href="https://aws.amazon.com/new/" target="_blank" rel="external">AWS What’s New section</a>以及 AWS Trusted Advisor</li>
</ul>
<h2 id="运维出色（Operational-Excellence-Pillar）"><a href="#运维出色（Operational-Excellence-Pillar）" class="headerlink" title="运维出色（Operational Excellence Pillar）"></a>运维出色（Operational Excellence Pillar）</h2><p>运维出色应该是AWS配合DevOps运动推出的一系列实践：</p>
<h3 id="设计原则-4"><a href="#设计原则-4" class="headerlink" title="设计原则"></a>设计原则</h3><ul>
<li>使用代码执行运维操作：运维的一个发展趋势是越来越自动化，比如我们可以用自动配置管理工具配置更改环境，响应实践等</li>
<li>强调配合业务需求的运维：将运营流程与业务目标相一致，减少不必要的运维指标</li>
<li>定期，小步，增量式的运维：工作负载应设计为允许组件定期更新，运维的更新也应该小步前进，且容易被回滚，在维护和更换组件时不应造成宕机时间</li>
<li>启用测试以对运维的误操作及时响应：对于组件更替和运维的操作应该有测试，及时发现变更错误以便于修复或回滚</li>
<li>在错误中学习：定期回顾对运维事件的处理方法以改进，持续推动卓越运维</li>
<li>保持操作流程：团队之间相互学习，及时更新文档，保证团队运维操作有统一流程，统一的运维方式</li>
</ul>
<h3 id="最佳实践-4"><a href="#最佳实践-4" class="headerlink" title="最佳实践"></a>最佳实践</h3><ul>
<li>准备：何种最佳实践？选用何种配置管理？</li>
<li>开始作业：如何小步前进，如何监控每一次运维操作？</li>
<li>响应：如何对计划之外的运维操作做出响应？</li>
</ul>
<h3 id="涉及到的服务-3"><a href="#涉及到的服务-3" class="headerlink" title="涉及到的服务"></a>涉及到的服务</h3><ul>
<li>准备：AWS Config，AWS Service Catalog，使用Auto Scaling和SQS来保证运维的连续性</li>
<li>作业：这一部分主要是CI/CD: AWS CodeCommit, AWS CodeDeploy, and AWS CodePipeline</li>
<li>响应：CloudWatch alarm</li>
</ul>
<h1 id="FAQ"><a href="#FAQ" class="headerlink" title="FAQ"></a>FAQ</h1><p>可以看到AWS对于优秀网站的设计，除了一般要求的可靠，省钱，还根据云服务的基础设施可灵活变更的特点强调了水平扩展和架构灵活变更，以更好地满足业务需要，保证<code>业务连续性</code>(business continuity)<br>白皮书最后还给出了FAQ（Frequently asked questions）部分回答了一些关于最佳实践的常见问题，非常值得一看。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;AWS Well Architected framework，其实是亚马逊的一封&lt;a href=&quot;https://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf&quot; ta
    
    </summary>
    
      <category term="Cloud" scheme="https://www.duyidong.com/categories/Cloud/"/>
    
    
      <category term="AWS" scheme="https://www.duyidong.com/tags/AWS/"/>
    
      <category term="Cloud" scheme="https://www.duyidong.com/tags/Cloud/"/>
    
      <category term="Cloud Native" scheme="https://www.duyidong.com/tags/Cloud-Native/"/>
    
      <category term="架构" scheme="https://www.duyidong.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>使用AWS解锁HTTPS和CDN</title>
    <link href="https://www.duyidong.com/2017/03/20/Enable-HTTPS-and-CDN-with-Cloudfront/"/>
    <id>https://www.duyidong.com/2017/03/20/Enable-HTTPS-and-CDN-with-Cloudfront/</id>
    <published>2017-03-20T12:23:37.000Z</published>
    <updated>2017-05-13T12:22:15.000Z</updated>
    
    <content type="html"><![CDATA[<p>在上一篇博客中，笔者已经介绍了<a href="https://www.duyidong.com/2017/03/07/Deploy-Hexo-to-S3/">将hexo博客发布到S3</a>，这一部分我将介绍如何使用AWS的Route53应用上自己的域名，以及如何使用Cloudfront开启HTTPS/HTTP2和CDN加速。</p>
<h2 id="关于Route53"><a href="#关于Route53" class="headerlink" title="关于Route53"></a>关于Route53</h2><p>Route53是AWS提供的DNS服务，提供常见域名服务，用户可以使用Route53注册使用域名，指向自己的服务，可以除了一般域名服务都支持的A类地址（直接指向IP），及CNAME（指向另一个域名）以外，Route53还支持一个功能叫做A-record，即可以将DNS指向AWS内部的资源，该服务功能与CNAME基本相同，但是免费。此外，Route53支持以下几种路由策略：</p>
<ul>
<li><strong>Simple Routing Policy</strong>：通常在只有一个资源的时候使用这种策略，该种策略会自由（平均）分配负载给所属资源</li>
<li><strong>Weighted Routing Policy</strong>：加权路由，这种路由策略支持用户指定的路由百分比，比如百分之20的流量导入测试环境，百分之80的流量导入产品环境，用于进行AB测试。</li>
<li><strong>Latency Routing Policy</strong>：该种策略会根据客户端访问的延迟情况选择合适的服务，比如一个客户访问A延迟为20毫秒，访问B服务延迟为250毫秒，那Latency Routing就会把该用户的访问导入A服务。</li>
<li><strong>Failover Routing Policy</strong>：该路由策略在其中一个被路由资源宕机的情况下会停止流量引入，从而避免用户访问到错误页面，这里涉及到Route53的另一个功能———健康检查。</li>
<li><strong>Geolocation Routing Policy</strong>：地理位置策略允许用户设置将不同地理位置的用户流量导入到不同服务，例如希望悉尼的用户和北京的用户在一个网站上看到不同的页面，可以采用这种路由方式。</li>
</ul>
<h2 id="关于Cloudfront"><a href="#关于Cloudfront" class="headerlink" title="关于Cloudfront"></a>关于Cloudfront</h2><p>Cloudfront是AWS的CND服务，利用AWS分布在全球的节点服务器（Edge Location）缓存用户的访问，用户在第二次访问（或同区域的另一个用户在非首次访问）页面时会直接从节点服务器取到已经缓存的数据，速度会大大加快。<br>同理，Cloudfront也可以用于文件上传。</p>
<h2 id="申请Route53和Cloudfront权限"><a href="#申请Route53和Cloudfront权限" class="headerlink" title="申请Route53和Cloudfront权限"></a>申请Route53和Cloudfront权限</h2><p>默认情况下，所有账户都是没有开启Cloudfront和Route53服务的，这个时候需要使用账号注册邮箱发送邮件到<a href="aws-verification@amazon.com">aws-verification@amazon.com</a>申请开通。</p>
<h2 id="申请域名"><a href="#申请域名" class="headerlink" title="申请域名"></a>申请域名</h2><p>得到服务使用权限之后，还需要申请一个域名，这个时候可以在AWS的<a href="https://console.aws.amazon.com/cloudfront/route53" target="_blank" rel="external">Route53</a>进行购买，也可以在阿里云的<a href="https://wanwang.aliyun.com/domain/" target="_blank" rel="external">万网</a>注册一个域名，域名会按使用年数收费，不同域名收费不同。<br>在亚马逊购买域名，只需要进入<a href="https://console.aws.amazon.com/route53/home" target="_blank" rel="external">Console</a>，在<strong>Register Domain</strong>栏输入你想要的域名，点选Check，接下来如果域名可用，可以Add to Card然后付费即可。大约一小时后，这个域名就可以被使用了。</p>
<p><img src="/images/Route53_Register_Domain.png" alt=""></p>
<h2 id="配置Cloudfront"><a href="#配置Cloudfront" class="headerlink" title="配置Cloudfront"></a>配置Cloudfront</h2><p>点击<strong>Create Distribution</strong>按钮，Delivery method选择Web。 Web主要针对一些html，css,js等静态文件，而RTMP则主要是一些音视频文件。点选“Get Start”。</p>
<p><img src="/images/Clouldfront_Configure_Select_Delivery_Method.png" alt=""></p>
<p>下一步，要选择Origin,即要进行内容分发的源。虽然亚马逊会自动列出你的S3 bucket，但是千万不要选。而是自己手动输入example.com这个Bucket的Endpoint(Endpoint在S3 Console的Properties标签下的Static Website hosting里看得到)。为什么不直接选S3 bucket那?这是因为当我们访问一个目录时，我们期望能返回默认的object。虽然CouldFront有个Default Root Object设置，只是对根目录起作用，对子目录不起作用。如果使用Bucket的Endpoint，再加上之前已经给该Bucket配置了Default Object，就可以解决这个问题。</p>
<p><img src="/images/Clouldfront_Configure_Origin_Domain_Name.png" alt=""></p>
<p>选择将HTTP重定向到HTTPS，在CNAMEs项中输入自己的域名，多个域名以逗号分隔。<br>在Distribution Setting下选择你自己的证书(如果没有可以点选Request or Import a Certificate with ACM免费申请)。</p>
<p><img src="/images/Clouldfront_Configure_Distribution_Setting.png" alt=""></p>
<p>[可选]勾选Logging，并选择Bucket for Logs，可以打印访问信息。由于是静态网站，Cookie的Log就没有必要了。</p>
<p><img src="/images/Clouldfront_Configure_Logging.png" alt=""></p>
<p>点选<strong>Create Distribution</strong>，创建成功，需要等待大约半小时等待Status从<code>In progress</code>变为<code>Deployed</code>，在这期间可以配置Route53。</p>
<p><img src="/images/Clouldfront_Configure_Success.png" alt=""></p>
<p>配置成功后可以在管理员面板修改所有创建Distribution时设置的参数，并可以增加Error Page等设置。</p>
<p><img src="/images/Clouldfront_Configure_Admin.png" alt=""></p>
<blockquote>
<ul>
<li>注意：Cloudfront的配置每次更改都需要从新部署，每次重新部署都需要大约半小时时间，为了避免不必要的时间浪费，最好是一次配置成功，不然真的很痛苦。。</li>
<li>另外，关于Cloudfront的日志，AWS不会针对日志功能进行收费，但用户需要对占用的S3 bucket存储和访问付费，日志内容大概和Nginx的access.log差不多，个人觉得AWS的<a href="https://console.aws.amazon.com/cloudfront/home#cache_stat_reports" target="_blank" rel="external">Reports &amp; Analytics</a>已经做得很好了，日志有些多余，建议可以在学习完后关闭。</li>
</ul>
</blockquote>
<h3 id="关于缓存时间"><a href="#关于缓存时间" class="headerlink" title="关于缓存时间"></a>关于缓存时间</h3><p>关于S3里的Object在Cloudfront的各节点缓存的时间，默认为24小时，也就是说当我发布一篇新博客，由于主页<code>index.html</code>名字没有变化，只是更新了新版本，我要等到24小时候Edge location中缓存的数据过期才能看到新版本，这对我的小博客来说时间太长了，需要更改这个Cache时间。更改Cache时间有两种方式：一是更改TTL（Time To Live）时间，二是增加<code>Cache-Control: max-age=[seconds]</code>的header，关于第二种方式，具体参见<a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html#expiration-individual-objects" target="_blank" rel="external">官方文档</a>，这里我说一下如何更改TTL：<br>进入Distribution的管理员界面，选择<strong>Behaviors</strong>标签，勾选待编辑的Behavior，点选<strong>Edit</strong></p>
<p><img src="/images/Cloudfront_Distributions_Behaviors.png" alt=""></p>
<p>在Edit Behavior页面Object Caching项目勾选<strong>Customize</strong>自定义TTL，将Default TTL改为3600（1小时）点选<strong>Yes，Edit</strong>即可。<br>同样，更新配置要等待半小时左右方能生效。</p>
<blockquote>
<ul>
<li>参见 <a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html" target="_blank" rel="external">Specifying How Long Objects Stay in a CloudFront Edge Cache (Expiration)</a></li>
</ul>
</blockquote>
<h4 id="首页缓存时间"><a href="#首页缓存时间" class="headerlink" title="首页缓存时间"></a>首页缓存时间</h4><p>更改TTL后，首页的更新也需要一个小时，对大部分情况来说这个时间还是比较长，这个时候可以通过更改S3的Bucket里面的Object的Metadata的方式增加<code>Cache-Control</code>的Header来进一步减少首页的Cache时间。</p>
<p><img src="/images/Cloudfront_S3_Metadata.png" alt=""></p>
<blockquote>
<ul>
<li>这个手动的设置会在每次Deploy的时候被覆盖，所以需要给Deploy插件增加Update Metadata/Header的设置。</li>
</ul>
</blockquote>
<h3 id="如何清除缓存"><a href="#如何清除缓存" class="headerlink" title="如何清除缓存"></a>如何清除缓存</h3><h2 id="配置Route53"><a href="#配置Route53" class="headerlink" title="配置Route53"></a>配置Route53</h2><p>进入Route53的<a href="https://console.aws.amazon.com/route53/home" target="_blank" rel="external">Console</a>，进入<strong>Hosted Zones</strong>标签，点选使用的Domain Name。</p>
<p><img src="/images/Route53_Host_Zones.png" alt=""></p>
<p>点选<strong>Create Record Set</strong>，输入二级域名下的三级域名（可以置空），选择Type为A类地址，选择一个A-record），在AWS的内部资源中选择Cloudfront下对应你博客的域名，Route Policy为默认的Simple即可，点选<strong>Save Record Set</strong></p>
<p><img src="/images/Route53_Create_Record_Set.png" alt=""></p>
<p>只需要数分钟，A-record即可生效。</p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>现在可以通过HTTPS访问我在每个Edge Location缓存的博客了：</p>
<p><a href="https://www.duyidong.com">https://www.duyidong.com</a></p>
<p>经测试，同一个页面在加上Cloudfront之前（在S3 bucket中）访问时间是11秒，使用gitHub.io(带CDN)是6秒，使用Cloudfront之后加载时间大概是2.4秒，可见Cloudfront的加速效果是非常理想的。</p>
<blockquote>
<ul>
<li>参考资料</li>
<li><a href="https://www.huangbowen.net/blog/2013/10/01/migrate-octopress-to-aws-step-2/" target="_blank" rel="external">https://www.huangbowen.net/blog/2013/10/01/migrate-octopress-to-aws-step-2/</a></li>
<li><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html" target="_blank" rel="external">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html</a></li>
<li><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html" target="_blank" rel="external">https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html</a></li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上一篇博客中，笔者已经介绍了&lt;a href=&quot;https://www.duyidong.com/2017/03/07/Deploy-Hexo-to-S3/&quot;&gt;将hexo博客发布到S3&lt;/a&gt;，这一部分我将介绍如何使用AWS的Route53应用上自己的域名，以及如何使用Cl
    
    </summary>
    
      <category term="我的博客" scheme="https://www.duyidong.com/categories/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="AWS" scheme="https://www.duyidong.com/tags/AWS/"/>
    
      <category term="Blog" scheme="https://www.duyidong.com/tags/Blog/"/>
    
      <category term="HTTPS" scheme="https://www.duyidong.com/tags/HTTPS/"/>
    
      <category term="CDN" scheme="https://www.duyidong.com/tags/CDN/"/>
    
      <category term="Cloudfront" scheme="https://www.duyidong.com/tags/Cloudfront/"/>
    
      <category term="Route53" scheme="https://www.duyidong.com/tags/Route53/"/>
    
      <category term="博客上云" scheme="https://www.duyidong.com/tags/%E5%8D%9A%E5%AE%A2%E4%B8%8A%E4%BA%91/"/>
    
  </entry>
  
  <entry>
    <title>AWS虚拟机EC2</title>
    <link href="https://www.duyidong.com/2017/03/15/AWS-EC2/"/>
    <id>https://www.duyidong.com/2017/03/15/AWS-EC2/</id>
    <published>2017-03-15T12:02:03.000Z</published>
    <updated>2017-05-04T12:18:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>Amazon Elastic Cloud Compute，简单来说就是亚马逊的虚拟机服务，用户可以使用EC2服务创建一个个实例(instances)，即虚拟机。</p>
<p>亚马逊的EC2标榜有几大优势：完全控制，灵活使用，方便集成，安全，便宜，简单好用。<br>关于EC2有几个重要的概念：Instance Type，即在选择Instance的时候的内存，CUP等硬件指标；然后是EBS，即挂载硬盘，租户可以选择不同IO，不同介质的虚拟硬盘；其次是AMI，即用于启动虚拟机的操作系统镜像；另外还有Security Group，可以理解为虚拟机的防火墙；其他的服务都属于附加服务，比如负载均衡，弹性伸缩，监控报警，权限控制，类似nfs的弹性存储介质等等。<br>虚拟机服务是云服务最重要的服务，几乎各大云厂商最终要的一项都是对租户提供虚拟机，看大厂的虚拟机策略，其他各厂基本可通晓一二。<br>由于企业级应用很少用windows的使用场景，笔者将主要关注在Linux的使用上，本文对windows使用场景改不涉及。</p>
<h2 id="Instances"><a href="#Instances" class="headerlink" title="Instances"></a>Instances</h2><p>EC2为亚马逊的服务，Instance就是该服务提供的一个实例 —— 虚拟机</p>
<h3 id="Instance-Purchasing-Options"><a href="#Instance-Purchasing-Options" class="headerlink" title="Instance Purchasing Options"></a>Instance Purchasing Options</h3><p>在说Instance Type之前，有个更重要的东西：Instance的收费方式（Instance Purchasing Options）。Instance有四种收费方式，针对不同应用场景要学会选择适合的Purchasing Option:</p>
<ul>
<li><strong>On-Demand Instance</strong> 按小时收费，也是默认的收费方式，不足一小时按一小时计费；属于比较灵活的按需付费方式</li>
<li><strong>Reserved Instances</strong> 预留实例，可选1-3年，一次付费，完成付费之后不管是否使用都会收费，价格相对按小时计费要便宜些，企业作为服务器长期使用通常会选择使用的付费方式</li>
<li><strong>Scheduled Reserved Instances</strong> 计划预留实例，为期一年，在计划时间内可用。值得注意的是，只有几个高性能的Instance Type支持该购买方式，且每年使用不得少于1200小时，需提前三个月购买</li>
<li><strong>Spot Instances</strong> 竞价实例，价格随时间浮动，租户在申请时出价，当租户出价高于该时间点竞价实例价格时，租户获得该实例使用权，当价格再次浮动导致实例价格高于租户出价，亚马逊会提前十分钟提醒租户，而后terminate实例，转移到别的地方。注意，被亚马逊销毁的实例最后一小时不收费，而用户在使用期间自行销毁的实例，不足一小时仍以一小时计费。这种收费方式适用于不需长期提供稳定服务的应用场景，比如大数据流处理。</li>
<li><strong>Dedicated hosts</strong>买下一个跑在固定物理设备上的Instance的使用权，保证租户的licenses不会因为不同物理设备过期。</li>
<li><strong>Dedicated Instances</strong>按小时计费的Dedicated hosts</li>
</ul>
<h3 id="Instances-Type"><a href="#Instances-Type" class="headerlink" title="Instances Type"></a>Instances Type</h3><p><a href="https://aws.amazon.com/ec2/instance-types/" target="_blank" rel="external">Instance Type</a>有10种类型，用于区分大致的应用场景，每个类型下有从nano, micro, small, medium, large, xlarge到16xlarge数目不等的型号，主要区分CPU数量，vCPU(亚马逊创造的用于衡量单个CPU运算能力的一个参数)，内存，不同，大小、类型不同，直接影响价格。</p>
<p><img src="/images/AWS_Instances_Type.png" alt=""></p>
<ul>
<li>D2 - Dense storage Instance，特点是硬盘价格平衡，支持HDD硬盘，支持EC2 Enhanced Networking，适用于对存储需求比较高的场景，比如数据库，大数据存储</li>
<li>R4: 特点是内存大</li>
<li>M4: 各项平衡的一个Instance类型，也是默认情况下首选的Instance Type</li>
<li>C4 - Compute Optimized: 计算能力优化，特点自然是计算速度快</li>
<li>G2: 包含GPU的Instance，适合于图形计算，视频转码等场景</li>
<li>I3 - High I/O Instance，高硬盘IO，使用固态硬盘，适用于非关系型数据库，大数据处理等</li>
<li>F1 - 可以为程序定制硬件加速</li>
<li>T2: 最常见的Instance使用类型，因为它最便宜，性能也最平衡，生产环境只适用于做web服务器，或小型数据库</li>
<li>P2: 通用GPU计算机，常用于人工智能等需要大量计算的领域</li>
<li><p>X1: CPU，内存都相当大，针对大规模，企业级，内存应用程序进行了优化，并且在Amazon EC2实例类型中具有每GiB最低的RAM价格</p>
<p>Instance类型在创建后可以被更改，前提是Stop Instance</p>
</li>
</ul>
<h3 id="Instance-LifeCycle"><a href="#Instance-LifeCycle" class="headerlink" title="Instance LifeCycle"></a>Instance LifeCycle</h3><p>Instance的生命周期，有pending, running, stop ,terminate几个主要的状态和动作，详见下图：</p>
<p><img src="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/images/instance_lifecycle.png" alt=""></p>
<h3 id="MetaData-amp-UserData"><a href="#MetaData-amp-UserData" class="headerlink" title="MetaData &amp; UserData"></a>MetaData &amp; UserData</h3><p>UserData是创建完成Instance最后一步用来准备Instance环境的Bash脚本，而MetaData是Instance与生俱来的元数据，通过<code>curl https://169.254.169.254/latest/meta-data/</code>这种奇特的方式获得，包含Instance类型，IP，public-key等信息。值得一提的是IAM的Role之所以在Instance的文件系统中不会出现Credential key的文件，是因为它把Credential key放到了MetaData中，可以通过获取MetaData的方式获得。</p>
<h2 id="EBS"><a href="#EBS" class="headerlink" title="EBS"></a>EBS</h2><p>简单来讲，EBS(Elastic Block Storage)就是AWS为租户提供的虚拟硬盘，Instance可以看做主板，EBS可以被关联到任何一个Instance上，启动Instance时也必须要一个启动硬盘作为系统盘才能启动。这里就要区分一个重要的概念，EBS 和 Instance Store，两种类型的Instance，应该说EBS Instance比Instance Store 更健全一些，支持更多的Instance Type，生命周期完整；而Instance Store，是由存放在S3的文件系统启动的，启动速度慢，生命周期不完整，只能被Reboot或者Terminate，不能Stop，一旦启动失败就会丢失所有数据，且支持类型有限，被称为短暂存储（ephemeral Storage）<br>下面重点区分一下<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html" target="_blank" rel="external">EBS Volum Type</a>，与Instance相同，重点也在使用场景和节省开销：</p>
<ul>
<li>SSD, General Purporse - <strong>gp2</strong>: 兼顾性能与价格，吞吐量160MB/s，最大IOPS为10,000; 挂载卷大小在1GB-16TB；使用场景：推荐使用在大部分场景，虚拟机启动磁盘，提供低延迟的服务，可在开发测试环境应用</li>
<li>SSD, Provisioned IOPS - <strong>io1</strong>: 高性能磁盘，吞吐量320MB/s，IOPS在10,000-20,000; 挂载卷大小在4GB-16TB；使用场景：执行紧急任务的应用模块，大数据库，比如MongDB, Orale, SQL Server等</li>
<li>HDD, Throughput Optimized HDD - <strong>st1</strong>: 价格相对便宜的机械硬盘，用于存放不常使用的数据，IOPS最大仅500，吞吐量可达500MB/s，磁盘大小为500GB-16TB；使用场景：需要高吞吐量量有需要控制预算的场景，比如大数据，日志存放；不能用作启动磁盘</li>
<li>HDD, Code HDD - <strong>sc1</strong>: 比普通机械硬盘更便宜的磁盘，IOPS仅为250，吞吐量250MB/s，容量500GB-16TB，使用场景：非常强调便宜的不常访问数据的存储</li>
<li>HDD, EBS Magnetic - <strong>standard</strong>: 磁带存储，非常便宜的低频次访问的磁盘，性能最次（40-200IOPS, 40-60MB/s吞吐）</li>
</ul>
<blockquote>
<p>注：以上参数均需在Instance类型的支持才能发挥到最大值，机械硬盘的优势在于高吞吐，固态硬盘的好处在于高IO；另外一个需要注意的是，你可以在一个Instance上绑定多个EBS，但是不能将一个EBS绑定在多个Instance上（这种情况要使用EFS）</p>
</blockquote>
<h2 id="Security-Group"><a href="#Security-Group" class="headerlink" title="Security Group"></a>Security Group</h2><p>Security Group可以理解为Instance的防火墙，在Instance的网络中大概处在以下位置：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1765038-d1edcf22e1e4784c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>SG的安全策略大范围分为Inbound和Outbound，顾名思义为控制进出，SG刚被创建时默认所有Inbound都是被禁止的，所有Outbound都是被允许的。<br>SG由数条规则（rules）构成，Rules有几个重要参数：目标地址（网段），协议类型，端口号。<br>关于SG有以下几个值得注意的点：</p>
<ul>
<li>SG策略在修改后立即生效</li>
<li>一个SG可以被绑定到任意数量的Instance上</li>
<li>一个Instance可以有多个SG，且被允许的Rules为多个SG的合</li>
<li>SG是有状态的，也就是说当租户允许了一个请求进入，默认会打开到目的地址的返回请求</li>
<li>通常情况我们不适用SG的Rules来组织IP访问，组织IP访问应该用ACL(Access Control List)</li>
<li>SG只能添加允许访问的策略，不能添加禁止访问的策略</li>
</ul>
<h2 id="Volumse-amp-Snapshots"><a href="#Volumse-amp-Snapshots" class="headerlink" title="Volumse &amp; Snapshots"></a>Volumse &amp; Snapshots</h2><p>关于Volume Type，已经在EBS部分提到了，这里主要想讲的是磁盘的生命周期。<br>Volume可以从EBS创建，Attache到一个Instance上，再在操作系统中进行挂载，使其成为一个可用的文件系统，Volume可以随时扩容，但扩容后需要更新文件系统。<br>Volume可以凭空创建，也可以使用Snapshot创建，Snapshot就是磁盘的一个镜像，存放于S3中，用于定期备份磁盘。Snapshot是增量式的，也就是说只有被更改的部分会被记录在S3中。<br>第一个Snapshot的创建会比较花时间。<br>Snapshot可以通过S3在账户之间共享。<br>可以开启自动备份定时备份Volume。<br>EBS可以被加密，除了root Volume，租户可以使用第三方工具对启动磁盘进行加密。<br>另外说一下关于Windows卷扩容，需要停止磁盘读写，有以下措施可以做到：</p>
<ul>
<li>冻结文件系统</li>
<li>卸载磁盘驱动（Unmount the RAID Array）</li>
<li>关闭关联的EC2 Instance</li>
</ul>
<blockquote>
<p>注：一个EBS可以被创建10,000个Snapshot，一个账户可以拥有的Volume存储大小总量单个类型不得超过20TB</p>
</blockquote>
<h2 id="AMI"><a href="#AMI" class="headerlink" title="AMI"></a>AMI</h2><p>既然有了Snapshot，另一个重要的概念就不得不提了，AMI，Amazon Machine Image，可以理解为虚拟机的启动镜像。一个AMI包含了在云上启动一个实例所需的所有信息，包括：</p>
<ul>
<li>一个Root Volume的模板（比如一个操作系统，一个应用）</li>
<li>启动许可（在启动时用于判断该用户是否有从该AMI启动实例的权限）</li>
<li>启动实例时需要挂载的磁盘映射表</li>
</ul>
<p>一个AMI的生命周期看起来像是这个样子的：</p>
<p><img src="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/images/ami_lifecycle.png" alt=""></p>
<p>AMI是划分Region的，租户可以通过Console或CLI在Region之间拷贝AMI。<br>AMI可以用于在<a href="https://aws.amazon.com/marketplace/search/results?x=0&amp;y=0&amp;searchTerms=&amp;page=1&amp;ref_=nav_search_box" target="_blank" rel="external">AWS Marketplace</a>出售。</p>
<p>AMI依赖于Snapshot缺不被Instance依赖，这意味着租户不能删除一个被注册的AMI的Snapshot，却可以删除一个运行中实例的AMI，Snapshot，AMI，Instance的关系如下图:<br><img src="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/images/ami_delete_ebs.png" alt=""></p>
<h2 id="ELB-amp-Health-Checks"><a href="#ELB-amp-Health-Checks" class="headerlink" title="ELB &amp; Health Checks"></a>ELB &amp; Health Checks</h2><p>ELB，Elastic LoadBalancer是构建一个高可用可用不得不谈的服务，经常和Autoscaling Group一起实现负载伸缩和高可用。<br>ELB是AWS提供的负载均衡器，用于将外部访问请求分发给状态健康的EC2 Instance。<br>ELB在创建的时候会有对外会有一个DNS解析域名，对所属Instance会做健康检查，所谓健康检查就是去定期访问一个文件，判断返回状态码为200即表明这个服务正常，Instance可以动态地被加载到ELB下，也可以动态移除，ELB会自动判断这个Instance已经失去连接并停止发送请求到这个Instance。<br>值得一提的是，ELB一个重要的功能是增加服务容灾性，通常会挂载多个不同AZ的Instance，做到一个数据中心挂掉仍然能够正常提供服务。</p>
<h2 id="Cloud-Watch-EC2"><a href="#Cloud-Watch-EC2" class="headerlink" title="Cloud Watch EC2"></a>Cloud Watch EC2</h2><p>CloudWatch是AWS提供的EC2监控报警的服务，简单好用。<br>作为一款与AWS各种资源高度集成且简单好用的监控工具，CloudWatch有以下功能：</p>
<ul>
<li>构建Dashboard用于可视化云环境资源状况</li>
<li>警告：配合SNS在某项指标超出一定阈值时发出邮件或短信通知</li>
<li>事件：监控事件用于动态变更云设施</li>
<li>日志：日志保存在S3中</li>
</ul>
<p>CloudWatch的一些类目默认情况是免费的，免费版本是5分钟取回一次数据，收费后变成1分钟一次，且部分metrics需要收费才能监控。默认监控的内容包括CPU，网络，硬盘IO等，但是没有内存。</p>
<h2 id="Autoscaling-Group"><a href="#Autoscaling-Group" class="headerlink" title="Autoscaling Group"></a>Autoscaling Group</h2><p>一个Autoscaling Group包含多个特性相同的Instance，可以根据Instance的负载自动扩容或缩减，同时可以对Instance开启健康检查，如果一个Instance服务异常，Group会依照Lunch Configuration重新启动一个实例替换掉旧的实例。这种方式保证了Group内的Instance总是健康的，且Instance数目会根据负载情况进行动态伸缩。</p>
<h2 id="Placement-Group"><a href="#Placement-Group" class="headerlink" title="Placement Group"></a>Placement Group</h2><p>Placement Group是一个在同AZ中的一组Instance，同PG的Instance可以享受到高带宽，低延迟的好处，但同时也有如下限制：</p>
<ul>
<li>一个Placement Group不能跨多个AZ</li>
<li>一个Placement Group的名字必须在一个账号中是独一无二的</li>
<li>Placement Group只支持一部分类型的Instance</li>
<li>AWS推荐在一个PG中使用同质的Instance</li>
<li>PG不能被合并</li>
<li>租户不能移动一个已经存在的Instance到一个PG中，可以对这个Instance创建AMI，再使用这个AMI在PG中启动一个Instance</li>
</ul>
<h2 id="EFS"><a href="#EFS" class="headerlink" title="EFS"></a>EFS</h2><p>EFS是AWS提供可以再Instance之间贡献的一个NFS server，其最大的优点是不需要预先设置大小，其空间大小会随文件写入增多逐步扩容至PB级别，而租户只需按使用收费。<br>EFS可以支持上千个NFS4连接，适用于大数据存储，Web服务器静态文件共享，等诸多应用场景。<br>AWS目前有4个Region支持EFS，EFS的文件存放在多个AZ中，可以跨AZ共享文件。</p>
<h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><ul>
<li>每个账户默认被限制可以申请20个保留实例，增加上限需要给亚马逊提Request</li>
<li>使用EC2发送邮件数量是有限制的</li>
<li>每个账户最多可申请5个Elastic IP</li>
<li>不同账户标记的一个AZ名字（比如us-east-1a）可能指向不同的物理数据中心</li>
<li>要使用增强网络型实例（Enhanced Network）租户不需要另外付费，只需要选择适当的AMI和适当的Instance类型在一个VPC中即可</li>
<li>默认情况下，当租户停止监控EC2实例或销毁了实例，两周内仍可访问CloudWatch的数据</li>
<li>如果删掉一个Auto Scaling Group，其中的Instance会先被销毁</li>
<li>租户可使用VM Import/Export从EC2导入/导出虚拟机镜像</li>
<li>虽然Snapshot被存在S3中，但租户不能通过S3的API访问到Snapshot，而只能通过EC2的API访问</li>
<li>分享Snapshot给特定的账户，Snapshot的状态仍为“private”</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Amazon Elastic Cloud Compute，简单来说就是亚马逊的虚拟机服务，用户可以使用EC2服务创建一个个实例(instances)，即虚拟机。&lt;/p&gt;
&lt;p&gt;亚马逊的EC2标榜有几大优势：完全控制，灵活使用，方便集成，安全，便宜，简单好用。&lt;br&gt;关于EC
    
    </summary>
    
      <category term="Amazon Web Services" scheme="https://www.duyidong.com/categories/Amazon-Web-Services/"/>
    
    
      <category term="AWS" scheme="https://www.duyidong.com/tags/AWS/"/>
    
      <category term="EC2" scheme="https://www.duyidong.com/tags/EC2/"/>
    
      <category term="云计算" scheme="https://www.duyidong.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>AWS对象存储服务S3</title>
    <link href="https://www.duyidong.com/2017/03/13/AWS-S3/"/>
    <id>https://www.duyidong.com/2017/03/13/AWS-S3/</id>
    <published>2017-03-13T01:45:12.000Z</published>
    <updated>2017-06-22T08:00:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>AWS S3是一个非常厉害的服务，上个月S3宕机4小时，江湖上传出了“半个互联网出现问题”的传言。姑且不谈S3的影响力有多大，在计算单元越来越小且移动存储设备近两年并未降价的趋势下，高可用高伸缩的云存储服务应该成为每一个开发者必备的知识。</p>
<p>简单来说S3提供了一些bucket，租户可以在其中存放一些对象，何为对象？所有静态文件都属于镜像。<br>关于S3的高持久和高可用：</p>
<p><img src="/images/Table_S3.png" alt=""></p>
<h2 id="S3有几个重要的特点"><a href="#S3有几个重要的特点" class="headerlink" title="S3有几个重要的特点"></a>S3有几个重要的特点</h2><ul>
<li><strong>Sunolicity:</strong>简单，S3服务可以使用AWS console控制，可以使用命令行，可以通过各种语言的sdk与各应用深度集成。</li>
<li><strong>Drability:</strong>数据持久，S3(除了冗余备份服务)可以提供高达11个9的数据持久性，且提供跨Region备份，版本管理，充分保证数据持久性和容灾性（数据丢失可通过版本管理即使回滚）。</li>
<li><strong>Scalability:</strong>可扩展性，S3对租户的文件存储总量不做限制，租户可以存放需求相当的任何数量级的对象在S3上。</li>
<li><strong>Security:</strong>安全，AWS S3的文件传输都经过SSL加密，租户可以通过设置IAM管理对象访问权限，租户也可以选择在本地加密后上传S3，使用前再选择解密文件。</li>
<li><strong>Available:</strong>可用性，S3的Standard提供可用性达到99.99%的服务，IA(Infrequent Access)达到99.9%，RRS(Reduced Redundancy Storage)达到99.99%。</li>
<li><strong>Low Cost:</strong>低花费，这一点除了体现在S3按需收费上，还体现在S3的生存周期管理上，S3可以定期将久不访问的数据转移到IA服务上，在定期归档备份至Glacier中。</li>
<li><strong>Broad integration with other AWS services:</strong>与AWS其他服务广泛集成，包括安全（IAM, KMS），报警（CLoudWatch, CloudTrail &amp; Event Notifications），计算（Lambda），数据库（EMR, Redshift）。</li>
<li><strong>Enterprise-class Storage Management:</strong>企业级存储管理，S3允许租户采用<strong>数据驱动</strong>的方式提高存储优化，数据安全性和管理效率。</li>
</ul>
<h2 id="S3的使用场景"><a href="#S3的使用场景" class="headerlink" title="S3的使用场景"></a>S3的使用场景</h2><h3 id="内容存储及分发"><a href="#内容存储及分发" class="headerlink" title="内容存储及分发"></a>内容存储及分发</h3><p>S3可以用以上传/下载文件，包括音频视频文件，比如构建一个提供给用户分享视频的网站，S3可以提供无限伸缩的空间，以及跨Region的备份，和定期的存储转移，充分保证网站可用性和高负载能力，另外还提供上传下载加密，以及访问请权限控制的功能。</p>
<h3 id="数据分析存储"><a href="#数据分析存储" class="headerlink" title="数据分析存储"></a>数据分析存储</h3><p>S3可以用于存储用于数据分析的原始数据，因其很容易和EC2，Lambda等AWS的计算资源或事件触发器集成，可以轻松使用S3构建数据驱动的Data Pipeline，用于数据分析。且S3也可以用于存放数据分析产生的报告。</p>
<h3 id="备份，存档以及灾难恢复"><a href="#备份，存档以及灾难恢复" class="headerlink" title="备份，存档以及灾难恢复"></a>备份，存档以及灾难恢复</h3><p>因为S3的版本管理和跨Region备份特特性，S3很适合作为备份，且可以定期将数据转归档存储到Glacier中，且易于恢复。</p>
<h3 id="静态网站部署"><a href="#静态网站部署" class="headerlink" title="静态网站部署"></a>静态网站部署</h3><p>利用S3的高持久和4个9的可用性，可以将自己的静态网站部署到S3上，有以下几个好处：</p>
<ul>
<li>不用担心激增的访问量，S3可以处理激增的访问量，而不用改变网站架构</li>
<li>S3是全球的，意味着你的网站可以在瞬间被部署到全球任意一个或多个节点</li>
<li>S3是按使用付费的</li>
</ul>
<h2 id="S3的功能及特性"><a href="#S3的功能及特性" class="headerlink" title="S3的功能及特性"></a>S3的功能及特性</h2><p>S3有很多功能特性用于构建服务，这些服务都往往相互依存，了解服务功能固然重要，但结合使用场景才能凸显其价值。<br>参照：<a href="https://aws.amazon.com/s3/details/" target="_blank" rel="external">https://aws.amazon.com/s3/details/</a>和<a href="https://www.amazonaws.cn/en/s3/details/" target="_blank" rel="external">https://www.amazonaws.cn/en/s3/details/</a></p>
<h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><h4 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h4><p>开启版本控制后，对于bucket里每一个object的操作都会在版本中被记录，租户可以在console中下载历史版本，回滚，删除版本。值得一提的是，在跨Region备份功能开启时，主Bucket的版本删除并不会影响到备份bucket的版本。</p>
<h4 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h4><p>该功能可以指定一个bucket和一个路径用于存放租户对于S3使用的所有日志，包括该bucket内的存取更新对象的操作。</p>
<h4 id="Staic-website-hosting"><a href="#Staic-website-hosting" class="headerlink" title="Staic website hosting"></a>Staic website hosting</h4><p>开启此功能可以将一个bucket变成一个静态网站，只需要制定入口index.html和错误页面即可。当然还有一个前提是设置对象权限为所有人外部可访问。</p>
<h4 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a>Tags</h4><p>给Bucket资源打上一个或多个标签，方便管理。</p>
<h4 id="Cross-region-replication"><a href="#Cross-region-replication" class="headerlink" title="Cross-region replication"></a>Cross-region replication</h4><p>制定一个另一个Region的Bucket作为备份，需要Version功能开启。</p>
<h4 id="Transfer-Acceleration"><a href="#Transfer-Acceleration" class="headerlink" title="Transfer Acceleration"></a>Transfer Acceleration</h4><p>加速上传功能，类似于CloudFront，通过缓存在Globle Infrastructure的节点加速上传。</p>
<h4 id="Events"><a href="#Events" class="headerlink" title="Events"></a>Events</h4><p>开启这个功能，当S3的bucket或object发生动作时，可以触发SNS topic或SQS队列，或者Lambda Function。</p>
<h3 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h3><h4 id="Access-Control-List"><a href="#Access-Control-List" class="headerlink" title="Access Control List"></a>Access Control List</h4><p>大概就是IAM的某一个用户，可以对对象/权限控制执行如何操作（读/写），值得注意的是，默认情况下一个bucket创建出来后它的全显是只有它的创建者可以读/写这个bucket，粒度较大，适用于整个bucket的权控制。</p>
<h4 id="Bucket-Policy"><a href="#Bucket-Policy" class="headerlink" title="Bucket Policy"></a>Bucket Policy</h4><p>更细粒度的权限控制方案，以资源标识符为单位，与IAM相对应，可用于指定某个用户可以对bucket内部的哪些资源做何种操作。</p>
<h4 id="Cross-Origin-Resource-Sharing-CORS"><a href="#Cross-Origin-Resource-Sharing-CORS" class="headerlink" title="Cross-Origin Resource Sharing (CORS)"></a>Cross-Origin Resource Sharing (CORS)</h4><p>允许外链请求，在网站中使用API调用S3的资源的时候必须将调用url添加到该项信任中。</p>
<h3 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h3><h4 id="Lifecycle"><a href="#Lifecycle" class="headerlink" title="Lifecycle"></a>Lifecycle</h4><p>生存周期主要针对一个文件被上传到S3中，一段时间后访问会减少，再过一段时间可能根本不会被访问而只需要备份的应用场景，可以设置Standard S3 -&gt; IA S3 -&gt; Glacier 的转移顺序，主要价值是减小开支。<br>关于Lifecycle还有一个重要的表格：</p>
<p><img src="/images/Table_S3_Claicer.png" alt=""></p>
<h4 id="Analytics"><a href="#Analytics" class="headerlink" title="Analytics"></a>Analytics</h4><p>可以按标签过滤bucket中的object，生成csv报告，并手动将过滤出来的object转存到另一个同Region的bucket内。</p>
<h4 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h4><p>分为Storage metrics，Request metrics，Data transfer metrics，跟Cloudwatch结合，从多个维度度量租户的S3使用情况。</p>
<h4 id="Inventory"><a href="#Inventory" class="headerlink" title="Inventory"></a>Inventory</h4><p>S3的一个对象分拣服务，通过Inventory的方式定期将对象分类。</p>
<h2 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h2><ul>
<li>一个对象最大不能超过5TB。</li>
<li>一个账号最多可创建100个bucket。</li>
<li>S3普通上传模式最大只支持5GB以下的文件大小，开启<a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/UploadingObjects.html" target="_blank" rel="external">multipart uploading</a>enable多进程上传和断点续传，从而提高上传效率，在带宽充足且有大文件需要上传的时候可以开启这个功能。</li>
</ul>
<blockquote>
<ul>
<li>参考资料</li>
<li>AWS S3 FAQ<a href="https://aws.amazon.com/s3/faqs/" target="_blank" rel="external">https://aws.amazon.com/s3/faqs/</a></li>
<li>AWS S3 Detail<a href="https://aws.amazon.com/s3/details/" target="_blank" rel="external">https://aws.amazon.com/s3/details/</a></li>
<li>AWS S3 Use Case<a href="https://docs.aws.amazon.com/AmazonS3/latest/gsg/S3-gsg-CommonUseScenarios.html" target="_blank" rel="external">https://docs.aws.amazon.com/AmazonS3/latest/gsg/S3-gsg-CommonUseScenarios.html</a></li>
<li><a href="https://www.amazonaws.cn/en/s3/" target="_blank" rel="external">https://www.amazonaws.cn/en/s3/</a></li>
<li>Uploading Object<a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/UploadingObjects.html" target="_blank" rel="external">https://docs.aws.amazon.com/AmazonS3/latest/dev/UploadingObjects.html</a></li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;AWS S3是一个非常厉害的服务，上个月S3宕机4小时，江湖上传出了“半个互联网出现问题”的传言。姑且不谈S3的影响力有多大，在计算单元越来越小且移动存储设备近两年并未降价的趋势下，高可用高伸缩的云存储服务应该成为每一个开发者必备的知识。&lt;/p&gt;
&lt;p&gt;简单来说S3提供了一
    
    </summary>
    
      <category term="Amazon Web Services" scheme="https://www.duyidong.com/categories/Amazon-Web-Services/"/>
    
    
      <category term="AWS" scheme="https://www.duyidong.com/tags/AWS/"/>
    
      <category term="S3" scheme="https://www.duyidong.com/tags/S3/"/>
    
      <category term="对象存储服务" scheme="https://www.duyidong.com/tags/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>将Hexo博客发布到S3</title>
    <link href="https://www.duyidong.com/2017/03/07/Deploy-Hexo-to-S3/"/>
    <id>https://www.duyidong.com/2017/03/07/Deploy-Hexo-to-S3/</id>
    <published>2017-03-07T09:42:34.000Z</published>
    <updated>2017-05-04T12:25:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近在学习AWS服务，加之两次遇到github.io无法访问的情况，决定将博客迁移到AWS S3上。</p>
<h2 id="S3介绍"><a href="#S3介绍" class="headerlink" title="S3介绍"></a>S3介绍</h2><p>S3是AWS一个对象存储服务，拥有11个9的耐久度和3个9的可用性（并不算高），属于AWS底层存储服务。同时提供Host静态网站的功能</p>
<h2 id="第一步：创建一个Bucket"><a href="#第一步：创建一个Bucket" class="headerlink" title="第一步：创建一个Bucket"></a>第一步：创建一个Bucket</h2><ul>
<li>进入S3界面，点击<strong>CreateBucket</strong>，取名为www.duyidong.com</li>
<li>选择一个Region，你可以在<a href="https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html" target="_blank" rel="external">这里</a>找到延迟最低的Region用于存放你的博客</li>
<li><p>设置Policy，确保外部可访问：</p>
<pre><code>{
 &quot;Version&quot;: &quot;2012-10-17&quot;,
 &quot;Statement&quot;: [
     {
         &quot;Sid&quot;: &quot;PublicReadForGetBucketObjects&quot;,
         &quot;Effect&quot;: &quot;Allow&quot;,
         &quot;Principal&quot;: &quot;*&quot;,
         &quot;Action&quot;: &quot;s3:GetObject&quot;,
         &quot;Resource&quot;: &quot;arn:aws:s3:::www.duyidong.com/*&quot;
     }
 ]
}
</code></pre><blockquote>
<p>注： <code>arn:aws:s3:::www.duyidong.com/*</code>为bucket里对象的资源标识符</p>
</blockquote>
</li>
<li><p>在<strong>Properties</strong>下开启<strong>Static website hosting</strong>，设置入口文件为<code>index.html</code>，404页面为<code>404/index.html</code></p>
</li>
</ul>
<h2 id="第二步：创建一个用于上传静态文件的用户"><a href="#第二步：创建一个用于上传静态文件的用户" class="headerlink" title="第二步：创建一个用于上传静态文件的用户"></a>第二步：创建一个用于上传静态文件的用户</h2><h4 id="使用Policy-Generator创建一个Policy"><a href="#使用Policy-Generator创建一个Policy" class="headerlink" title="使用Policy Generator创建一个Policy"></a>使用Policy Generator创建一个Policy</h4><p>这里需要一个只有对www.duyidong.com这个bucket有上传权限的用户，首先要创建Policy，这里要用到Policy Generator。</p>
<ul>
<li>进入<strong>IAM -&gt; Policies -&gt; Create Policy -&gt; Policy Generator</strong></li>
<li><p>选择S3的PutObject Action, ARN为目标Bucket的ARN，届时会生成如下Policy:</p>
<blockquote>
<p>注：经笔者反复试错，再参照<a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/example-policies-s3.html" target="_blank" rel="external">官方文档</a>，最终确定User Policy需要以下权限：</p>
</blockquote>
<pre><code>{
&quot;Version&quot;:&quot;2012-10-17&quot;,
&quot;Statement&quot;:[
   {
      &quot;Effect&quot;:&quot;Allow&quot;,
      &quot;Action&quot;:[
         &quot;s3:ListBucket&quot;,
         &quot;s3:GetBucketLocation&quot;
      ],
      &quot;Resource&quot;:&quot;arn:aws:s3:::www.duyidong.com&quot;
   },
   {
      &quot;Effect&quot;:&quot;Allow&quot;,
      &quot;Action&quot;:[
         &quot;s3:PutObject&quot;,
         &quot;s3:GetObject&quot;,
         &quot;s3:DeleteObject&quot;
      ],
      &quot;Resource&quot;:&quot;arn:aws:s3:::www.duyidong.com/*&quot;
   }
]
}
</code></pre></li>
</ul>
<h4 id="创建用户组"><a href="#创建用户组" class="headerlink" title="创建用户组"></a>创建用户组</h4><p><strong>Groups -&gt; Create New Group -&gt; </strong>将上一步创建的Policy attach到该UserGroup上，用户组创建完成。</p>
<h4 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h4><p><strong>Users -&gt; Add User</strong>，勾选<code>Programmatic access</code>，输入用户名，将用户加入到上一步创建的用户组中，将用户的Access key下载到本地。</p>
<h2 id="第三步：安装插件，上传静态文件"><a href="#第三步：安装插件，上传静态文件" class="headerlink" title="第三步：安装插件，上传静态文件"></a>第三步：安装插件，上传静态文件</h2><ul>
<li>运行命令</li>
</ul>
<pre><code>npm install --save hexo-deployer-s3
</code></pre><p>编辑<code>_config.yml</code>:</p>
<pre><code>deploy:
  type: s3
  bucket: &lt;AWS bucket name&gt;
  aws_key: &lt;AWS id key&gt;
  aws_secret: &lt;AWS secret key&gt;
  region: &lt;AWS bucket region&gt;
</code></pre><p>由于我会把博客源码放到Github上，Access key不能写在配置文件里，而采用环境变量的方式，在~/.bashrc中加入：</p>
<pre><code>export AWS_ACCESS_KEY-ID=&lt;access key&gt;
export AWS_SECRET_ACCESS_KEY=&lt;secret key&gt;
</code></pre><p>再执行</p>
<pre><code>source ~/.bashrc
</code></pre><p>届时将可以成功将博客发布到S3上，执行：</p>
<pre><code>hexo d
</code></pre><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>对比了一下Github和S3的速度，最大的一个页面github.io大概需要6-9秒，而S3要11秒左右，虽然github的速度不太稳定，但毕竟要比S3快，所以暂不把DNS指向S3，待日后开启CloudFront服务后再做决定。<br>另外，hexo是支持多路径发布的，形如：</p>
<pre><code>deploy:
- type: git
  repo:
- type: heroku
  repo:
</code></pre><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>要使用自己的域名，开启HTTPS，使用AWS的CND，参照：<a href="https://www.duyidong.com/2017/03/20/Enable-HTTPS-and-CDN-with-Cloudfront/">使用AWS解锁HTTPS和CDN</a></p>
<blockquote>
<ul>
<li>参考资料:</li>
<li><a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">https://hexo.io/docs/deployment.html</a></li>
<li><a href="https://inject.coffee/hexo-travis-s3-part-2-deploying-to-aws/" target="_blank" rel="external">https://inject.coffee/hexo-travis-s3-part-2-deploying-to-aws/</a></li>
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html" target="_blank" rel="external">https://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html</a></li>
<li><a href="https://aws.amazon.com/s3/storage-classes/" target="_blank" rel="external">https://aws.amazon.com/s3/storage-classes/</a></li>
<li><a href="https://aws.amazon.com/s3/reduced-redundancy/" target="_blank" rel="external">https://aws.amazon.com/s3/reduced-redundancy/</a></li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在学习AWS服务，加之两次遇到github.io无法访问的情况，决定将博客迁移到AWS S3上。&lt;/p&gt;
&lt;h2 id=&quot;S3介绍&quot;&gt;&lt;a href=&quot;#S3介绍&quot; class=&quot;headerlink&quot; title=&quot;S3介绍&quot;&gt;&lt;/a&gt;S3介绍&lt;/h2&gt;&lt;p&gt;S3是A
    
    </summary>
    
      <category term="我的博客" scheme="https://www.duyidong.com/categories/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="AWS" scheme="https://www.duyidong.com/tags/AWS/"/>
    
      <category term="S3" scheme="https://www.duyidong.com/tags/S3/"/>
    
      <category term="Blog" scheme="https://www.duyidong.com/tags/Blog/"/>
    
      <category term="Hexo" scheme="https://www.duyidong.com/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>AWS认证与权限管理IAM</title>
    <link href="https://www.duyidong.com/2017/03/06/%E6%B5%85%E8%B0%88AWS-IAM/"/>
    <id>https://www.duyidong.com/2017/03/06/浅谈AWS-IAM/</id>
    <published>2017-03-06T12:41:50.000Z</published>
    <updated>2017-06-22T09:18:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>IAM，全称Identity &amp; Access Management，作用是AWS资源的权限管理。</p>
<h2 id="IAM解决了什么问题"><a href="#IAM解决了什么问题" class="headerlink" title="IAM解决了什么问题"></a>IAM解决了什么问题</h2><p>解决了什么问题，等同于带来了什么价值，在AWS的<a href="https://aws.amazon.com/iam/details/" target="_blank" rel="external">官方文档</a>中，IAM主要是出于以下需求被设计出来的：</p>
<ul>
<li><strong>增强安全：</strong>AWS给每个用户单独的验证，保证每个用户能够被分配恰当的权限，从而保证AWS资源的安全。默认情况下，IAM的User在被创建的时候是没有任何权限的，所以IAM是默认安全的。</li>
<li><strong>粒度控制：</strong>IAM让租户可以进行细粒度的权限控制，比如terminate instance的权限，比如对S3 bucket中对象的只读权限。</li>
<li><strong>临时证书：</strong>IAM允许创造生命周期短于用户的权限（Role），Role被绑定在AWS资源（如EC2 instance）上，确保资源之间的相互调用有适当的权限。</li>
<li><strong>灵活的安全证书管理：</strong>IAM提供了多种验证方式，包括key pair， 用户名密码，X.509 certificates， MFA，用于Console，CLI，sdk等API调用。</li>
<li><strong>外部身份系统：</strong>IAM使AWS支持第三方登录或与企业现有权限管理系统集成，比如微软的Active Directory，或第三方验证，比如Google，Facebook。</li>
<li><strong>与AWS服务无缝贴合：</strong>IAM与AWS的几乎所有服务集成，首先你需要IAM的权限再能访问和使用AWS的服务，其次AWS中的服务需要IAM的权限才能完成对AWS其他资源的调用。</li>
</ul>
<h2 id="几个概念"><a href="#几个概念" class="headerlink" title="几个概念"></a>几个概念</h2><p>AWS的官方文档和很多博客都在说的Get Start，最重要的就是AWS中的几个名词：</p>
<ul>
<li><strong>User：</strong>一个User对应一个AWS用户，这个用户指的是一个真实的用户，用户在创建初期是没有任何权限的，需要被加到用户组或绑定Policy才能有相应权限，User有两种验证方式，一种是key pair，常用于集成到程序中和AWS CLI 使用，另一种是Username+Password的方式，这种方式只能用于Console登录。</li>
<li><strong>UserGroup：</strong>类比Linux系统的UserGroup，一个UserGroup可以包含多个User，这些User具有UserGroup指定的所有权限，UserGroup的权限由Policy制定，Group不能嵌套Group，一个用户如在多个UserGroup中，权限取Group权限的和。</li>
<li><strong>Policy：</strong>由“资源类型”和“操作类型”两个重要参数构成的Json文件，用于定义一定粒度的权限，支持模糊匹配（*），分为官方定义和自己定义，用于定义用户可对何种资源执行何种操作，Policy可以与User，UserGroup，Role绑定。</li>
<li><strong>Role：</strong>IAM定义用于代替User赋予资源权限的权限单位，比如给一个EC2 instance S3 administrator的权限，便可以在改Instance上执行aws s3的所有命令，且在本地不会出现Creadentical文件（比User安全）。与User相同，Role 的权限也由Polic组成，由用户定义。另外，Role还可以用于赋予外部账号权限。</li>
</ul>
<h2 id="官方推荐最佳实践"><a href="#官方推荐最佳实践" class="headerlink" title="官方推荐最佳实践"></a>官方推荐最佳实践</h2><p>参照官方文档：<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html" target="_blank" rel="external">https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html</a></p>
<ul>
<li>禁用AWS Root账户：因为Root用户权限实在太大，要尽可能避免Root账户认证被泄露的风险，建议不要给Root账户创建Access Key，另外开启MFA验证。</li>
<li>为每个用户创建单独的User</li>
<li>尽可能使用Policies 添加权限</li>
<li>使用UserGroup对用户权限进行分组管理</li>
<li>最小权限原则</li>
<li>开启强密码限制</li>
<li>开启MFA设备验证</li>
<li>为EC2 instance上的应用程序创建Role</li>
<li>使用Role而不是User的Credentials</li>
<li>经常更新Credentials</li>
<li>移除不再使用的Creadentials</li>
<li>使用策略提高额外的安全性：比如限制该资源只能从哪个网段访问，只能在某个时间段访问，强制开启MFA验证后才可访问，等等</li>
<li>监控账户活动情况：CloudFront, CloudTrail, CloudWatch, Config, S3 log都可以保证账户活动被监控</li>
</ul>
<h2 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h2><p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_iam-limits.html" target="_blank" rel="external">https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_iam-limits.html</a><br>大部分限制大部分情况下都碰不到，列几个常见的：</p>
<ul>
<li>每个User最多可被加入到10个UserGroup</li>
<li>每个User最多可以有2个Access key(包括root account)</li>
<li>一个用户只能验证一个MFA设备</li>
<li>User Policy的长度限制为2KB</li>
<li>Role Policy的长度限制为10KB</li>
<li>UserGroup Policy的长度限制为5KB</li>
</ul>
<h2 id="几个知识点"><a href="#几个知识点" class="headerlink" title="几个知识点"></a>几个知识点</h2><p>以下知识点是笔者在查阅 <a href="https://aws.amazon.com/iam/faqs/" target="_blank" rel="external">FAQs</a> 时记录的：</p>
<ul>
<li>一个EC2 instance不能有多个Role，但一个Role可以被多个EC2 instance共用</li>
<li>Role可以被attach 到一个正在运行的实例</li>
<li>可以将Role与Auto Scaing Group关联，这样每个在该安全组内被启动的实例都会被附上该Role所指的权限</li>
<li>AWS有一个用于测试你的Polic的工具：<a href="https://policysim.aws.amazon.com/" target="_blank" rel="external">Policy Simulator</a></li>
<li>IAM的每一个记录都会被CloudTrail记录log，保存在S3中</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;IAM，全称Identity &amp;amp; Access Management，作用是AWS资源的权限管理。&lt;/p&gt;
&lt;h2 id=&quot;IAM解决了什么问题&quot;&gt;&lt;a href=&quot;#IAM解决了什么问题&quot; class=&quot;headerlink&quot; title=&quot;IAM解决了什么问题&quot;
    
    </summary>
    
      <category term="Amazon Web Services" scheme="https://www.duyidong.com/categories/Amazon-Web-Services/"/>
    
    
      <category term="AWS" scheme="https://www.duyidong.com/tags/AWS/"/>
    
      <category term="亚马逊认证与权限" scheme="https://www.duyidong.com/tags/%E4%BA%9A%E9%A9%AC%E9%80%8A%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%9D%83%E9%99%90/"/>
    
      <category term="Security" scheme="https://www.duyidong.com/tags/Security/"/>
    
      <category term="IAM" scheme="https://www.duyidong.com/tags/IAM/"/>
    
  </entry>
  
  <entry>
    <title>Amazon Web Server 服务概览</title>
    <link href="https://www.duyidong.com/2017/02/28/AWS-Services-Overview/"/>
    <id>https://www.duyidong.com/2017/02/28/AWS-Services-Overview/</id>
    <published>2017-02-28T06:55:01.000Z</published>
    <updated>2017-05-13T12:28:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近在准备AWS助理级架构师认证考试，借此机会梳理一下AWS比较核心的几个服务，不会太深入细节，只做简单阐释。</p>
<p>首先关于AWS服务一览：</p>
<p><img src="/images/AWS_Services_Overview.png" alt=""></p>
<p>以下服务会出现在助理级架构师考试中：</p>
<p><img src="/images/AWS_Services_Exam.png" alt=""></p>
<p>下面就按照这个顺序过一下AWS的众多服务。</p>
<h2 id="AWS-Global-Infrastructure"><a href="#AWS-Global-Infrastructure" class="headerlink" title="AWS Global Infrastructure"></a>AWS Global Infrastructure</h2><p>AWS拥有全球化的基础设施让你的服务可以在瞬间扩展到全球，你可以在<a href="https://aws.amazon.com/about-aws/global-infrastructure/" target="_blank" rel="external">这里</a>查看亚马逊当前拥有的全球基础设施信息。<br>截止到今天（2017.02.28）AWS Cloud在全球共有<strong>42</strong>个<code>Availablity Zone</code>和<strong>16</strong>个<code>geographic Regions</code>，中国区有2个Region分别在北京和宁夏（宁夏区暂未开放），每个Region各有两个AZ，受政策限制，AWS中国区与其他各地区服务分离，由<a href="https://www.sinnet.com.cn/home/product/indexyun/16" target="_blank" rel="external">光环新网</a>代理，需要单独<a href="https://www.amazonaws.cn/en/sign-up/" target="_blank" rel="external">申请账号</a>。</p>
<p><img src="https://d0.awsstatic.com/global-infrastructure/Global_Infrastructure_12-15-2016.png" alt=""></p>
<h3 id="Region-amp-Availablity-Zone"><a href="#Region-amp-Availablity-Zone" class="headerlink" title="Region &amp; Availablity Zone"></a>Region &amp; Availablity Zone</h3><p>Region是AWS按物理地理划分的节点，每个Region包含两个或以上AZ，AZ可以理解为同在一个Region的多个数据中心。之所以一个Region要有至少两个Region是因为AWS很多服务都推荐跨AZ备份而做到高可用。<br>另外AZ之间网络通信延迟远大于Region之前通信，原因也很好理解，Region的物理距离很远，而同Region的AZ是在同一个城市。</p>
<h3 id="Edge-Location"><a href="#Edge-Location" class="headerlink" title="Edge Location"></a>Edge Location</h3><p>Edge Location是比亚马逊数据中心覆盖面还广的服务，我们访问AWS console就使用过Edge Location，同时Edge Location还作为AWS Cloudfront（CDN）服务的节点，你可以在<a href="https://www.google.com/maps/d/viewer?msa=0&amp;mid=z8tAG_iMI0RE.kBLn8p8h4GGw" target="_blank" rel="external">这里</a>看到AWS服务在全球分布的情况，在<a href="https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/#AWS Edge Network Locations" target="_blank" rel="external">这里</a>查看AWS的Edge Location分部情况。</p>
<h2 id="Networking-amp-Content-Deivery"><a href="#Networking-amp-Content-Deivery" class="headerlink" title="Networking &amp; Content Deivery"></a>Networking &amp; Content Deivery</h2><p>这一部分的内容主要包含网络和CDN。</p>
<h3 id="VPC"><a href="#VPC" class="headerlink" title="VPC"></a>VPC</h3><p>VPC(<a href="https://aws.amazon.com/vpc/" target="_blank" rel="external">Virtual Private Cloud</a>)，AWS服务中关于网络最重要的一个服务，作用是在AWS中虚拟一个定制化局域网，从而可以像管理一个虚拟数据中心一样管理AWS中的资源。一个Region最多可以有5个VPC，你可以自由定义VPC的局域网网段（当然要使用专用网段），每个VPC之间可以单点连通前提是专用网段不重复。<br>VPC就是一个虚拟的局域网，可以通过给VPC绑定InternetGateway的方式让VPC成为public VPC，即在外网可以访问VPC内的服务。就好比公司网络中加了一个从内网出去的路由。当然要让外网的设备找到VPC中的资源还需要给VPC中的资源绑定一个公网IP。</p>
<h3 id="Route53"><a href="#Route53" class="headerlink" title="Route53"></a>Route53</h3><p><a href="https://aws.amazon.com/route53/" target="_blank" rel="external">Route53</a>是AWS的DNS服务。可以注册DNS，配置A地址和CNAME。</p>
<h3 id="Cloud-Front"><a href="#Cloud-Front" class="headerlink" title="Cloud Front"></a>Cloud Front</h3><p><a href="https://aws.amazon.com/cloudfront/" target="_blank" rel="external">Cloud Front</a>是亚马逊的CDN（Content Delivery Network）服务，用于缓存下载或上传的数据。</p>
<h3 id="Direct-Connect"><a href="#Direct-Connect" class="headerlink" title="Direct Connect"></a>Direct Connect</h3><p><a href="https://aws.amazon.com/directconnect/" target="_blank" rel="external">Direct Connect</a>是亚马逊的网络直连服务，就是用一跟又粗又长的网线，从你的数据中心翻山越岭地连接到AWS的数据中心从而建立一个稳定可靠高效的私有连接。</p>
<h2 id="Compute"><a href="#Compute" class="headerlink" title="Compute"></a>Compute</h2><p><a href="https://aws.amazon.com/products/compute/" target="_blank" rel="external">AWS Compute</a>包含了亚马逊最重要的服务——计算服务</p>
<h3 id="EC2"><a href="#EC2" class="headerlink" title="EC2"></a>EC2</h3><p>EC2(<a href="https://aws.amazon.com/ec2/" target="_blank" rel="external">Elastic Compute Cloud</a>)可以理解为AWS的虚拟机，包含存储（EBS），镜像（AMI），备份（snapshot），防火墙（Security Group）等紧密相关的服务，AWS的一部分服务也是基于EC2的，比如ECS和RDS。<br>使用EC2你可以按照你的需要创建Instance，不仅可以自由控制Instance的数量，还可以动态调整虚拟机的各种参数，比如内存，CPU。最重要的是，使用AWS EC2你可以——按需付费。</p>
<h3 id="EC2-Contianer-Service"><a href="#EC2-Contianer-Service" class="headerlink" title="EC2 Contianer Service"></a>EC2 Contianer Service</h3><p>ECS(<a href="https://aws.amazon.com/ecs/" target="_blank" rel="external">EC2 Contianer Service</a>)帮助管理在EC2上运行Docker或容器集群，适用于构建微服务。</p>
<blockquote>
<p>注：该服务不会出现在SAA考试中</p>
</blockquote>
<h3 id="Elastic-Beanstalk"><a href="#Elastic-Beanstalk" class="headerlink" title="Elastic Beanstalk"></a>Elastic Beanstalk</h3><p><a href="https://aws.amazon.com/elasticbeanstalk/" target="_blank" rel="external">Elastic Beanstalk</a>是一个用于方便部署web服务的一个傻瓜式应用，你不需要知道关于AWS的一切，只需要上传代码，Beanstalk会帮你选择合适的环境，运行环境，负载均衡，监控等等，目前支持语言包括 Java, .NET, PHP, Node.js, Python, Ruby, Go。</p>
<blockquote>
<p>注：该服务不会出现在SAA考试中，只需要知道Beanstalk是什么就可以。</p>
</blockquote>
<h3 id="Lambda"><a href="#Lambda" class="headerlink" title="Lambda"></a>Lambda</h3><p><a href="https://aws.amazon.com/lambda/" target="_blank" rel="external">Lambda</a>是一个云计算革命性的服务，关键词<strong>Serverless</strong>，也是AWS这几年大力在推的服务，主要特点是除了功能性的function以外的所有服务（操作系统，物理硬件，运行环境）都由AWS管理，资源只在被调用时创建并在使用完后立即销毁，最大限度地做到了高可用高伸缩，同时非常便宜，按照访问次数收费。（每百万次0.05美刀）<br>主要使用场景是流处理，应用后端。</p>
<blockquote>
<p>注：因为是比较新的服务，所以暂时还没有在SAA考试或样题中出现，但毫无疑问这是AWS一个重要的服务。</p>
</blockquote>
<h3 id="Lightsail"><a href="#Lightsail" class="headerlink" title="Lightsail"></a>Lightsail</h3><p><a href="https://amazonlightsail.com/" target="_blank" rel="external">Lightsail</a>与Elastic Beanstalk类似，也是一个给不会使用AWS的用户提供自动化部署的一个服务。</p>
<blockquote>
<p>注：该服务不算是AWS的核心服务，仅作为了解，考试内容不会涉及。</p>
</blockquote>
<h2 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h2><p><a href="https://aws.amazon.com/products/storage/" target="_blank" rel="external">AWS Storage</a>包含了AWS存储有关的服务，这里暂不列举EBS。</p>
<h3 id="S3"><a href="#S3" class="headerlink" title="S3"></a>S3</h3><p>S3(<a href="https://aws.amazon.com/s3/" target="_blank" rel="external">Simple Storage Service</a>) 差不多是和AWS一样老的一个服务，同时支撑着AWS中很多其他的服务。<br>S3是一个高可用的对象存储服务，可以理解为一个巨大的磁盘可以存放图片，视频一类的大小静态文件，其存储持久性可达到11个9，可用性可以达到4个9。S3的对象存储单个文件最大可达5TB，总大小不设上限。同时S3可以作为静态网站使用，可以开启版本管理。本博客也准备迁移到AWS S3上。<br>S3的使用场景可以用作静态网站部署，数据存储（例如数据胡泊），用于数据分析，数据备份等。当然也可以用来构建Serverless服务。</p>
<h3 id="Clacier"><a href="#Clacier" class="headerlink" title="Clacier"></a>Clacier</h3><p><a href="https://aws.amazon.com/glacier/" target="_blank" rel="external">Claier</a>是用于存档数据长期保存的一个服务，如果你有长时间不使用但是需要保存的数据，例如医院的病例，电视台的历史影像资料，你可以使用这个服务，其主要特点是异常便宜（0.004美刀/GB），同时能做到11个9的持久度。另外归档数据在提取时大概需要4-5个小时，所以不适宜存储需要频繁读写的数据。</p>
<h3 id="EFS"><a href="#EFS" class="headerlink" title="EFS"></a>EFS</h3><p>EFS(<a href="https://aws.amazon.com/efs/" target="_blank" rel="external">Elastic File System</a>)是一个可移动的块存储设备，你可以想象成一个可以任意扩容的移动硬盘，在需要时被接到任何一台EC2 instance上，同时它还具有nfs的功能，可以同时连接多台设备。EFS在刚创建的时候大小为零，随着存放资源增多逐渐扩容，真正做到按需付费，缺点是小贵，大概0.3美刀/GB</p>
<h3 id="Storage-Gateway"><a href="#Storage-Gateway" class="headerlink" title="Storage Gateway"></a>Storage Gateway</h3><p><a href="https://aws.amazon.com/storagegateway/" target="_blank" rel="external">Storage Gateway</a>是一个让你的数据中心可以和AWS存储设备无缝对接的服务，你可以像访问本地文件系统一样访问你存储在AWS云上的资源。</p>
<blockquote>
<p>注：该服务在Ops认证会被重点考察，SAA涉及不多。</p>
</blockquote>
<h2 id="Databases"><a href="#Databases" class="headerlink" title="Databases"></a>Databases</h2><p><a href="https://aws.amazon.com/products/databases" target="_blank" rel="external">AWS Cloud Database</a><br>涉及到考试，重点在针对不同的使用场景选择合适的数据库服务，另外非关系型数据库的高性能高伸缩和关系型数据库如何做到高可用，读写分离也常会作为考点。</p>
<h3 id="RDS"><a href="#RDS" class="headerlink" title="RDS"></a>RDS</h3><p>RDS(<a href="https://aws.amazon.com/rds/" target="_blank" rel="external">Relation Database Serveice</a>)是一个托管在AWS上的关系型数据库，目前支持MySQL，Postgresql，SQLserver，MariaDB，Oracle和一个亚马逊自己出的Aurora（据说很屌）。</p>
<h3 id="DynamoDB"><a href="#DynamoDB" class="headerlink" title="DynamoDB"></a>DynamoDB</h3><p><a href="https://aws.amazon.com/dynamodb/" target="_blank" rel="external">DynamoDB</a>是AWS提供的非关系型数据库，特点是高一致，低延迟，极易伸缩，相当灵活。</p>
<blockquote>
<p>注：该服务在Developor认证考试中重点考察，SAA认证也有涉及。</p>
</blockquote>
<h3 id="Redshift"><a href="#Redshift" class="headerlink" title="Redshift"></a>Redshift</h3><p><a href="https://aws.amazon.com/redshift/" target="_blank" rel="external">Redshift</a>是托管在AWS上的数据仓库，提供PB级的存储服务。</p>
<h3 id="Elasticache"><a href="#Elasticache" class="headerlink" title="Elasticache"></a>Elasticache</h3><p><a href="https://aws.amazon.com/elasticache/" target="_blank" rel="external">Elasticache</a>AWS上一个高吞吐的缓存服务，有Redis和Memcached两种类型。</p>
<h2 id="Migration"><a href="#Migration" class="headerlink" title="Migration"></a>Migration</h2><h3 id="Snowball"><a href="#Snowball" class="headerlink" title="Snowball"></a>Snowball</h3><p>AWS官方提供的物理迁移，小型的是一个手提箱，大型的有卡车大小的移动存储，帮助你将大量数据加密传输到亚马逊的云上。<br>关于Snowball一个重要的概念就是Import和Export，你可以从S3导出或导入数据到Snowball。</p>
<h3 id="DMS"><a href="#DMS" class="headerlink" title="DMS"></a>DMS</h3><p>DMS(<a href="https://aws.amazon.com/dms/" target="_blank" rel="external">Database Migration Service</a>)帮助你将本地数据库中的数据迁移到AWS上，同时还支持在AWS中不同类型的数据库之间做零宕机的数据迁移。比如从本地的Oracle中将数据迁移到AWS的Aurora上。</p>
<blockquote>
<p>注：DMS是AWS中一个重要的服务，但暂未出现在SAA的考试中。</p>
</blockquote>
<h3 id="SMS"><a href="#SMS" class="headerlink" title="SMS"></a>SMS</h3><p>SMS(<a href="https://aws.amazon.com/server-migration-service/" target="_blank" rel="external">Server Migration Service</a>)AWS服务器迁移服务是一种无代理服务，使租户能够快速将本地服务增量式地迁移到云上，具体就是将本地服务器的卷打成镜像放到云上再跑起来。</p>
<blockquote>
<p>注：该服务暂时没有在所有考试中出现。</p>
</blockquote>
<h2 id="Analytics"><a href="#Analytics" class="headerlink" title="Analytics"></a>Analytics</h2><p><a href="https://aws.amazon.com/products/analytics/" target="_blank" rel="external">Analytics</a>主要用于处理，分析，可视化数据。</p>
<h3 id="Athena"><a href="#Athena" class="headerlink" title="Athena"></a>Athena</h3><p><a href="https://aws.amazon.com/athena/" target="_blank" rel="external">Athena</a>让租户可以使用SQL交互式地查询S3中的数据，Athena是Serverless的，所以用户只需按使用次数付费。</p>
<h3 id="EMR"><a href="#EMR" class="headerlink" title="EMR"></a>EMR</h3><p>Elastic MapReduce，就是托管在AWS上的map reduce，用于管理大数据集群（EC2 instance集群）</p>
<blockquote>
<p>注：SAA考试会涉及。</p>
</blockquote>
<h3 id="Cloud-Search-amp-Elastic-Search"><a href="#Cloud-Search-amp-Elastic-Search" class="headerlink" title="Cloud Search &amp; Elastic Search"></a>Cloud Search &amp; Elastic Search</h3><p>用于构建站内搜索或应用内搜索。</p>
<blockquote>
<p>注：助理级考试均不涉及。</p>
</blockquote>
<h3 id="Kinesis"><a href="#Kinesis" class="headerlink" title="Kinesis"></a>Kinesis</h3><p><a href="https://aws.amazon.com/kinesis/" target="_blank" rel="external">Kinesis</a>强大的实时数据流处理服务，速度可达TB每小时，用于上传，分析实时数据流。比较重要。</p>
<h3 id="Data-Pipeline"><a href="#Data-Pipeline" class="headerlink" title="Data Pipeline"></a>Data Pipeline</h3><p>提供有序处理数据，洗数据，数据迁移的工作。</p>
<h3 id="Quick-Sight"><a href="#Quick-Sight" class="headerlink" title="Quick Sight"></a>Quick Sight</h3><p>为你的数据创建可视化面板。</p>
<h2 id="Security-amp-Identity"><a href="#Security-amp-Identity" class="headerlink" title="Security &amp; Identity"></a>Security &amp; Identity</h2><h3 id="IAM"><a href="#IAM" class="headerlink" title="IAM"></a>IAM</h3><p>IAM(<a href="https://aws.amazon.com/iam/" target="_blank" rel="external">Identity &amp; Access Management</a>)是AWS的权限管理服务，是一个非常重要的服务。这个服务是免费的，而且Global，即不收Region限制的。<br>关于IAM主要需要知道关于User Group, User, Role, Polic几个概念即可；User Group和User都类似于Linux中的用户组和用户的概念，不同的是AWS根据Polic赋予用户权限，关于Polic，主要就是规定可以对“何种资源”进行“何种操作”两个参数，Role的定义类似于User，但是Role不是赋予用户使用，而是赋予给AWS的资源的，例如租户需要创建一个EC2 instance，这个Instance需要操纵S3的资源，那么你需要在创建这个EC2 instance的时候赋予一个带S3操作权限的Role，需要注意的是Role只能在创建资源的时候被赋予，且不能更改不能解除绑定，另外在包含Role的instance中你无法看到AWS ACCESS KEY 之类的文本文件，这是AWS出于安全的设计。</p>
<h3 id="Inspector"><a href="#Inspector" class="headerlink" title="Inspector"></a>Inspector</h3><p><a href="https://aws.amazon.com/inspector/" target="_blank" rel="external">Inspector</a>是一个安装在EC2 instance上的客户端，用于生成安全报告。</p>
<blockquote>
<p>注：暂不在考试中出现</p>
</blockquote>
<h3 id="Certificate-Manager"><a href="#Certificate-Manager" class="headerlink" title="Certificate Manager"></a>Certificate Manager</h3><p><a href="https://aws.amazon.com/certificate-manager/" target="_blank" rel="external">Certificate Manager</a>是一个用于管理SSL证书的服务。</p>
<h3 id="Directory-Service"><a href="#Directory-Service" class="headerlink" title="Directory Service"></a>Directory Service</h3><p><a href="https://aws.amazon.com/directoryservice/" target="_blank" rel="external">Directory Service</a>让租户可以将AWS权限管理和自建数据中的AD group集合在一起，可以直接使用Microsoft AD Group创建AWS中的资源。</p>
<h3 id="WAF"><a href="#WAF" class="headerlink" title="WAF"></a>WAF</h3><p>WAF(<a href="https://aws.amazon.com/certificate-manager.com/waf/" target="_blank" rel="external">Web Application Firewall</a>)给予租户应用级别的安全防护，比如SQL注入，跨站攻击，等。</p>
<h3 id="Artifact"><a href="#Artifact" class="headerlink" title="Artifact"></a>Artifact</h3><p>这是让你能访问到AWS compliance document 的服务，可以从中获取各种合规文件。</p>
<h2 id="Management-Tools"><a href="#Management-Tools" class="headerlink" title="Management Tools"></a>Management Tools</h2><h3 id="Could-Watch"><a href="#Could-Watch" class="headerlink" title="Could Watch"></a>Could Watch</h3><p>Cloud Watch 是AWS重要的Ops工具，作用为监控AWS资源状态的工具，可以设置连个级别，分别是五分钟一个心跳（默认）和一分钟一个心跳。该服务监控类目(Metrics)繁多，甚至包括花费的监控预警，可以设置Alarm触发SNS给到租户通知实现报警的功能。</p>
<h3 id="Cloud-Formation"><a href="#Cloud-Formation" class="headerlink" title="Cloud Formation"></a>Cloud Formation</h3><p>Cloud Formation是AWS一个重要的DevOps工具，实践了基础设施及代码，租户可以使用一套模板（Template），即一个Json或者Yaml的文件定义整个AWS服务的使用，包括资源，网络，权限。是一个可以投入大量精力使用学习的一个服务。</p>
<blockquote>
<p>注：Cloud Formation是一个重要的服务，但不会在SAA考试中出现很多，只需要一定程度的了解即可，但想成为一个真正的架构师，这个服务必须要熟悉。</p>
</blockquote>
<h3 id="Cloud-Trail"><a href="#Cloud-Trail" class="headerlink" title="Cloud Trail"></a>Cloud Trail</h3><p>用于监控AWS API调用的一个服务，哪些操作属于AWS API调用——创建一个资源，改变一个资源的配置，销毁一个资源，往S3上传一个对象，都算。这些操作被Cloud Trail记录下来保存在S3中作为log供租户使用，AWS的一些边缘服务也有依赖于Cloud Trail的。但笔者在使用该服务时发现其存在延迟时间长（10-20min），无法划分日志级别，且日志冗余不易分析等缺点，仍不是很好用。</p>
<h3 id="Opsworks"><a href="#Opsworks" class="headerlink" title="Opsworks"></a>Opsworks</h3><p>AWS提供的有一个基础设施及代码的工具，使用<a href="https://www.chef.io/chef/" target="_blank" rel="external">Chef</a>。</p>
<h3 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h3><p><a href="https://aws.amazon.com/waf/" target="_blank" rel="external">Config</a>是用于记录资源配置规则变更，并判断资源配置是否合规的一个服务。</p>
<blockquote>
<p>注：该服务不会出现在助理级考试中，但会在Security的考察中出现。</p>
</blockquote>
<h3 id="Service-Catalog-amp-Trusted-Advisor"><a href="#Service-Catalog-amp-Trusted-Advisor" class="headerlink" title="Service Catalog &amp; Trusted Advisor"></a>Service Catalog &amp; Trusted Advisor</h3><p>Trusted Advisor是一个有意思的服务，从安全，省钱，性能，容错四个角度给你的AWS资源配给一个全面的分析，这四个角度也是AWS架构师设计一个良好的架构必须要考虑的四个角度。且该服务与AWS收费等级强相关，AWS的服务等级分为基础版、开发版、商业版、企业版四个级别，交的钱不同会高度体现在这个服务的内容上。<a href="https://aws.amazon.com/premiumsupport/compare-plans/" target="_blank" rel="external">https://aws.amazon.com/premiumsupport/compare-plans/</a></p>
<h2 id="Application-Services"><a href="#Application-Services" class="headerlink" title="Application Services"></a>Application Services</h2><h3 id="Step-Functions"><a href="#Step-Functions" class="headerlink" title="Step Functions"></a>Step Functions</h3><p><a href="https://aws.amazon.com/step-functions/" target="_blank" rel="external">Step Functions</a>是在2017年初才推出的一个新服务，可用于执行批处理脚本。</p>
<blockquote>
<p>注：因为该服务还很新，暂未出现在认证考试中</p>
</blockquote>
<h3 id="SWF"><a href="#SWF" class="headerlink" title="SWF"></a>SWF</h3><p>SWF(<a href="https://aws.amazon.com/swf/" target="_blank" rel="external">Simple Workflow Service</a>)让开发者可以按顺序执行一些后台命令，如果您的应用程序的步骤需要超过500毫秒的时间来完成，您需要跟踪处理状态，如果任务失败，您需要恢复或重试，Amazon SWF可以做到。</p>
<blockquote>
<p>注：这个服务比较重要，需要动手实践。</p>
</blockquote>
<h3 id="API-Gateway"><a href="#API-Gateway" class="headerlink" title="API Gateway"></a>API Gateway</h3><p>API Gateway是AWS一个Serverless有关的重要的服务，常用于触发Lambda function。</p>
<blockquote>
<p>注：这个服务在构建无服务架构的时候非常重要，但不会在考试中涉及很多细节，只需要了解其作用，用法即可。</p>
</blockquote>
<h3 id="Elasic-Transcoder"><a href="#Elasic-Transcoder" class="headerlink" title="Elasic Transcoder"></a>Elasic Transcoder</h3><p>用于视频转码。</p>
<h2 id="Message"><a href="#Message" class="headerlink" title="Message"></a>Message</h2><p>消息服务是AWS一个非常重要的服务，我们可以通过SNS(Simple Noticfication Service)发送短信，邮件提示，使用SQS（Simple Queue Service）构建一个保证交付的消息队列，使用SES(Simple Email Service)收发邮件。</p>
<h2 id="Desktop-amp-App-Streaming"><a href="#Desktop-amp-App-Streaming" class="headerlink" title="Desktop &amp; App Streaming"></a>Desktop &amp; App Streaming</h2><h3 id="workspace"><a href="#workspace" class="headerlink" title="workspace"></a>workspace</h3><p>一个在AWS云端的远程办公桌面。</p>
<h3 id="AppStream2-0"><a href="#AppStream2-0" class="headerlink" title="AppStream2.0"></a>AppStream2.0</h3><p><a href="https://aws.amazon.com/appstream2/" target="_blank" rel="external">AppStream</a>可以将桌面应用程序流式传输到运行Web浏览器的任何设备，安全地从任何地方即时访问桌面应用程序，如AWS console。</p>
<blockquote>
<ul>
<li>参考资料</li>
<li><a href="https://www.linuxnix.com/amazon-aws-regions-vs-availability-zones-vs-edge-locations-vs-data-centers/" target="_blank" rel="external">https://www.linuxnix.com/amazon-aws-regions-vs-availability-zones-vs-edge-locations-vs-data-centers/</a></li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在准备AWS助理级架构师认证考试，借此机会梳理一下AWS比较核心的几个服务，不会太深入细节，只做简单阐释。&lt;/p&gt;
&lt;p&gt;首先关于AWS服务一览：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/AWS_Services_Overview.png&quot; alt=&quot;&quot;&gt;&lt;/
    
    </summary>
    
      <category term="Amazon Web Services" scheme="https://www.duyidong.com/categories/Amazon-Web-Services/"/>
    
    
      <category term="AWS" scheme="https://www.duyidong.com/tags/AWS/"/>
    
      <category term="云计算" scheme="https://www.duyidong.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
</feed>
